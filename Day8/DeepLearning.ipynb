{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e0821f-4031-4066-8d63-a387ec643350",
   "metadata": {},
   "source": [
    "# Deep Learning - Derin Öğrenme - ANN - Artificial Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77b83a17-05cd-49fc-b68c-6100929ecfc4",
   "metadata": {},
   "source": [
    "1- Derin Öğrenmede Feature Engineering'e gerek yok.\n",
    "2- Tensorflow kullanıyoruz. Keras - API kullanıyor.\n",
    "3- Tensor - Çok boyutlu Matrix Flow akış Google tarafından geliştirildi. Rakip - Facebook Pytorch\n",
    "4- GPU ( Ekran Kartlari ile hesap yapmak daha hızlı)\n",
    "5- Derin Öğrenme insan beynininöğrenme şeklini kopyalar, insan beyni nasıl öğrenirse yapay sinir ağlari da öyle öğrenir.\n",
    "6- Nöronlar arasında gidip gelme işlemine epoch denir.\n",
    "7- Her nörondan diğerine bir ağırlık aktarılık(katsayı) aktarılır.\n",
    "8- Aktarma işlemine Aktivasyon fonksiyonu karar verir. ReLU, Softmax, Sigmoid\n",
    "9- Resimler çok büyük olduğu için parça - parça işlenir  buna bathch-size denir.\n",
    "10- Resimler üzerinde çalışıyorsanız CNN kullanılır.\n",
    "11- Resim, Text(yazı), video üretme işlmeler LSTM ile yapılır. (Long-Short Time Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbf247-c633-4e8b-b111-36fee66eaba5",
   "metadata": {},
   "source": [
    "### Deep Learning ile Makine Öğrenmesi (1-Classification 2-Regression 3-Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ba5e0-7ae8-4076-8112-5a24bcbebd26",
   "metadata": {},
   "source": [
    "1- Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37837880-38b0-48f8-b5d8-64c89e62141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b504543e-b209-48b3-9e5b-47294893bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bde8439-bb06-4f7c-83ef-694f5795bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfab51f-fb44-4178-b033-d27b7a25668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70e7620-0afd-46b9-b49a-f56414a31310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a0dd57-7e29-4daa-ac43-f4ba7f814635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c443ce7-387d-4c92-a7fb-45c2de7ef711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3575dc-9798-46ef-baef-612a7c9e4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']] #Hedefimiz şeker hastası olup olmadıklarını tespit edebilmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5068b3f-3e4e-4ca3-ac80-b5a3f8665e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[['Outcome']] #Hedefimiz şeker hastası olup olmadıklarını tespit edebilmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15295541-74ed-4bf6-bc13-112f58c2ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ya da\n",
    "#x=df.iloc[:,0:8] #ilk 8 sütunu al 8 dahil değil\n",
    "#y=df.iloc[:,8] #8i al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f906224b-4869-4031-9313-e01e867fa360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46f77143-770c-42a2-bdd9-d889ab3335d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82184720-abc6-42d5-adf7-70f1a3fa4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(8,activation=\"relu\")) # Dense layer tüm layerlarda bulun demek, ilkine 8 koyuyoruz çünkü 8 sütun var. activation koduna relu diyoruz. birinin çıktısı diğerinin girdiği oluyor\n",
    "model.add(Dense(12,activation=\"relu\")) \n",
    "model.add(Dense(4,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))#classificaion olduğu için sonuç evet veya hayır olacak o yüzden 1 koyuyoruz.\n",
    "#nöron sayısını arttırmak başarıyı arttıtrıyor\n",
    "#birden fazla layer varsa reLU kullanıyoruz aralarda\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\") #optimizer ; eğer öğrenme hızı düşükse hızlandırıyor, hızlıysa ortalamaya getiritor ayarlıyor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29bd2b19-ae7f-4ed2-8dd2-a547a00b10a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "77/77 [==============================] - 1s 2ms/step - loss: 0.7727 - accuracy: 0.6419\n",
      "Epoch 2/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6510\n",
      "Epoch 3/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6510\n",
      "Epoch 4/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6510\n",
      "Epoch 5/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6510\n",
      "Epoch 6/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6510\n",
      "Epoch 7/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6510\n",
      "Epoch 8/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6510\n",
      "Epoch 9/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6510\n",
      "Epoch 10/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6510\n",
      "Epoch 11/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6510\n",
      "Epoch 12/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6510\n",
      "Epoch 13/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6510\n",
      "Epoch 14/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6510\n",
      "Epoch 15/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6510\n",
      "Epoch 16/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6510\n",
      "Epoch 17/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6510\n",
      "Epoch 18/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6510\n",
      "Epoch 19/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6510\n",
      "Epoch 20/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6510\n",
      "Epoch 22/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6510\n",
      "Epoch 23/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6510\n",
      "Epoch 24/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6510\n",
      "Epoch 25/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6510\n",
      "Epoch 26/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6510\n",
      "Epoch 27/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6510\n",
      "Epoch 28/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6510\n",
      "Epoch 29/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6510\n",
      "Epoch 30/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6510\n",
      "Epoch 31/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6510\n",
      "Epoch 32/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6510\n",
      "Epoch 33/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6510\n",
      "Epoch 34/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6510\n",
      "Epoch 35/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6510\n",
      "Epoch 36/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6510\n",
      "Epoch 37/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6510\n",
      "Epoch 38/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6510\n",
      "Epoch 39/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6510\n",
      "Epoch 40/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6510\n",
      "Epoch 41/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6510\n",
      "Epoch 42/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6510\n",
      "Epoch 43/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6510\n",
      "Epoch 44/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6510\n",
      "Epoch 45/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6510\n",
      "Epoch 46/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6510\n",
      "Epoch 47/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6510\n",
      "Epoch 48/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6510\n",
      "Epoch 49/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6510\n",
      "Epoch 50/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6510\n",
      "Epoch 51/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6510\n",
      "Epoch 52/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6510\n",
      "Epoch 53/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6510\n",
      "Epoch 54/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6510\n",
      "Epoch 55/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6510\n",
      "Epoch 56/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6322 - accuracy: 0.6510\n",
      "Epoch 57/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.6510\n",
      "Epoch 58/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6510\n",
      "Epoch 59/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6510\n",
      "Epoch 60/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6510\n",
      "Epoch 61/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.6510\n",
      "Epoch 62/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.6510\n",
      "Epoch 63/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6510\n",
      "Epoch 64/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6510\n",
      "Epoch 65/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6510\n",
      "Epoch 66/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.6510\n",
      "Epoch 67/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6510\n",
      "Epoch 68/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.6510\n",
      "Epoch 69/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6510\n",
      "Epoch 70/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6510\n",
      "Epoch 71/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6510\n",
      "Epoch 72/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.6510\n",
      "Epoch 73/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6510\n",
      "Epoch 74/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6510\n",
      "Epoch 75/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6510\n",
      "Epoch 76/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6510\n",
      "Epoch 77/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6510\n",
      "Epoch 78/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.6510\n",
      "Epoch 79/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6510\n",
      "Epoch 80/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6510\n",
      "Epoch 81/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6510\n",
      "Epoch 82/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6510\n",
      "Epoch 83/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6510\n",
      "Epoch 84/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6510\n",
      "Epoch 85/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6510\n",
      "Epoch 86/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6510\n",
      "Epoch 87/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6510\n",
      "Epoch 88/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.6510\n",
      "Epoch 89/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.6510\n",
      "Epoch 90/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6510\n",
      "Epoch 91/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6510\n",
      "Epoch 92/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6510\n",
      "Epoch 93/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6510\n",
      "Epoch 94/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.6510\n",
      "Epoch 95/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6510\n",
      "Epoch 96/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6510\n",
      "Epoch 97/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6510\n",
      "Epoch 98/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6510\n",
      "Epoch 99/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6510\n",
      "Epoch 100/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6510\n",
      "Epoch 101/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6510\n",
      "Epoch 102/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.6510\n",
      "Epoch 103/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6510\n",
      "Epoch 104/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.6510\n",
      "Epoch 105/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6510\n",
      "Epoch 106/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.6510\n",
      "Epoch 107/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.6510\n",
      "Epoch 108/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6510\n",
      "Epoch 109/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.6510\n",
      "Epoch 110/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6510\n",
      "Epoch 111/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.6510\n",
      "Epoch 112/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.6510\n",
      "Epoch 113/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.5829 - accuracy: 0.6510\n",
      "Epoch 114/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.6510\n",
      "Epoch 115/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.6510\n",
      "Epoch 116/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.6510\n",
      "Epoch 117/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.6510\n",
      "Epoch 118/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.6510\n",
      "Epoch 119/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.6510\n",
      "Epoch 120/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.6510\n",
      "Epoch 121/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.6510\n",
      "Epoch 122/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6510\n",
      "Epoch 123/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.6510\n",
      "Epoch 124/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6667\n",
      "Epoch 125/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6966\n",
      "Epoch 126/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7044\n",
      "Epoch 127/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6979\n",
      "Epoch 128/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.6992\n",
      "Epoch 129/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.6966\n",
      "Epoch 130/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.6927\n",
      "Epoch 131/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.6888\n",
      "Epoch 132/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6992\n",
      "Epoch 133/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7057\n",
      "Epoch 134/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7005\n",
      "Epoch 135/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.6953\n",
      "Epoch 136/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.6966\n",
      "Epoch 137/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.6992\n",
      "Epoch 138/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.6966\n",
      "Epoch 139/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7083\n",
      "Epoch 140/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7057\n",
      "Epoch 141/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7096\n",
      "Epoch 142/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7057\n",
      "Epoch 143/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7070\n",
      "Epoch 144/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7018\n",
      "Epoch 145/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7044\n",
      "Epoch 146/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7122\n",
      "Epoch 147/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7031\n",
      "Epoch 148/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7083\n",
      "Epoch 149/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7044\n",
      "Epoch 150/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7083\n",
      "Epoch 151/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7044\n",
      "Epoch 152/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7135\n",
      "Epoch 153/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7161\n",
      "Epoch 154/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7227\n",
      "Epoch 155/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7135\n",
      "Epoch 156/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7135\n",
      "Epoch 157/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7161\n",
      "Epoch 158/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7122\n",
      "Epoch 159/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7174\n",
      "Epoch 160/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7227\n",
      "Epoch 161/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7122\n",
      "Epoch 162/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7174\n",
      "Epoch 163/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7174\n",
      "Epoch 164/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7357\n",
      "Epoch 165/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7344\n",
      "Epoch 166/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7214\n",
      "Epoch 167/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7253\n",
      "Epoch 168/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7279\n",
      "Epoch 169/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7240\n",
      "Epoch 170/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7292\n",
      "Epoch 172/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7292\n",
      "Epoch 173/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7070\n",
      "Epoch 174/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7344\n",
      "Epoch 175/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7148\n",
      "Epoch 176/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7227\n",
      "Epoch 177/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7279\n",
      "Epoch 178/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7201\n",
      "Epoch 179/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7201\n",
      "Epoch 180/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7279\n",
      "Epoch 181/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7344\n",
      "Epoch 182/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7357\n",
      "Epoch 183/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7357\n",
      "Epoch 184/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7318\n",
      "Epoch 185/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7318\n",
      "Epoch 186/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7383\n",
      "Epoch 187/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7266\n",
      "Epoch 188/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7396\n",
      "Epoch 189/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7370\n",
      "Epoch 190/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7396\n",
      "Epoch 191/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7370\n",
      "Epoch 192/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7292\n",
      "Epoch 193/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7292\n",
      "Epoch 194/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7227\n",
      "Epoch 195/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7370\n",
      "Epoch 196/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7266\n",
      "Epoch 197/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7188\n",
      "Epoch 198/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7331\n",
      "Epoch 199/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7266\n",
      "Epoch 200/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7396\n",
      "Epoch 201/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7539\n",
      "Epoch 202/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7253\n",
      "Epoch 203/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7409\n",
      "Epoch 204/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7396\n",
      "Epoch 205/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7240\n",
      "Epoch 206/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7513\n",
      "Epoch 207/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7383\n",
      "Epoch 208/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7552\n",
      "Epoch 209/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7370\n",
      "Epoch 210/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7487\n",
      "Epoch 211/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7474\n",
      "Epoch 212/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7526\n",
      "Epoch 213/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7500\n",
      "Epoch 214/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7461\n",
      "Epoch 215/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7422\n",
      "Epoch 216/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7461\n",
      "Epoch 217/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7409\n",
      "Epoch 218/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7526\n",
      "Epoch 219/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7500\n",
      "Epoch 220/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7526\n",
      "Epoch 221/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7331\n",
      "Epoch 222/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7526\n",
      "Epoch 223/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7396\n",
      "Epoch 224/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7253\n",
      "Epoch 225/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7552\n",
      "Epoch 226/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7526\n",
      "Epoch 227/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7396\n",
      "Epoch 228/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7474\n",
      "Epoch 229/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7565\n",
      "Epoch 230/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7487\n",
      "Epoch 231/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7604\n",
      "Epoch 232/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7604\n",
      "Epoch 233/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7630\n",
      "Epoch 234/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7539\n",
      "Epoch 235/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7539\n",
      "Epoch 236/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7448\n",
      "Epoch 237/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7591\n",
      "Epoch 238/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7552\n",
      "Epoch 239/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7643\n",
      "Epoch 240/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7656\n",
      "Epoch 241/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7539\n",
      "Epoch 242/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7552\n",
      "Epoch 243/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7617\n",
      "Epoch 244/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7474\n",
      "Epoch 245/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7552\n",
      "Epoch 246/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7487\n",
      "Epoch 247/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7513\n",
      "Epoch 248/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7734\n",
      "Epoch 249/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7643\n",
      "Epoch 250/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7643\n",
      "Epoch 251/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7448\n",
      "Epoch 252/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7513\n",
      "Epoch 253/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7591\n",
      "Epoch 254/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7682\n",
      "Epoch 255/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7500\n",
      "Epoch 256/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7305\n",
      "Epoch 257/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7578\n",
      "Epoch 258/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7669\n",
      "Epoch 259/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7591\n",
      "Epoch 260/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7500\n",
      "Epoch 261/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7591\n",
      "Epoch 262/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7630\n",
      "Epoch 263/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7487\n",
      "Epoch 264/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7734\n",
      "Epoch 265/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7565\n",
      "Epoch 266/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7695\n",
      "Epoch 267/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7539\n",
      "Epoch 268/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7526\n",
      "Epoch 269/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7526\n",
      "Epoch 270/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7500\n",
      "Epoch 271/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7682\n",
      "Epoch 272/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7591\n",
      "Epoch 273/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7474\n",
      "Epoch 274/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7630\n",
      "Epoch 275/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7617\n",
      "Epoch 276/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7643\n",
      "Epoch 277/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7617\n",
      "Epoch 278/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7669\n",
      "Epoch 279/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7591\n",
      "Epoch 280/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7656\n",
      "Epoch 281/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7721\n",
      "Epoch 282/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7578\n",
      "Epoch 283/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7565\n",
      "Epoch 284/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7708\n",
      "Epoch 285/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7656\n",
      "Epoch 286/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7591\n",
      "Epoch 287/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7630\n",
      "Epoch 288/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7513\n",
      "Epoch 289/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7591\n",
      "Epoch 290/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7760\n",
      "Epoch 291/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7591\n",
      "Epoch 292/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7695\n",
      "Epoch 293/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7578\n",
      "Epoch 294/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7578\n",
      "Epoch 295/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7578\n",
      "Epoch 296/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7617\n",
      "Epoch 297/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7617\n",
      "Epoch 298/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7591\n",
      "Epoch 299/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7591\n",
      "Epoch 300/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7617\n",
      "Epoch 301/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7721\n",
      "Epoch 302/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7591\n",
      "Epoch 304/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7513\n",
      "Epoch 305/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7669\n",
      "Epoch 306/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7578\n",
      "Epoch 307/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7513\n",
      "Epoch 308/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7656\n",
      "Epoch 309/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7682\n",
      "Epoch 310/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7617\n",
      "Epoch 311/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7839\n",
      "Epoch 312/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7552\n",
      "Epoch 313/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7604\n",
      "Epoch 314/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7708\n",
      "Epoch 315/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7747\n",
      "Epoch 316/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7695\n",
      "Epoch 317/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7799\n",
      "Epoch 318/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7500\n",
      "Epoch 319/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7669\n",
      "Epoch 320/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7630\n",
      "Epoch 321/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7552\n",
      "Epoch 322/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7695\n",
      "Epoch 323/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7617\n",
      "Epoch 324/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7747\n",
      "Epoch 325/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7643\n",
      "Epoch 326/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7669\n",
      "Epoch 327/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7578\n",
      "Epoch 330/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7565\n",
      "Epoch 331/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7669\n",
      "Epoch 332/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7630\n",
      "Epoch 333/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7500\n",
      "Epoch 334/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7682\n",
      "Epoch 335/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7695\n",
      "Epoch 336/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7682\n",
      "Epoch 337/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7591\n",
      "Epoch 338/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7695\n",
      "Epoch 339/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7682\n",
      "Epoch 340/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7526\n",
      "Epoch 341/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7604\n",
      "Epoch 342/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7708\n",
      "Epoch 343/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7643\n",
      "Epoch 344/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7643\n",
      "Epoch 345/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7760\n",
      "Epoch 346/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7656\n",
      "Epoch 347/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7708\n",
      "Epoch 348/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7682\n",
      "Epoch 349/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7604\n",
      "Epoch 350/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7617\n",
      "Epoch 351/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7773\n",
      "Epoch 352/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7786\n",
      "Epoch 353/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7682\n",
      "Epoch 354/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7695\n",
      "Epoch 355/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7747\n",
      "Epoch 356/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7708\n",
      "Epoch 357/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7747\n",
      "Epoch 358/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7721\n",
      "Epoch 359/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7721\n",
      "Epoch 360/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7721\n",
      "Epoch 361/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7604\n",
      "Epoch 362/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7539\n",
      "Epoch 363/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7669\n",
      "Epoch 364/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7643\n",
      "Epoch 365/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7760\n",
      "Epoch 366/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7760\n",
      "Epoch 367/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7682\n",
      "Epoch 368/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7799\n",
      "Epoch 369/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7721\n",
      "Epoch 370/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7865\n",
      "Epoch 371/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7812\n",
      "Epoch 372/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7669\n",
      "Epoch 373/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7734\n",
      "Epoch 374/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7734\n",
      "Epoch 375/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7826\n",
      "Epoch 376/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7786\n",
      "Epoch 377/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7643\n",
      "Epoch 378/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7643\n",
      "Epoch 379/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7565\n",
      "Epoch 380/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7669\n",
      "Epoch 381/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7630\n",
      "Epoch 382/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7747\n",
      "Epoch 383/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7708\n",
      "Epoch 384/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7826\n",
      "Epoch 385/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7865\n",
      "Epoch 386/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7565\n",
      "Epoch 387/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7799\n",
      "Epoch 388/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7852\n",
      "Epoch 389/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7852\n",
      "Epoch 390/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7773\n",
      "Epoch 391/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7747\n",
      "Epoch 392/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7734\n",
      "Epoch 393/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7591\n",
      "Epoch 394/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7669\n",
      "Epoch 395/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7734\n",
      "Epoch 396/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7812\n",
      "Epoch 397/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7852\n",
      "Epoch 398/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7721\n",
      "Epoch 399/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7760\n",
      "Epoch 400/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7812\n",
      "Epoch 401/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7682\n",
      "Epoch 402/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7708\n",
      "Epoch 403/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7734\n",
      "Epoch 404/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7760\n",
      "Epoch 405/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7773\n",
      "Epoch 406/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7747\n",
      "Epoch 407/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7747\n",
      "Epoch 408/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7695\n",
      "Epoch 409/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7695\n",
      "Epoch 410/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7878\n",
      "Epoch 411/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7773\n",
      "Epoch 412/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7578\n",
      "Epoch 413/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7734\n",
      "Epoch 414/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7734\n",
      "Epoch 415/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7760\n",
      "Epoch 416/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7695\n",
      "Epoch 417/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7747\n",
      "Epoch 418/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7891\n",
      "Epoch 419/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7721\n",
      "Epoch 420/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7682\n",
      "Epoch 421/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812\n",
      "Epoch 422/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7721\n",
      "Epoch 423/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7826\n",
      "Epoch 424/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7812\n",
      "Epoch 425/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7826\n",
      "Epoch 426/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7773\n",
      "Epoch 427/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7747\n",
      "Epoch 428/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7695\n",
      "Epoch 429/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7630\n",
      "Epoch 430/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7773\n",
      "Epoch 431/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7839\n",
      "Epoch 432/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7812\n",
      "Epoch 433/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7734\n",
      "Epoch 434/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7812\n",
      "Epoch 435/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7721\n",
      "Epoch 436/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7682\n",
      "Epoch 437/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7799\n",
      "Epoch 438/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7760\n",
      "Epoch 439/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7839\n",
      "Epoch 440/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7747\n",
      "Epoch 441/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7826\n",
      "Epoch 442/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7773\n",
      "Epoch 443/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7760\n",
      "Epoch 444/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7760\n",
      "Epoch 445/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7734\n",
      "Epoch 446/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7826\n",
      "Epoch 447/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7865\n",
      "Epoch 448/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7812\n",
      "Epoch 449/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7695\n",
      "Epoch 450/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7721\n",
      "Epoch 451/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7812\n",
      "Epoch 452/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7786\n",
      "Epoch 453/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7891\n",
      "Epoch 454/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7669\n",
      "Epoch 455/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7839\n",
      "Epoch 456/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7734\n",
      "Epoch 457/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7669\n",
      "Epoch 458/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7786\n",
      "Epoch 459/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7826\n",
      "Epoch 460/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7826\n",
      "Epoch 461/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7773\n",
      "Epoch 462/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7617\n",
      "Epoch 463/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7812\n",
      "Epoch 464/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7812\n",
      "Epoch 465/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7812\n",
      "Epoch 466/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7474\n",
      "Epoch 467/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7617\n",
      "Epoch 468/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7773\n",
      "Epoch 469/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7786\n",
      "Epoch 470/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7747\n",
      "Epoch 471/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7760\n",
      "Epoch 472/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7865\n",
      "Epoch 473/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7721\n",
      "Epoch 474/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7812\n",
      "Epoch 475/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7839\n",
      "Epoch 476/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7799\n",
      "Epoch 477/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7617\n",
      "Epoch 478/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7878\n",
      "Epoch 479/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7773\n",
      "Epoch 480/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7799\n",
      "Epoch 481/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7812\n",
      "Epoch 482/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7826\n",
      "Epoch 483/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7734\n",
      "Epoch 484/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7773\n",
      "Epoch 485/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7826\n",
      "Epoch 486/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7786\n",
      "Epoch 487/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7708\n",
      "Epoch 488/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7695\n",
      "Epoch 489/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7839\n",
      "Epoch 490/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7747\n",
      "Epoch 491/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7852\n",
      "Epoch 492/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7812\n",
      "Epoch 493/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7852\n",
      "Epoch 494/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7826\n",
      "Epoch 495/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7773\n",
      "Epoch 496/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7891\n",
      "Epoch 497/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7773\n",
      "Epoch 498/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7786\n",
      "Epoch 499/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7695\n",
      "Epoch 500/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7708\n",
      "Epoch 501/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7721\n",
      "Epoch 502/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7760\n",
      "Epoch 503/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7917\n",
      "Epoch 504/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7878\n",
      "Epoch 505/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7865\n",
      "Epoch 506/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7799\n",
      "Epoch 507/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7786\n",
      "Epoch 508/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7760\n",
      "Epoch 509/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7708\n",
      "Epoch 510/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7682\n",
      "Epoch 511/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7786\n",
      "Epoch 512/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7786\n",
      "Epoch 513/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7773\n",
      "Epoch 514/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7760\n",
      "Epoch 515/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7695\n",
      "Epoch 516/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7786\n",
      "Epoch 517/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7799\n",
      "Epoch 518/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7826\n",
      "Epoch 519/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7865\n",
      "Epoch 520/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7891\n",
      "Epoch 521/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7786\n",
      "Epoch 522/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7852\n",
      "Epoch 523/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7865\n",
      "Epoch 524/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7734\n",
      "Epoch 525/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7604\n",
      "Epoch 526/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7956\n",
      "Epoch 527/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7643\n",
      "Epoch 528/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7839\n",
      "Epoch 529/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7852\n",
      "Epoch 530/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7812\n",
      "Epoch 531/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7565\n",
      "Epoch 532/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7839\n",
      "Epoch 533/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7786\n",
      "Epoch 534/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7891\n",
      "Epoch 535/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7826\n",
      "Epoch 536/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7852\n",
      "Epoch 537/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7760\n",
      "Epoch 538/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7773\n",
      "Epoch 539/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7839\n",
      "Epoch 540/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7826\n",
      "Epoch 541/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7812\n",
      "Epoch 542/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7852\n",
      "Epoch 543/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7760\n",
      "Epoch 544/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7812\n",
      "Epoch 545/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7669\n",
      "Epoch 546/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7799\n",
      "Epoch 547/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7878\n",
      "Epoch 548/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7891\n",
      "Epoch 549/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7708\n",
      "Epoch 550/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7891\n",
      "Epoch 551/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7695\n",
      "Epoch 552/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7773\n",
      "Epoch 553/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7852\n",
      "Epoch 554/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7773\n",
      "Epoch 555/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7708\n",
      "Epoch 556/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7839\n",
      "Epoch 557/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7917\n",
      "Epoch 558/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7826\n",
      "Epoch 559/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7734\n",
      "Epoch 560/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7760\n",
      "Epoch 561/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7617\n",
      "Epoch 562/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7734\n",
      "Epoch 563/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7878\n",
      "Epoch 564/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7812\n",
      "Epoch 565/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7721\n",
      "Epoch 566/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7826\n",
      "Epoch 567/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7786\n",
      "Epoch 568/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7799\n",
      "Epoch 569/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7956\n",
      "Epoch 570/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7721\n",
      "Epoch 571/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7826\n",
      "Epoch 572/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7799\n",
      "Epoch 573/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7786\n",
      "Epoch 574/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7812\n",
      "Epoch 575/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7747\n",
      "Epoch 576/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7852\n",
      "Epoch 577/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7721\n",
      "Epoch 578/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7865\n",
      "Epoch 579/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7826\n",
      "Epoch 580/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7773\n",
      "Epoch 581/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7799\n",
      "Epoch 582/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7799\n",
      "Epoch 583/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7721\n",
      "Epoch 584/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7826\n",
      "Epoch 585/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7826\n",
      "Epoch 586/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7839\n",
      "Epoch 587/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7760\n",
      "Epoch 588/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7721\n",
      "Epoch 589/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7943\n",
      "Epoch 590/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7799\n",
      "Epoch 591/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7760\n",
      "Epoch 592/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7799\n",
      "Epoch 593/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7760\n",
      "Epoch 594/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7812\n",
      "Epoch 595/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7930\n",
      "Epoch 596/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7721\n",
      "Epoch 597/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7826\n",
      "Epoch 598/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7852\n",
      "Epoch 599/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7812\n",
      "Epoch 600/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7773\n",
      "Epoch 601/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7773\n",
      "Epoch 602/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7917\n",
      "Epoch 603/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7826\n",
      "Epoch 604/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7878\n",
      "Epoch 605/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7773\n",
      "Epoch 606/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7773\n",
      "Epoch 607/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7695\n",
      "Epoch 608/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7799\n",
      "Epoch 609/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7839\n",
      "Epoch 610/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7826\n",
      "Epoch 611/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7799\n",
      "Epoch 612/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7839\n",
      "Epoch 613/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7682\n",
      "Epoch 614/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7891\n",
      "Epoch 615/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7773\n",
      "Epoch 616/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7956\n",
      "Epoch 617/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7760\n",
      "Epoch 618/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.7760\n",
      "Epoch 619/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7721\n",
      "Epoch 620/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7760\n",
      "Epoch 621/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7747\n",
      "Epoch 622/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7786\n",
      "Epoch 623/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7773\n",
      "Epoch 624/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7734\n",
      "Epoch 625/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7799\n",
      "Epoch 626/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.7917\n",
      "Epoch 627/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7865\n",
      "Epoch 628/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7956\n",
      "Epoch 629/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7799\n",
      "Epoch 630/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7786\n",
      "Epoch 631/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7799\n",
      "Epoch 632/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7904\n",
      "Epoch 633/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7669\n",
      "Epoch 634/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7917\n",
      "Epoch 635/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7878\n",
      "Epoch 636/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7956\n",
      "Epoch 637/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7669\n",
      "Epoch 638/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7865\n",
      "Epoch 639/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7773\n",
      "Epoch 640/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7682\n",
      "Epoch 641/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7799\n",
      "Epoch 642/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7747\n",
      "Epoch 643/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7930\n",
      "Epoch 644/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7865\n",
      "Epoch 645/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7865\n",
      "Epoch 646/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7773\n",
      "Epoch 647/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4523 - accuracy: 0.7760\n",
      "Epoch 648/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7904\n",
      "Epoch 649/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7852\n",
      "Epoch 650/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7917\n",
      "Epoch 651/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7747\n",
      "Epoch 652/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7826\n",
      "Epoch 653/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7865\n",
      "Epoch 654/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7865\n",
      "Epoch 655/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7904\n",
      "Epoch 656/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7812\n",
      "Epoch 657/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7904\n",
      "Epoch 658/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7786\n",
      "Epoch 659/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7812\n",
      "Epoch 660/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7826\n",
      "Epoch 661/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7799\n",
      "Epoch 662/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7708\n",
      "Epoch 663/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7812\n",
      "Epoch 664/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7917\n",
      "Epoch 665/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7852\n",
      "Epoch 666/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7747\n",
      "Epoch 667/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7917\n",
      "Epoch 668/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7812\n",
      "Epoch 669/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7747\n",
      "Epoch 670/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7747\n",
      "Epoch 671/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7852\n",
      "Epoch 672/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7852\n",
      "Epoch 673/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7904\n",
      "Epoch 674/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7826\n",
      "Epoch 675/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7878\n",
      "Epoch 676/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7852\n",
      "Epoch 677/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7878\n",
      "Epoch 678/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7891\n",
      "Epoch 679/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7812\n",
      "Epoch 680/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7852\n",
      "Epoch 681/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7839\n",
      "Epoch 682/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7721\n",
      "Epoch 683/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7695\n",
      "Epoch 684/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7773\n",
      "Epoch 685/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7917\n",
      "Epoch 686/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7865\n",
      "Epoch 687/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7734\n",
      "Epoch 688/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7747\n",
      "Epoch 689/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7812\n",
      "Epoch 690/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7852\n",
      "Epoch 691/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7786\n",
      "Epoch 692/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7878\n",
      "Epoch 693/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7799\n",
      "Epoch 694/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7760\n",
      "Epoch 695/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7878\n",
      "Epoch 696/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7799\n",
      "Epoch 697/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7786\n",
      "Epoch 698/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7839\n",
      "Epoch 699/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7852\n",
      "Epoch 700/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7839\n",
      "Epoch 701/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7839\n",
      "Epoch 702/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7799\n",
      "Epoch 703/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7734\n",
      "Epoch 704/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7839\n",
      "Epoch 705/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7773\n",
      "Epoch 706/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7773\n",
      "Epoch 707/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7839\n",
      "Epoch 708/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7917\n",
      "Epoch 709/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7826\n",
      "Epoch 710/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7878\n",
      "Epoch 711/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7904\n",
      "Epoch 712/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7865\n",
      "Epoch 713/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7852\n",
      "Epoch 714/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7747\n",
      "Epoch 715/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7865\n",
      "Epoch 716/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7852\n",
      "Epoch 717/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7839\n",
      "Epoch 718/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7786\n",
      "Epoch 719/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7852\n",
      "Epoch 720/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7826\n",
      "Epoch 721/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7969\n",
      "Epoch 722/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7982\n",
      "Epoch 723/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7799\n",
      "Epoch 724/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7839\n",
      "Epoch 725/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7956\n",
      "Epoch 726/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7760\n",
      "Epoch 727/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7799\n",
      "Epoch 728/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7773\n",
      "Epoch 729/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7747\n",
      "Epoch 730/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7617\n",
      "Epoch 731/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7917\n",
      "Epoch 732/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7773\n",
      "Epoch 733/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7357\n",
      "Epoch 734/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7773\n",
      "Epoch 735/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7826\n",
      "Epoch 736/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7917\n",
      "Epoch 737/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7878\n",
      "Epoch 738/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7904\n",
      "Epoch 739/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7826\n",
      "Epoch 740/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4409 - accuracy: 0.7799\n",
      "Epoch 741/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7878\n",
      "Epoch 742/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4463 - accuracy: 0.7839\n",
      "Epoch 743/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7826\n",
      "Epoch 744/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.7786\n",
      "Epoch 745/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7917\n",
      "Epoch 746/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7839\n",
      "Epoch 747/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7865\n",
      "Epoch 748/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.7865\n",
      "Epoch 749/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7812\n",
      "Epoch 750/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.7773\n",
      "Epoch 751/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7878\n",
      "Epoch 752/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7891\n",
      "Epoch 753/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7799\n",
      "Epoch 754/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4482 - accuracy: 0.7760\n",
      "Epoch 755/1500\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.4380 - accuracy: 0.7852\n",
      "Epoch 756/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4341 - accuracy: 0.7865\n",
      "Epoch 757/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.7995\n",
      "Epoch 758/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4344 - accuracy: 0.7852\n",
      "Epoch 759/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7904\n",
      "Epoch 760/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7799\n",
      "Epoch 761/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7930\n",
      "Epoch 762/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7995\n",
      "Epoch 763/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7930\n",
      "Epoch 764/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7773\n",
      "Epoch 765/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7786\n",
      "Epoch 766/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7773\n",
      "Epoch 767/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7826\n",
      "Epoch 768/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7891\n",
      "Epoch 769/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7904\n",
      "Epoch 770/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7852\n",
      "Epoch 771/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7878\n",
      "Epoch 772/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7799\n",
      "Epoch 773/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7865\n",
      "Epoch 774/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7865\n",
      "Epoch 775/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7812\n",
      "Epoch 776/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812\n",
      "Epoch 777/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7812\n",
      "Epoch 778/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7891\n",
      "Epoch 779/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4312 - accuracy: 0.8008\n",
      "Epoch 780/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.7799\n",
      "Epoch 781/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7878\n",
      "Epoch 782/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7799\n",
      "Epoch 783/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7760\n",
      "Epoch 784/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7826\n",
      "Epoch 785/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7904\n",
      "Epoch 786/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7669\n",
      "Epoch 787/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7747\n",
      "Epoch 788/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7852\n",
      "Epoch 789/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7839\n",
      "Epoch 790/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7747\n",
      "Epoch 791/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7826\n",
      "Epoch 792/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4358 - accuracy: 0.7865\n",
      "Epoch 793/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7721\n",
      "Epoch 794/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7891\n",
      "Epoch 795/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7917\n",
      "Epoch 796/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.7839\n",
      "Epoch 797/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7812\n",
      "Epoch 798/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.7852\n",
      "Epoch 799/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7852\n",
      "Epoch 800/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4476 - accuracy: 0.7826\n",
      "Epoch 801/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7773\n",
      "Epoch 802/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7852\n",
      "Epoch 803/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7786\n",
      "Epoch 804/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7826\n",
      "Epoch 805/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7852\n",
      "Epoch 806/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7956\n",
      "Epoch 807/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7878\n",
      "Epoch 808/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7891\n",
      "Epoch 809/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7904\n",
      "Epoch 810/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7839\n",
      "Epoch 811/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7799\n",
      "Epoch 812/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.7917\n",
      "Epoch 813/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.7904\n",
      "Epoch 814/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4543 - accuracy: 0.7669\n",
      "Epoch 815/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4374 - accuracy: 0.7812\n",
      "Epoch 816/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4330 - accuracy: 0.7943\n",
      "Epoch 817/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4350 - accuracy: 0.7930\n",
      "Epoch 818/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7995\n",
      "Epoch 819/1500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.4308 - accuracy: 0.7891\n",
      "Epoch 820/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4381 - accuracy: 0.7786\n",
      "Epoch 821/1500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.4503 - accuracy: 0.7773\n",
      "Epoch 822/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.7969\n",
      "Epoch 823/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7826\n",
      "Epoch 824/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.7904\n",
      "Epoch 825/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.7904\n",
      "Epoch 826/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7930\n",
      "Epoch 827/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.7839\n",
      "Epoch 828/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7904\n",
      "Epoch 829/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7878\n",
      "Epoch 830/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7865\n",
      "Epoch 831/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7865\n",
      "Epoch 832/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7943\n",
      "Epoch 833/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7969\n",
      "Epoch 834/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7812\n",
      "Epoch 835/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7839\n",
      "Epoch 836/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7839\n",
      "Epoch 837/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7917\n",
      "Epoch 838/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7891\n",
      "Epoch 839/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4385 - accuracy: 0.7865\n",
      "Epoch 840/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.7878\n",
      "Epoch 841/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.7878\n",
      "Epoch 842/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.7943\n",
      "Epoch 843/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.7812\n",
      "Epoch 844/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7852\n",
      "Epoch 845/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.7904\n",
      "Epoch 846/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7943\n",
      "Epoch 847/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7878\n",
      "Epoch 848/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.7799\n",
      "Epoch 849/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7852\n",
      "Epoch 850/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7839\n",
      "Epoch 851/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7943\n",
      "Epoch 852/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7826\n",
      "Epoch 853/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7917\n",
      "Epoch 854/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7904\n",
      "Epoch 855/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7943\n",
      "Epoch 856/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7891\n",
      "Epoch 857/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7917\n",
      "Epoch 858/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4351 - accuracy: 0.7878\n",
      "Epoch 859/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.7826\n",
      "Epoch 860/1500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4405 - accuracy: 0.7917\n",
      "Epoch 861/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4339 - accuracy: 0.7891\n",
      "Epoch 862/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4460 - accuracy: 0.7917\n",
      "Epoch 863/1500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.4323 - accuracy: 0.7943\n",
      "Epoch 864/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4344 - accuracy: 0.7904\n",
      "Epoch 865/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4357 - accuracy: 0.7865\n",
      "Epoch 866/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7904\n",
      "Epoch 867/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7943\n",
      "Epoch 868/1500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4324 - accuracy: 0.7826\n",
      "Epoch 869/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4447 - accuracy: 0.7826\n",
      "Epoch 870/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4325 - accuracy: 0.7891\n",
      "Epoch 871/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7891\n",
      "Epoch 872/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7943\n",
      "Epoch 873/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4445 - accuracy: 0.7878\n",
      "Epoch 874/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7826\n",
      "Epoch 875/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.7812\n",
      "Epoch 876/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4319 - accuracy: 0.7930\n",
      "Epoch 877/1500\n",
      "77/77 [==============================] - 1s 6ms/step - loss: 0.4355 - accuracy: 0.7930\n",
      "Epoch 878/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7878\n",
      "Epoch 879/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7917\n",
      "Epoch 880/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7891\n",
      "Epoch 881/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7969\n",
      "Epoch 882/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7904\n",
      "Epoch 883/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7865\n",
      "Epoch 884/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7812\n",
      "Epoch 885/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7878\n",
      "Epoch 886/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7852\n",
      "Epoch 887/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7930\n",
      "Epoch 888/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4464 - accuracy: 0.7747\n",
      "Epoch 889/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.8047\n",
      "Epoch 890/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4289 - accuracy: 0.8034\n",
      "Epoch 891/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4376 - accuracy: 0.7891\n",
      "Epoch 892/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7930\n",
      "Epoch 893/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7826\n",
      "Epoch 894/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7943\n",
      "Epoch 895/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7969\n",
      "Epoch 896/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7812\n",
      "Epoch 897/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7943\n",
      "Epoch 898/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7904\n",
      "Epoch 899/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7865\n",
      "Epoch 900/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8021\n",
      "Epoch 901/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7891\n",
      "Epoch 902/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7865\n",
      "Epoch 903/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7930\n",
      "Epoch 904/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7878\n",
      "Epoch 905/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7917\n",
      "Epoch 906/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7917\n",
      "Epoch 907/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7852\n",
      "Epoch 908/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7995\n",
      "Epoch 909/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7982\n",
      "Epoch 910/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7969\n",
      "Epoch 911/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.7943\n",
      "Epoch 912/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.7812\n",
      "Epoch 913/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4296 - accuracy: 0.7865\n",
      "Epoch 914/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7956\n",
      "Epoch 915/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8047\n",
      "Epoch 916/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7917\n",
      "Epoch 917/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7839\n",
      "Epoch 918/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7930\n",
      "Epoch 919/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7852\n",
      "Epoch 920/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7930\n",
      "Epoch 921/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7891\n",
      "Epoch 922/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4347 - accuracy: 0.7956\n",
      "Epoch 923/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8008\n",
      "Epoch 924/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.7904\n",
      "Epoch 925/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7852\n",
      "Epoch 926/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7878\n",
      "Epoch 927/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8073\n",
      "Epoch 928/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7995\n",
      "Epoch 929/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7904\n",
      "Epoch 930/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8021\n",
      "Epoch 931/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8073\n",
      "Epoch 932/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7917\n",
      "Epoch 933/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8073\n",
      "Epoch 934/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7865\n",
      "Epoch 935/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7943\n",
      "Epoch 936/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7852\n",
      "Epoch 937/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7891\n",
      "Epoch 938/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4287 - accuracy: 0.7995\n",
      "Epoch 939/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7695\n",
      "Epoch 940/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7826\n",
      "Epoch 941/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7865\n",
      "Epoch 942/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7852\n",
      "Epoch 943/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7943\n",
      "Epoch 944/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7904\n",
      "Epoch 945/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7878\n",
      "Epoch 946/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7956\n",
      "Epoch 947/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7708\n",
      "Epoch 948/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7891\n",
      "Epoch 949/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7904\n",
      "Epoch 950/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7852\n",
      "Epoch 951/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7852\n",
      "Epoch 952/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7982\n",
      "Epoch 953/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7917\n",
      "Epoch 954/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.7956\n",
      "Epoch 955/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7917\n",
      "Epoch 956/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.7930\n",
      "Epoch 957/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.7943\n",
      "Epoch 958/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7721\n",
      "Epoch 959/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7995\n",
      "Epoch 960/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7982\n",
      "Epoch 961/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4298 - accuracy: 0.7995\n",
      "Epoch 962/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7995\n",
      "Epoch 963/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7917\n",
      "Epoch 964/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.7812\n",
      "Epoch 965/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7930\n",
      "Epoch 966/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7969\n",
      "Epoch 967/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7917\n",
      "Epoch 968/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7917\n",
      "Epoch 969/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7943\n",
      "Epoch 970/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8047\n",
      "Epoch 971/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.7995\n",
      "Epoch 972/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4257 - accuracy: 0.7995\n",
      "Epoch 973/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4319 - accuracy: 0.7917\n",
      "Epoch 974/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7917\n",
      "Epoch 975/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8060\n",
      "Epoch 976/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7904\n",
      "Epoch 977/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7891\n",
      "Epoch 978/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8060\n",
      "Epoch 979/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7956\n",
      "Epoch 980/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8034\n",
      "Epoch 981/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8034\n",
      "Epoch 982/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8099\n",
      "Epoch 983/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7995\n",
      "Epoch 984/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7956\n",
      "Epoch 985/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.7878\n",
      "Epoch 986/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8047\n",
      "Epoch 987/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7930\n",
      "Epoch 988/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7930\n",
      "Epoch 989/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8021\n",
      "Epoch 990/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8021\n",
      "Epoch 991/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8008\n",
      "Epoch 992/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7930\n",
      "Epoch 993/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7995\n",
      "Epoch 994/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7891\n",
      "Epoch 995/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8086\n",
      "Epoch 996/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7956\n",
      "Epoch 997/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7878\n",
      "Epoch 998/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7773\n",
      "Epoch 999/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7904\n",
      "Epoch 1000/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7930\n",
      "Epoch 1001/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7930\n",
      "Epoch 1002/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969\n",
      "Epoch 1003/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7956\n",
      "Epoch 1004/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8021\n",
      "Epoch 1005/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8021\n",
      "Epoch 1006/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8138\n",
      "Epoch 1007/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8008\n",
      "Epoch 1008/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8073\n",
      "Epoch 1009/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7969\n",
      "Epoch 1010/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7956\n",
      "Epoch 1011/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7943\n",
      "Epoch 1012/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7839\n",
      "Epoch 1013/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7891\n",
      "Epoch 1014/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7956\n",
      "Epoch 1015/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7982\n",
      "Epoch 1016/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7969\n",
      "Epoch 1017/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7982\n",
      "Epoch 1018/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8073\n",
      "Epoch 1019/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7956\n",
      "Epoch 1020/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8021\n",
      "Epoch 1021/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7982\n",
      "Epoch 1022/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7930\n",
      "Epoch 1023/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7891\n",
      "Epoch 1024/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7995\n",
      "Epoch 1025/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7878\n",
      "Epoch 1026/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7943\n",
      "Epoch 1027/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8086\n",
      "Epoch 1028/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7995\n",
      "Epoch 1029/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7969\n",
      "Epoch 1030/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8060\n",
      "Epoch 1031/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8060\n",
      "Epoch 1032/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7943\n",
      "Epoch 1033/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7982\n",
      "Epoch 1034/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7917\n",
      "Epoch 1035/1500\n",
      "77/77 [==============================] - 1s 6ms/step - loss: 0.4141 - accuracy: 0.8047\n",
      "Epoch 1036/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7826\n",
      "Epoch 1037/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7930\n",
      "Epoch 1038/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7956\n",
      "Epoch 1039/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8047\n",
      "Epoch 1040/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7904\n",
      "Epoch 1041/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7995\n",
      "Epoch 1042/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8112\n",
      "Epoch 1043/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7969\n",
      "Epoch 1044/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7995\n",
      "Epoch 1045/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8021\n",
      "Epoch 1046/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7930\n",
      "Epoch 1047/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8021\n",
      "Epoch 1048/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7917\n",
      "Epoch 1049/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8034\n",
      "Epoch 1050/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8086\n",
      "Epoch 1051/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7917\n",
      "Epoch 1052/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7995\n",
      "Epoch 1053/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7852\n",
      "Epoch 1054/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7786\n",
      "Epoch 1055/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7839\n",
      "Epoch 1056/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7956\n",
      "Epoch 1057/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7995\n",
      "Epoch 1058/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7943\n",
      "Epoch 1059/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7891\n",
      "Epoch 1060/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7917\n",
      "Epoch 1061/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7930\n",
      "Epoch 1062/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7982\n",
      "Epoch 1063/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8060\n",
      "Epoch 1064/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7943\n",
      "Epoch 1065/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8021\n",
      "Epoch 1066/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8008\n",
      "Epoch 1067/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8021\n",
      "Epoch 1068/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8151\n",
      "Epoch 1069/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7956\n",
      "Epoch 1070/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7969\n",
      "Epoch 1071/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8138\n",
      "Epoch 1072/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8047\n",
      "Epoch 1073/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7930\n",
      "Epoch 1074/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8112\n",
      "Epoch 1075/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8034\n",
      "Epoch 1076/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8034\n",
      "Epoch 1077/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8034\n",
      "Epoch 1078/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8047\n",
      "Epoch 1079/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7982\n",
      "Epoch 1080/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7786\n",
      "Epoch 1081/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7995\n",
      "Epoch 1082/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7826\n",
      "Epoch 1083/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7995\n",
      "Epoch 1084/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7839\n",
      "Epoch 1085/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8034\n",
      "Epoch 1086/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8021\n",
      "Epoch 1087/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7891\n",
      "Epoch 1088/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8047\n",
      "Epoch 1089/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8021\n",
      "Epoch 1090/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8047\n",
      "Epoch 1091/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8073\n",
      "Epoch 1092/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8008\n",
      "Epoch 1093/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7982\n",
      "Epoch 1094/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8086\n",
      "Epoch 1095/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7969\n",
      "Epoch 1096/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7904\n",
      "Epoch 1097/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8060\n",
      "Epoch 1098/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7930\n",
      "Epoch 1099/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8034\n",
      "Epoch 1100/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7982\n",
      "Epoch 1101/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8086\n",
      "Epoch 1102/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7878\n",
      "Epoch 1103/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8060\n",
      "Epoch 1104/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8047\n",
      "Epoch 1105/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7760\n",
      "Epoch 1106/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8073\n",
      "Epoch 1107/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8073\n",
      "Epoch 1108/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8073\n",
      "Epoch 1109/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8008\n",
      "Epoch 1110/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8034\n",
      "Epoch 1111/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7995\n",
      "Epoch 1112/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8008\n",
      "Epoch 1113/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8047\n",
      "Epoch 1114/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969\n",
      "Epoch 1115/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7969\n",
      "Epoch 1116/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8099\n",
      "Epoch 1117/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7969\n",
      "Epoch 1118/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8073\n",
      "Epoch 1119/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7917\n",
      "Epoch 1120/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7930\n",
      "Epoch 1121/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8034\n",
      "Epoch 1122/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8008\n",
      "Epoch 1123/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8034\n",
      "Epoch 1124/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7969\n",
      "Epoch 1125/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7930\n",
      "Epoch 1126/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8047\n",
      "Epoch 1127/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7995\n",
      "Epoch 1128/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8008\n",
      "Epoch 1129/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8073\n",
      "Epoch 1130/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8034\n",
      "Epoch 1131/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8047\n",
      "Epoch 1132/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8047\n",
      "Epoch 1133/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8073\n",
      "Epoch 1134/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8112\n",
      "Epoch 1135/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.7995\n",
      "Epoch 1136/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8164\n",
      "Epoch 1137/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8060\n",
      "Epoch 1138/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.7930\n",
      "Epoch 1139/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8008\n",
      "Epoch 1140/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8086\n",
      "Epoch 1141/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7982\n",
      "Epoch 1142/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8073\n",
      "Epoch 1143/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8086\n",
      "Epoch 1144/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8008\n",
      "Epoch 1145/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8086\n",
      "Epoch 1146/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8034\n",
      "Epoch 1147/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7930\n",
      "Epoch 1148/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8086\n",
      "Epoch 1149/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8008\n",
      "Epoch 1150/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7930\n",
      "Epoch 1151/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7982\n",
      "Epoch 1152/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8060\n",
      "Epoch 1153/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7917\n",
      "Epoch 1154/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8060\n",
      "Epoch 1155/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8073\n",
      "Epoch 1156/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8047\n",
      "Epoch 1157/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7969\n",
      "Epoch 1158/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8034\n",
      "Epoch 1159/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7982\n",
      "Epoch 1160/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8047\n",
      "Epoch 1161/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7982\n",
      "Epoch 1162/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8164\n",
      "Epoch 1163/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8047\n",
      "Epoch 1164/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8060\n",
      "Epoch 1165/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7956\n",
      "Epoch 1166/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7982\n",
      "Epoch 1167/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8086\n",
      "Epoch 1168/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8164\n",
      "Epoch 1169/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8021\n",
      "Epoch 1170/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8021\n",
      "Epoch 1171/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8099\n",
      "Epoch 1172/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8073\n",
      "Epoch 1173/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7943\n",
      "Epoch 1174/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7995\n",
      "Epoch 1175/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8060\n",
      "Epoch 1176/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8099\n",
      "Epoch 1177/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7943\n",
      "Epoch 1178/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8112\n",
      "Epoch 1179/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.7969\n",
      "Epoch 1180/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8021\n",
      "Epoch 1181/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7930\n",
      "Epoch 1182/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7917\n",
      "Epoch 1183/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8047\n",
      "Epoch 1184/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8073\n",
      "Epoch 1185/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8021\n",
      "Epoch 1186/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8125\n",
      "Epoch 1187/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8164\n",
      "Epoch 1188/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7956\n",
      "Epoch 1189/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8073\n",
      "Epoch 1190/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8086\n",
      "Epoch 1191/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8138\n",
      "Epoch 1192/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7982\n",
      "Epoch 1193/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8073\n",
      "Epoch 1194/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8021\n",
      "Epoch 1195/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8060\n",
      "Epoch 1196/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8060\n",
      "Epoch 1197/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8034\n",
      "Epoch 1198/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8034\n",
      "Epoch 1199/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8086\n",
      "Epoch 1200/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7982\n",
      "Epoch 1201/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8047\n",
      "Epoch 1202/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8008\n",
      "Epoch 1203/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8008\n",
      "Epoch 1204/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8047\n",
      "Epoch 1205/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7995\n",
      "Epoch 1206/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8060\n",
      "Epoch 1207/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8060\n",
      "Epoch 1208/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8047\n",
      "Epoch 1209/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8151\n",
      "Epoch 1210/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8047\n",
      "Epoch 1211/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7982\n",
      "Epoch 1212/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7982\n",
      "Epoch 1213/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7917\n",
      "Epoch 1214/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8073\n",
      "Epoch 1215/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7982\n",
      "Epoch 1216/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8112\n",
      "Epoch 1217/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8125\n",
      "Epoch 1218/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8034\n",
      "Epoch 1219/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8034\n",
      "Epoch 1220/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7917\n",
      "Epoch 1221/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7995\n",
      "Epoch 1222/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7956\n",
      "Epoch 1223/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8073\n",
      "Epoch 1224/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8060\n",
      "Epoch 1225/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7930\n",
      "Epoch 1226/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7930\n",
      "Epoch 1227/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7995\n",
      "Epoch 1228/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7930\n",
      "Epoch 1229/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8112\n",
      "Epoch 1230/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8099\n",
      "Epoch 1231/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7982\n",
      "Epoch 1232/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8021\n",
      "Epoch 1233/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8021\n",
      "Epoch 1234/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8060\n",
      "Epoch 1235/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.7969\n",
      "Epoch 1236/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8099\n",
      "Epoch 1237/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8047\n",
      "Epoch 1238/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7930\n",
      "Epoch 1239/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7930\n",
      "Epoch 1240/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8008\n",
      "Epoch 1241/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8060\n",
      "Epoch 1242/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8021\n",
      "Epoch 1243/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8112\n",
      "Epoch 1244/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8203\n",
      "Epoch 1245/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8151\n",
      "Epoch 1246/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7995\n",
      "Epoch 1247/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8060\n",
      "Epoch 1248/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8125\n",
      "Epoch 1249/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8125\n",
      "Epoch 1250/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7943\n",
      "Epoch 1251/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7852\n",
      "Epoch 1252/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7995\n",
      "Epoch 1253/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7956\n",
      "Epoch 1254/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8086\n",
      "Epoch 1255/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8216\n",
      "Epoch 1256/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8125\n",
      "Epoch 1257/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7982\n",
      "Epoch 1258/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8086\n",
      "Epoch 1259/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8164\n",
      "Epoch 1260/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8047\n",
      "Epoch 1261/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8112\n",
      "Epoch 1262/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7995\n",
      "Epoch 1263/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8047\n",
      "Epoch 1264/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8086\n",
      "Epoch 1265/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8060\n",
      "Epoch 1266/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8151\n",
      "Epoch 1267/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8099\n",
      "Epoch 1268/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8125\n",
      "Epoch 1269/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8060\n",
      "Epoch 1270/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8151\n",
      "Epoch 1271/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8164\n",
      "Epoch 1272/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8112\n",
      "Epoch 1273/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7995\n",
      "Epoch 1274/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8112\n",
      "Epoch 1275/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8138\n",
      "Epoch 1276/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8008\n",
      "Epoch 1277/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8021\n",
      "Epoch 1278/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7969\n",
      "Epoch 1279/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8073\n",
      "Epoch 1280/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8021\n",
      "Epoch 1281/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7956\n",
      "Epoch 1282/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7943\n",
      "Epoch 1283/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8073\n",
      "Epoch 1284/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.7995\n",
      "Epoch 1285/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7995\n",
      "Epoch 1286/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8125\n",
      "Epoch 1287/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8060\n",
      "Epoch 1288/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8073\n",
      "Epoch 1289/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8086\n",
      "Epoch 1290/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8008\n",
      "Epoch 1291/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8125\n",
      "Epoch 1292/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8047\n",
      "Epoch 1293/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8073\n",
      "Epoch 1294/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7995\n",
      "Epoch 1295/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8008\n",
      "Epoch 1296/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8151\n",
      "Epoch 1297/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8112\n",
      "Epoch 1298/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8177\n",
      "Epoch 1299/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8112\n",
      "Epoch 1300/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8112\n",
      "Epoch 1301/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8112\n",
      "Epoch 1302/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8151\n",
      "Epoch 1303/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8125\n",
      "Epoch 1304/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8073\n",
      "Epoch 1305/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8073\n",
      "Epoch 1306/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8177\n",
      "Epoch 1307/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8047\n",
      "Epoch 1308/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8034\n",
      "Epoch 1309/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.7956\n",
      "Epoch 1310/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8216\n",
      "Epoch 1311/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8099\n",
      "Epoch 1312/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8177\n",
      "Epoch 1313/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8034\n",
      "Epoch 1314/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.7969\n",
      "Epoch 1315/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8047\n",
      "Epoch 1316/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8021\n",
      "Epoch 1317/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8073\n",
      "Epoch 1318/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8255\n",
      "Epoch 1319/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7956\n",
      "Epoch 1320/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8164\n",
      "Epoch 1321/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8047\n",
      "Epoch 1322/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8086\n",
      "Epoch 1323/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8073\n",
      "Epoch 1324/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8177\n",
      "Epoch 1325/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8060\n",
      "Epoch 1326/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8099\n",
      "Epoch 1327/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8086\n",
      "Epoch 1328/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7956\n",
      "Epoch 1329/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8086\n",
      "Epoch 1330/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8060\n",
      "Epoch 1331/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8008\n",
      "Epoch 1332/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8112\n",
      "Epoch 1333/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8073\n",
      "Epoch 1334/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7930\n",
      "Epoch 1335/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8073\n",
      "Epoch 1336/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8034\n",
      "Epoch 1337/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8125\n",
      "Epoch 1338/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8060\n",
      "Epoch 1339/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.7982\n",
      "Epoch 1340/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8086\n",
      "Epoch 1341/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8060\n",
      "Epoch 1342/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8034\n",
      "Epoch 1343/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7982\n",
      "Epoch 1344/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8086\n",
      "Epoch 1345/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8047\n",
      "Epoch 1346/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8099\n",
      "Epoch 1347/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8034\n",
      "Epoch 1348/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8138\n",
      "Epoch 1349/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8151\n",
      "Epoch 1350/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8099\n",
      "Epoch 1351/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8099\n",
      "Epoch 1352/1500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8203\n",
      "Epoch 1353/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8099\n",
      "Epoch 1354/1500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8125\n",
      "Epoch 1355/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8060\n",
      "Epoch 1356/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8060\n",
      "Epoch 1357/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8086\n",
      "Epoch 1358/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8125\n",
      "Epoch 1359/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7904\n",
      "Epoch 1360/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4097 - accuracy: 0.8021\n",
      "Epoch 1361/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8125\n",
      "Epoch 1362/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.7982\n",
      "Epoch 1363/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4228 - accuracy: 0.8060\n",
      "Epoch 1364/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8034\n",
      "Epoch 1365/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8164\n",
      "Epoch 1366/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8099\n",
      "Epoch 1367/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8190\n",
      "Epoch 1368/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8112\n",
      "Epoch 1369/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8177\n",
      "Epoch 1370/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8086\n",
      "Epoch 1371/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8060\n",
      "Epoch 1372/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8112\n",
      "Epoch 1373/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8112\n",
      "Epoch 1374/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7904\n",
      "Epoch 1375/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.7982\n",
      "Epoch 1376/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7878\n",
      "Epoch 1377/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8099\n",
      "Epoch 1378/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8073\n",
      "Epoch 1379/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8073\n",
      "Epoch 1380/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8112\n",
      "Epoch 1381/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8073\n",
      "Epoch 1382/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8047\n",
      "Epoch 1383/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8229\n",
      "Epoch 1384/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8008\n",
      "Epoch 1385/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8099\n",
      "Epoch 1386/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8086\n",
      "Epoch 1387/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8073\n",
      "Epoch 1388/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8177\n",
      "Epoch 1389/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8060\n",
      "Epoch 1390/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8008\n",
      "Epoch 1391/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8021\n",
      "Epoch 1392/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8151\n",
      "Epoch 1393/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8099\n",
      "Epoch 1394/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8112\n",
      "Epoch 1395/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7839\n",
      "Epoch 1396/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8112\n",
      "Epoch 1397/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8047\n",
      "Epoch 1398/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8099\n",
      "Epoch 1399/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8047\n",
      "Epoch 1400/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8190\n",
      "Epoch 1401/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8008\n",
      "Epoch 1402/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8203\n",
      "Epoch 1403/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7982\n",
      "Epoch 1404/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.4058 - accuracy: 0.8125\n",
      "Epoch 1405/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8034\n",
      "Epoch 1406/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8177\n",
      "Epoch 1407/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8099\n",
      "Epoch 1408/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.7995\n",
      "Epoch 1409/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.7995\n",
      "Epoch 1410/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8073\n",
      "Epoch 1411/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8112\n",
      "Epoch 1412/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8099\n",
      "Epoch 1413/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8125\n",
      "Epoch 1414/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8151\n",
      "Epoch 1415/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8138\n",
      "Epoch 1416/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8125\n",
      "Epoch 1417/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7969\n",
      "Epoch 1418/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8086\n",
      "Epoch 1419/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8151\n",
      "Epoch 1420/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8177\n",
      "Epoch 1421/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8138\n",
      "Epoch 1422/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8177\n",
      "Epoch 1423/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8190\n",
      "Epoch 1424/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8255\n",
      "Epoch 1425/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8242\n",
      "Epoch 1426/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8177\n",
      "Epoch 1427/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8112\n",
      "Epoch 1428/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8112\n",
      "Epoch 1429/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8060\n",
      "Epoch 1430/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8138\n",
      "Epoch 1431/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8099\n",
      "Epoch 1432/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8203\n",
      "Epoch 1433/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8138\n",
      "Epoch 1434/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8203\n",
      "Epoch 1435/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8216\n",
      "Epoch 1436/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8112\n",
      "Epoch 1437/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8021\n",
      "Epoch 1438/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8034\n",
      "Epoch 1439/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8177\n",
      "Epoch 1440/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8125\n",
      "Epoch 1441/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8008\n",
      "Epoch 1442/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8138\n",
      "Epoch 1443/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8164\n",
      "Epoch 1444/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8125\n",
      "Epoch 1445/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8073\n",
      "Epoch 1446/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7930\n",
      "Epoch 1447/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8268\n",
      "Epoch 1448/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8229\n",
      "Epoch 1449/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8190\n",
      "Epoch 1450/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8112\n",
      "Epoch 1451/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8177\n",
      "Epoch 1452/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8164\n",
      "Epoch 1453/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8190\n",
      "Epoch 1454/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8164\n",
      "Epoch 1455/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8151\n",
      "Epoch 1456/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8034\n",
      "Epoch 1457/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8112\n",
      "Epoch 1458/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8060\n",
      "Epoch 1459/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8099\n",
      "Epoch 1460/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8008\n",
      "Epoch 1461/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8190\n",
      "Epoch 1462/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8125\n",
      "Epoch 1463/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8099\n",
      "Epoch 1464/1500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4145 - accuracy: 0.8073\n",
      "Epoch 1465/1500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4140 - accuracy: 0.8034\n",
      "Epoch 1466/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4196 - accuracy: 0.8047\n",
      "Epoch 1467/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4063 - accuracy: 0.8086\n",
      "Epoch 1468/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.4017 - accuracy: 0.8034\n",
      "Epoch 1469/1500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.4056 - accuracy: 0.8008\n",
      "Epoch 1470/1500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4113 - accuracy: 0.8177\n",
      "Epoch 1471/1500\n",
      "77/77 [==============================] - 1s 6ms/step - loss: 0.3908 - accuracy: 0.8190\n",
      "Epoch 1472/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4019 - accuracy: 0.8190\n",
      "Epoch 1473/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8255\n",
      "Epoch 1474/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4010 - accuracy: 0.8151\n",
      "Epoch 1475/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.3939 - accuracy: 0.8138\n",
      "Epoch 1476/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8112\n",
      "Epoch 1477/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8125\n",
      "Epoch 1478/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.3960 - accuracy: 0.8112\n",
      "Epoch 1479/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.3953 - accuracy: 0.8255\n",
      "Epoch 1480/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8216\n",
      "Epoch 1481/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8073\n",
      "Epoch 1482/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8138\n",
      "Epoch 1483/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8112\n",
      "Epoch 1484/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8099\n",
      "Epoch 1485/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7865\n",
      "Epoch 1486/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4045 - accuracy: 0.8216\n",
      "Epoch 1487/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4041 - accuracy: 0.8086\n",
      "Epoch 1488/1500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.3970 - accuracy: 0.8099\n",
      "Epoch 1489/1500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.3974 - accuracy: 0.8125\n",
      "Epoch 1490/1500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4042 - accuracy: 0.8190\n",
      "Epoch 1491/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.3988 - accuracy: 0.8151\n",
      "Epoch 1492/1500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8112\n",
      "Epoch 1493/1500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.4037 - accuracy: 0.8060\n",
      "Epoch 1494/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7943\n",
      "Epoch 1495/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8060\n",
      "Epoch 1496/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8047\n",
      "Epoch 1497/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8047\n",
      "Epoch 1498/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.7995\n",
      "Epoch 1499/1500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8138\n",
      "Epoch 1500/1500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20891a50070>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=1500,batch_size=10,verbose=1) #nöronlar araası gidip gelme işlemine epoch diyoruz. kaç def gidip geleceğini belirtiyoruz.\n",
    "#batch_size -> derin öğrenmede veriler çok fazla olduğu için bir seferde 10 veriyi alıyoruz\n",
    "#verbose -> bazen makineler 1 hafta çalışıyor, acaba tıkandı mı ram hatası mı verdi, çalışışyor mu dondur mu vbilmediğimiz için verbose=1 yazıyoruz bunu sonucu görmek istiyoruz. \n",
    "#her seferinde rakamları yazsın diye kaçıncı epoch'da gibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20653711-9c60-4265-8320-a83ddd469f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147e2b70-c112-4600-95a1-78b1c1d0f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step - loss: 0.3931 - accuracy: 0.8229\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80c6d28-326f-4f57-ae23-cc38bcde785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39310720562934875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0] # hata - loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1106d347-d408-4335-85d4-47aebc7fcf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8229166865348816"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] # başarı -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7deb675f-b7d2-47bb-81c5-eff782bf6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping # örneğin 150 doğru sayısı olmayabilir, eğer geriye düşmeye başlamışsa durmamız gerektiğiniz anlıyoruz. accuraacy ile val_accuracy'inin neredeyse eşitlendiği yer bizim aslında durmamız için yeterli epochs sayısı oluyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5603d9f1-76af-44ae-9f9f-b73c230793b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4046 - accuracy: 0.8176 - val_loss: 0.4172 - val_accuracy: 0.7662\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4112 - accuracy: 0.8127 - val_loss: 0.3748 - val_accuracy: 0.8182\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8143 - val_loss: 0.3922 - val_accuracy: 0.8182\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8046 - val_loss: 0.3892 - val_accuracy: 0.7987\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8094 - val_loss: 0.3902 - val_accuracy: 0.7987\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8111 - val_loss: 0.3690 - val_accuracy: 0.8442\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8241 - val_loss: 0.4105 - val_accuracy: 0.7792\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8046 - val_loss: 0.3838 - val_accuracy: 0.8182\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8143 - val_loss: 0.3885 - val_accuracy: 0.7987\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8143 - val_loss: 0.3876 - val_accuracy: 0.8312\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8029 - val_loss: 0.3797 - val_accuracy: 0.8506\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7997 - val_loss: 0.4070 - val_accuracy: 0.8182\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.8143 - val_loss: 0.3825 - val_accuracy: 0.8117\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3945 - accuracy: 0.8176 - val_loss: 0.4208 - val_accuracy: 0.7857\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4001 - accuracy: 0.8127 - val_loss: 0.4149 - val_accuracy: 0.8117\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 2s 36ms/step - loss: 0.4132 - accuracy: 0.8078 - val_loss: 0.3946 - val_accuracy: 0.8247\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.3819 - val_accuracy: 0.7922\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4110 - accuracy: 0.8143 - val_loss: 0.3823 - val_accuracy: 0.8117\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.4157 - accuracy: 0.8046 - val_loss: 0.3875 - val_accuracy: 0.8182\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 0.4181 - accuracy: 0.8046 - val_loss: 0.4038 - val_accuracy: 0.8052\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.3835 - val_accuracy: 0.8182\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4050 - accuracy: 0.8176 - val_loss: 0.3861 - val_accuracy: 0.7922\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3957 - accuracy: 0.8160 - val_loss: 0.3907 - val_accuracy: 0.7922\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8160 - val_loss: 0.3773 - val_accuracy: 0.8312\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8111 - val_loss: 0.3988 - val_accuracy: 0.8052\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8176 - val_loss: 0.4093 - val_accuracy: 0.7987\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8257 - val_loss: 0.3795 - val_accuracy: 0.8312\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8160 - val_loss: 0.3826 - val_accuracy: 0.8247\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8192 - val_loss: 0.4067 - val_accuracy: 0.7857\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8225 - val_loss: 0.4205 - val_accuracy: 0.7727\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8143 - val_loss: 0.4239 - val_accuracy: 0.7727\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8274 - val_loss: 0.4297 - val_accuracy: 0.7922\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8078 - val_loss: 0.3877 - val_accuracy: 0.8052\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8225 - val_loss: 0.3869 - val_accuracy: 0.8182\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8176 - val_loss: 0.3994 - val_accuracy: 0.7987\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3966 - accuracy: 0.8111 - val_loss: 0.4142 - val_accuracy: 0.7857\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4052 - accuracy: 0.8127 - val_loss: 0.3886 - val_accuracy: 0.7987\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8127 - val_loss: 0.4223 - val_accuracy: 0.7857\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8078 - val_loss: 0.4055 - val_accuracy: 0.8117\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8241 - val_loss: 0.4052 - val_accuracy: 0.8117\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8192 - val_loss: 0.4595 - val_accuracy: 0.7597\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4043 - accuracy: 0.8160 - val_loss: 0.4222 - val_accuracy: 0.8117\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8192 - val_loss: 0.4331 - val_accuracy: 0.7662\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4020 - accuracy: 0.8241 - val_loss: 0.4326 - val_accuracy: 0.8052\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7948 - val_loss: 0.4036 - val_accuracy: 0.7922\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4027 - accuracy: 0.8062 - val_loss: 0.4012 - val_accuracy: 0.7987\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3984 - accuracy: 0.8192 - val_loss: 0.3815 - val_accuracy: 0.8247\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3977 - accuracy: 0.8160 - val_loss: 0.4302 - val_accuracy: 0.7857\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4110 - accuracy: 0.8160 - val_loss: 0.4147 - val_accuracy: 0.7857\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8257 - val_loss: 0.4431 - val_accuracy: 0.7857\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4190 - accuracy: 0.8111 - val_loss: 0.5394 - val_accuracy: 0.7273\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4154 - accuracy: 0.8160 - val_loss: 0.4389 - val_accuracy: 0.8052\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4114 - accuracy: 0.8176 - val_loss: 0.4473 - val_accuracy: 0.7662\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4126 - accuracy: 0.8176 - val_loss: 0.4624 - val_accuracy: 0.7662\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.8046 - val_loss: 0.4030 - val_accuracy: 0.8182\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8143 - val_loss: 0.4085 - val_accuracy: 0.7922\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8127 - val_loss: 0.4159 - val_accuracy: 0.8182\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8078 - val_loss: 0.4451 - val_accuracy: 0.7857\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8062 - val_loss: 0.4419 - val_accuracy: 0.7857\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8078 - val_loss: 0.4084 - val_accuracy: 0.8052\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8127 - val_loss: 0.4146 - val_accuracy: 0.7922\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8176 - val_loss: 0.4423 - val_accuracy: 0.7662\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8078 - val_loss: 0.4198 - val_accuracy: 0.7857\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8078 - val_loss: 0.4188 - val_accuracy: 0.7987\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8111 - val_loss: 0.4176 - val_accuracy: 0.7987\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8257 - val_loss: 0.4702 - val_accuracy: 0.7468\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8143 - val_loss: 0.4535 - val_accuracy: 0.7857\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8143 - val_loss: 0.4037 - val_accuracy: 0.7987\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8143 - val_loss: 0.4474 - val_accuracy: 0.7922\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8176 - val_loss: 0.4560 - val_accuracy: 0.7727\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8143 - val_loss: 0.4315 - val_accuracy: 0.7792\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7932 - val_loss: 0.4156 - val_accuracy: 0.7922\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8062 - val_loss: 0.4156 - val_accuracy: 0.7922\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8160 - val_loss: 0.4337 - val_accuracy: 0.7857\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8192 - val_loss: 0.4171 - val_accuracy: 0.7987\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8241 - val_loss: 0.4344 - val_accuracy: 0.7727\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8225 - val_loss: 0.4390 - val_accuracy: 0.8117\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8111 - val_loss: 0.4350 - val_accuracy: 0.7922\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8257 - val_loss: 0.4161 - val_accuracy: 0.7857\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8208 - val_loss: 0.4127 - val_accuracy: 0.7987\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8160 - val_loss: 0.4380 - val_accuracy: 0.7857\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8111 - val_loss: 0.4256 - val_accuracy: 0.8052\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.4343 - val_accuracy: 0.7597\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8127 - val_loss: 0.4308 - val_accuracy: 0.7987\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8208 - val_loss: 0.4126 - val_accuracy: 0.8247\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8143 - val_loss: 0.4602 - val_accuracy: 0.7727\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8111 - val_loss: 0.4193 - val_accuracy: 0.7857\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8176 - val_loss: 0.4274 - val_accuracy: 0.7922\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8192 - val_loss: 0.4436 - val_accuracy: 0.7922\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8160 - val_loss: 0.4464 - val_accuracy: 0.7922\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8241 - val_loss: 0.4653 - val_accuracy: 0.7857\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8143 - val_loss: 0.4346 - val_accuracy: 0.8182\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8241 - val_loss: 0.4607 - val_accuracy: 0.7792\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8274 - val_loss: 0.4625 - val_accuracy: 0.7987\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8225 - val_loss: 0.4545 - val_accuracy: 0.7857\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8127 - val_loss: 0.4559 - val_accuracy: 0.7922\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8111 - val_loss: 0.4680 - val_accuracy: 0.7922\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8111 - val_loss: 0.4844 - val_accuracy: 0.7727\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.4465 - val_accuracy: 0.8247\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8094 - val_loss: 0.5137 - val_accuracy: 0.7792\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8208 - val_loss: 0.4730 - val_accuracy: 0.8117\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8111 - val_loss: 0.4627 - val_accuracy: 0.7987\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8225 - val_loss: 0.4742 - val_accuracy: 0.7857\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8062 - val_loss: 0.4589 - val_accuracy: 0.8052\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8078 - val_loss: 0.4674 - val_accuracy: 0.7922\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8029 - val_loss: 0.4793 - val_accuracy: 0.7857\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8094 - val_loss: 0.4740 - val_accuracy: 0.7792\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8208 - val_loss: 0.5067 - val_accuracy: 0.7857\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8029 - val_loss: 0.4492 - val_accuracy: 0.7922\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8046 - val_loss: 0.4456 - val_accuracy: 0.8052\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8078 - val_loss: 0.5002 - val_accuracy: 0.7792\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8225 - val_loss: 0.4752 - val_accuracy: 0.7987\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8127 - val_loss: 0.4737 - val_accuracy: 0.7857\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8013 - val_loss: 0.5380 - val_accuracy: 0.7468\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8094 - val_loss: 0.4541 - val_accuracy: 0.7922\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8046 - val_loss: 0.4560 - val_accuracy: 0.7987\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8160 - val_loss: 0.4473 - val_accuracy: 0.8247\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8062 - val_loss: 0.5070 - val_accuracy: 0.7597\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8127 - val_loss: 0.4973 - val_accuracy: 0.7727\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8078 - val_loss: 0.4730 - val_accuracy: 0.7792\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8111 - val_loss: 0.4649 - val_accuracy: 0.7922\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8094 - val_loss: 0.4892 - val_accuracy: 0.7792\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8062 - val_loss: 0.4754 - val_accuracy: 0.7727\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8143 - val_loss: 0.4551 - val_accuracy: 0.8117\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8160 - val_loss: 0.4908 - val_accuracy: 0.7727\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.8013 - val_loss: 0.4848 - val_accuracy: 0.7727\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8111 - val_loss: 0.4777 - val_accuracy: 0.7792\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8192 - val_loss: 0.4825 - val_accuracy: 0.7922\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4122 - accuracy: 0.8127 - val_loss: 0.5378 - val_accuracy: 0.7338\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4007 - accuracy: 0.8241 - val_loss: 0.4878 - val_accuracy: 0.7727\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4144 - accuracy: 0.8062 - val_loss: 0.4794 - val_accuracy: 0.7792\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4175 - accuracy: 0.7964 - val_loss: 0.4715 - val_accuracy: 0.7987\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4119 - accuracy: 0.8094 - val_loss: 0.4880 - val_accuracy: 0.7662\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4038 - accuracy: 0.8111 - val_loss: 0.4767 - val_accuracy: 0.7857\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 0.4116 - accuracy: 0.8029 - val_loss: 0.5049 - val_accuracy: 0.7857\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3977 - accuracy: 0.8225 - val_loss: 0.4983 - val_accuracy: 0.7597\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4065 - accuracy: 0.8078 - val_loss: 0.4819 - val_accuracy: 0.7987\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4051 - accuracy: 0.8062 - val_loss: 0.4883 - val_accuracy: 0.7727\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8111 - val_loss: 0.4825 - val_accuracy: 0.7727\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7980 - val_loss: 0.4941 - val_accuracy: 0.7922\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8127 - val_loss: 0.4736 - val_accuracy: 0.8117\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4110 - accuracy: 0.8111 - val_loss: 0.4784 - val_accuracy: 0.7727\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8160 - val_loss: 0.5026 - val_accuracy: 0.7792\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8078 - val_loss: 0.5096 - val_accuracy: 0.7727\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8029 - val_loss: 0.5133 - val_accuracy: 0.7597\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.7997 - val_loss: 0.4864 - val_accuracy: 0.7792\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8029 - val_loss: 0.4898 - val_accuracy: 0.7662\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8127 - val_loss: 0.4875 - val_accuracy: 0.7857\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4108 - accuracy: 0.8046 - val_loss: 0.4664 - val_accuracy: 0.7922\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4043 - accuracy: 0.8160 - val_loss: 0.4813 - val_accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=150,validation_split=0.20,batch_size=10,verbose=1) # %20 test için %80 eğitim için kullan diyoruz. \n",
    "#derste hoca ---19--- olarak güncelledi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ea7f93e-de01-4190-87ab-145e866ee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e3b7a4-dbe4-47dd-99e8-1db126782e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20897d40a00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#validation_split ile ayırdığımız veri, val_accuracy test verisi\n",
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"ValAccuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f31c21c5-b03f-4902-a0a9-3a9d88eb0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resimle çalışıyorsanız giriş ve çıkışın aynı olması lazım.\n",
    "# belirli bir hiyerarşi var, aralarda kaç layer olmasıyla ilgili. pub.towardai.net sitesinde bunula ilgili bir makale var. \n",
    "#https://pub.towardsai.net/main-types-of-neural-networks-and-its-applications-tutorial-734480d7ec8e    #hangi durumda ne kadar nöron koymamız gerektiğiyle ilgili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5741374f-07d6-4625-ac0a-473b8eec2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer sayısını arttırmak nöron sayısını arttırmak  başarı sonucunu arttırır ama bilgisayarınızın kaldırabilmesi lazım."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426726d-b489-4123-8a16-b13691913995",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2272f7bf-d446-4126-9f22-0d13c652104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100) #kolonları görebilmek için 100'e çıkardık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b59febac-187d-4e16-8d1c-da95bff97517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"kc_house.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2e37ebd-eb55-4f2b-a1f6-22da13d4ea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>price</th>\n",
       "      <th>zipcode_98002</th>\n",
       "      <th>zipcode_98003</th>\n",
       "      <th>zipcode_98004</th>\n",
       "      <th>zipcode_98005</th>\n",
       "      <th>zipcode_98006</th>\n",
       "      <th>zipcode_98007</th>\n",
       "      <th>zipcode_98008</th>\n",
       "      <th>zipcode_98010</th>\n",
       "      <th>zipcode_98011</th>\n",
       "      <th>zipcode_98014</th>\n",
       "      <th>zipcode_98019</th>\n",
       "      <th>zipcode_98022</th>\n",
       "      <th>zipcode_98023</th>\n",
       "      <th>zipcode_98024</th>\n",
       "      <th>zipcode_98027</th>\n",
       "      <th>zipcode_98028</th>\n",
       "      <th>zipcode_98029</th>\n",
       "      <th>zipcode_98030</th>\n",
       "      <th>zipcode_98031</th>\n",
       "      <th>zipcode_98032</th>\n",
       "      <th>zipcode_98033</th>\n",
       "      <th>zipcode_98034</th>\n",
       "      <th>zipcode_98038</th>\n",
       "      <th>zipcode_98039</th>\n",
       "      <th>zipcode_98040</th>\n",
       "      <th>zipcode_98042</th>\n",
       "      <th>zipcode_98045</th>\n",
       "      <th>zipcode_98052</th>\n",
       "      <th>zipcode_98053</th>\n",
       "      <th>zipcode_98055</th>\n",
       "      <th>zipcode_98056</th>\n",
       "      <th>zipcode_98058</th>\n",
       "      <th>zipcode_98059</th>\n",
       "      <th>zipcode_98065</th>\n",
       "      <th>zipcode_98070</th>\n",
       "      <th>zipcode_98072</th>\n",
       "      <th>zipcode_98074</th>\n",
       "      <th>zipcode_98075</th>\n",
       "      <th>zipcode_98077</th>\n",
       "      <th>zipcode_98092</th>\n",
       "      <th>zipcode_98102</th>\n",
       "      <th>zipcode_98103</th>\n",
       "      <th>zipcode_98105</th>\n",
       "      <th>zipcode_98106</th>\n",
       "      <th>zipcode_98107</th>\n",
       "      <th>zipcode_98108</th>\n",
       "      <th>zipcode_98109</th>\n",
       "      <th>zipcode_98112</th>\n",
       "      <th>zipcode_98115</th>\n",
       "      <th>zipcode_98116</th>\n",
       "      <th>zipcode_98117</th>\n",
       "      <th>zipcode_98118</th>\n",
       "      <th>zipcode_98119</th>\n",
       "      <th>zipcode_98122</th>\n",
       "      <th>zipcode_98125</th>\n",
       "      <th>zipcode_98126</th>\n",
       "      <th>zipcode_98133</th>\n",
       "      <th>zipcode_98136</th>\n",
       "      <th>zipcode_98144</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1180</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2170</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1050</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  condition  sqft_above     price  zipcode_98002  \\\n",
       "0     1.0   65          0          3        1180  221900.0              0   \n",
       "1     2.0   69          1          3        2170  538000.0              0   \n",
       "2     1.0   87          0          3         770  180000.0              0   \n",
       "3     1.0   55          0          5        1050  604000.0              0   \n",
       "4     1.0   33          0          3        1680  510000.0              0   \n",
       "\n",
       "   zipcode_98003  zipcode_98004  zipcode_98005  zipcode_98006  zipcode_98007  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98008  zipcode_98010  zipcode_98011  zipcode_98014  zipcode_98019  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98022  zipcode_98023  zipcode_98024  zipcode_98027  zipcode_98028  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              1   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98029  zipcode_98030  zipcode_98031  zipcode_98032  zipcode_98033  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98034  zipcode_98038  zipcode_98039  zipcode_98040  zipcode_98042  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98045  zipcode_98052  zipcode_98053  zipcode_98055  zipcode_98056  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98058  zipcode_98059  zipcode_98065  zipcode_98070  zipcode_98072  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98074  zipcode_98075  zipcode_98077  zipcode_98092  zipcode_98102  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   zipcode_98103  zipcode_98105  zipcode_98106  zipcode_98107  zipcode_98108  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98109  zipcode_98112  zipcode_98115  zipcode_98116  zipcode_98117  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98118  zipcode_98119  zipcode_98122  zipcode_98125  zipcode_98126  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98133  zipcode_98136  zipcode_98144  zipcode_98146  zipcode_98148  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  \\\n",
       "0              0              0              0              0              1   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be53eef0-0335-4835-9136-35255bc1731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        221900.0\n",
       "1        538000.0\n",
       "2        180000.0\n",
       "3        604000.0\n",
       "4        510000.0\n",
       "           ...   \n",
       "21608    360000.0\n",
       "21609    400000.0\n",
       "21610    402101.0\n",
       "21611    400000.0\n",
       "21612    325000.0\n",
       "Name: price, Length: 19034, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05f5c3a5-aca6-4b1a-8117-1a689849e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"price\",axis=1) #price'ı kaldır\n",
    "y=df[[\"price\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7c7cd45-f1b1-43b9-9f76-6ea5ab50537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dccea3bb-7cc2-4c46-8a96-01c9eefede10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(81,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(42,activation=\"relu\"))\n",
    "model.add(Dense(21,activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8130057-d18c-4d15-bf6f-7147d30e89b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "119/119 [==============================] - 2s 6ms/step - loss: 190515527680.0000 - val_loss: 40021094400.0000\n",
      "Epoch 2/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 32852402176.0000 - val_loss: 34112989184.0000\n",
      "Epoch 3/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 32153493504.0000 - val_loss: 33580740608.0000\n",
      "Epoch 4/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31710636032.0000 - val_loss: 32744656896.0000\n",
      "Epoch 5/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 31067174912.0000 - val_loss: 32155326464.0000\n",
      "Epoch 6/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 30424238080.0000 - val_loss: 31724640256.0000\n",
      "Epoch 7/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 29771689984.0000 - val_loss: 30751049728.0000\n",
      "Epoch 8/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 29159737344.0000 - val_loss: 30313906176.0000\n",
      "Epoch 9/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 28650227712.0000 - val_loss: 29703245824.0000\n",
      "Epoch 10/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 28290080768.0000 - val_loss: 29494206464.0000\n",
      "Epoch 11/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 28034334720.0000 - val_loss: 29273020416.0000\n",
      "Epoch 12/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 27889553408.0000 - val_loss: 29171709952.0000\n",
      "Epoch 13/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 27938197504.0000 - val_loss: 29284888576.0000\n",
      "Epoch 14/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 27699683328.0000 - val_loss: 29495408640.0000\n",
      "Epoch 15/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27624841216.0000 - val_loss: 30236147712.0000\n",
      "Epoch 16/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27538208768.0000 - val_loss: 29499820032.0000\n",
      "Epoch 17/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27591616512.0000 - val_loss: 29345648640.0000\n",
      "Epoch 18/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27387455488.0000 - val_loss: 29556846592.0000\n",
      "Epoch 19/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27303260160.0000 - val_loss: 29510307840.0000\n",
      "Epoch 20/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27292491776.0000 - val_loss: 29541068800.0000\n",
      "Epoch 21/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27230148608.0000 - val_loss: 29211926528.0000\n",
      "Epoch 22/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27140642816.0000 - val_loss: 30065985536.0000\n",
      "Epoch 23/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27110447104.0000 - val_loss: 29002659840.0000\n",
      "Epoch 24/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26997217280.0000 - val_loss: 28720349184.0000\n",
      "Epoch 25/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 26878255104.0000 - val_loss: 28565428224.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208a294f580>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,validation_split=0.20, batch_size=128,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26061b2d-cd0a-40f8-a466-e8b0f5632cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history) # dataframe dönüştürdük ki hataları görebilelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7404595-3e3f-4779-a2de-571e50c47ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEDCAYAAAAyZm/jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg+0lEQVR4nO3de5gcdb3n8fe3L3PLzCQxVyBAgIOCkAO4A8pREH1WRB4lXg6GiAqsmF3k4u3hEa9wEB99zK6edUUw60bQ5ZIclGPOiiDniAZX5ckkJ5AAGtkIOAGSSUKuc+nbd/+o6pmeSc9Mz0zP9EzV5/U8/VTVr6qrfzWdfOrXv676tbk7IiISH4laV0BERCaXgl9EJGYU/CIiMaPgFxGJGQW/iEjMKPhFRGJmyga/ma02s11mtrWCbc83s01mljOzvx+07mEz22dm/2fiaisiMn1M2eAH7gIuqnDbF4ErgXvLrFsJfKQ6VRIRmf6mbPC7+3pgb2mZmZ0UtuA3mtnjZnZKuO3z7v4UUCizn38DDk5KpUVEpoFUrSswSquA/+LufzazNwLfA95e4zqJiEwr0yb4zawZ+Dvgn8ysWFxfuxqJiExP0yb4Cbql9rn7mbWuiIjIdDZl+/gHc/cDwF/M7FIAC5xR42qJiEw7NlVH5zSz+4ALgLnATuBm4FfAHcBRQBq4391vNbOzgQeB2UAP8Iq7nxbu53HgFKAZ2AN8zN0fmdyjERGZOqZs8IuIyMSYNl09IiJSHVPyy925c+f64sWLa10NEZFpY+PGjbvdfV4l207J4F+8eDHt7e21roaIyLRhZi9Uuq26ekREYkbBLyISMwp+EZGYmZJ9/CISP9lslo6ODnp6empdlSmtoaGBRYsWkU6nx7wPBb+ITAkdHR20tLSwePFiSsbjkhLuzp49e+jo6OCEE04Y837U1SMiU0JPTw9z5sxR6A/DzJgzZ864PxUp+EVkylDoj6waf6PIBL+7851/+zO/2dZZ66qIiExpkQl+M2PV+u38+k+7al0VEZmmmpuba12FSRGZ4AeY2Zhmf3e21tUQEZnSIhX8rY1pDij4RWSc3J0bb7yR008/nSVLlrBmzRoAXn75Zc4//3zOPPNMTj/9dB5//HHy+TxXXnll37bf/va3a1z7kUXqcs6ZjSm1+EUi4B/+5WmeeelAVff5+qNbufk9p1W07U9/+lM2b97Mk08+ye7duzn77LM5//zzuffee3nnO9/JF7/4RfL5PF1dXWzevJkdO3awdetWAPbt21fVek+ESLX41dUjItXw29/+luXLl5NMJlmwYAFvfetb2bBhA2effTY//OEPueWWW9iyZQstLS2ceOKJbN++neuvv56HH36Y1tbWWld/RBFr8Sv4RaKg0pb5ZDv//PNZv349P//5z7nyyiv5zGc+w0c/+lGefPJJHnnkEe68807Wrl3L6tWra13VYUWqxT+rqU7BLyLjdt5557FmzRry+TydnZ2sX7+ec845hxdeeIEFCxbw8Y9/nKuvvppNmzaxe/duCoUCH/jAB7jtttvYtGlTras/osi1+HuyBXpzeepTyVpXR0Smqfe97338/ve/54wzzsDM+OY3v8nChQu5++67WblyJel0mubmZn70ox+xY8cOrrrqKgqFAgBf//rXa1z7kUUq+Fsbg0GL9ndnmd+i4BeR0Tl06BAQ3Be0cuVKVq5cOWD9FVdcwRVXXHHE86ZDK79UpLp6ZobBr0s6RUSGFsngVz+/iMjQFPwiIjGj4BcRiZlIBv++LgW/iMhQIhX8rQ3BRUpq8YuIDC1SwZ9KJmiu13g9IiLDGTH4zWy1me0ys61DrL/RzDaHj61mljez14TrnjezLeG69mpXvhwN2yAik2G4sfuff/55Tj/99EmszehU0uK/C7hoqJXuvtLdz3T3M4HPA79x970lm7wtXN82rppWSEMzi4gMb8Q7d919vZktrnB/y4H7xlWjcdLQzCIR8Iub4JUt1d3nwiXwrm8Mufqmm27i2GOP5dprrwXglltuIZVK8dhjj/Hqq6+SzWa57bbbWLp06ahetqenh2uuuYb29nZSqRTf+ta3eNvb3sbTTz/NVVddRSaToVAo8JOf/ISjjz6aD37wg3R0dJDP5/nyl7/MsmXLxnXY5VRtyAYzayL4ZHBdSbEDvzQzB77v7quGef4KYAXAcccdN+Z6zGxM85fdh8f8fBGJp2XLlvGpT32qL/jXrl3LI488wg033EBrayu7d+/mTW96E5dccsmofvD89ttvx8zYsmULf/zjH7nwwgvZtm0bd955J5/85Ce5/PLLyWQy5PN5HnroIY4++mh+/vOfA7B///4JOdZqjtXzHuD/DurmeYu77zCz+cCjZvZHd19f7snhSWEVQFtbm4+1EurjF4mAYVrmE+Wss85i165dvPTSS3R2djJ79mwWLlzIpz/9adavX08ikWDHjh3s3LmThQsXVrzf3/72t1x//fUAnHLKKRx//PFs27aNc889l6997Wt0dHTw/ve/n5NPPpklS5bw2c9+ls997nO8+93v5rzzzpuQY63mVT2XMaibx913hNNdwIPAOVV8vbIU/CIyVpdeeikPPPAAa9asYdmyZdxzzz10dnayceNGNm/ezIIFC+jp6anKa33oQx9i3bp1NDY2cvHFF/OrX/2K1772tWzatIklS5bwpS99iVtvvbUqrzVYVYLfzGYCbwV+VlI2w8xaivPAhUDZK4OqqXRoZhGR0Vi2bBn3338/DzzwAJdeein79+9n/vz5pNNpHnvsMV544YVR7/O8887jnnvuAWDbtm28+OKLvO51r2P79u2ceOKJ3HDDDSxdupSnnnqKl156iaamJj784Q9z4403TtionyN29ZjZfcAFwFwz6wBuBtIA7n5nuNn7gF+6e2nn+gLgwbAvLAXc6+4PV6/q5c3U0MwiMkannXYaBw8e5JhjjuGoo47i8ssv5z3veQ9Lliyhra2NU045ZdT7/MQnPsE111zDkiVLSKVS3HXXXdTX17N27Vp+/OMfk06nWbhwIV/4whfYsGEDN954I4lEgnQ6zR133DEBRwnmPubu9AnT1tbm7e1ju+z/Z5t38Mn7N/Ovnzmfv5nfUuWaichEefbZZzn11FNrXY1podzfysw2VnrZfKTu3AUN1CYiMpJI/QIXKPhFZPJs2bKFj3zkIwPK6uvreeKJJ2pUo8oo+EVkynD3UV0jX2tLlixh8+bNk/qa1eiej1xXz6ymOgD2a2hmkWmloaGBPXv2VCXYosrd2bNnDw0NDePaT+Ra/P1DM+dqXBMRGY1FixbR0dFBZ2dnrasypTU0NLBo0aJx7SNywa+hmUWmp3Q6zQknnFDrasRC5Lp6QHfviogMJ5LB36rgFxEZUiSDf2ZjSmPyi4gMIaLBrxa/iMhQIhv8+7ozta6GiMiUFNngV4tfRKS8yAa/hmYWESkvssEPGrZBRKScSAZ/axj8urJHRORIkQx+tfhFRIam4BcRiRkFv4hIzEQ7+DU0s4jIESIZ/K19LX4NzSwiMlgkgz+dTDCjLqmuHhGRMkYMfjNbbWa7zGzrEOsvMLP9ZrY5fHylZN1FZvYnM3vOzG6qZsVHort3RUTKq6TFfxdw0QjbPO7uZ4aPWwHMLAncDrwLeD2w3MxeP57KjoaGZhYRKW/E4Hf39cDeMez7HOA5d9/u7hngfmDpGPYzJjMb07qBS0SkjGr18Z9rZk+a2S/M7LSw7BjgryXbdIRlZZnZCjNrN7P2avzmprp6RETKq0bwbwKOd/czgP8B/PNYduLuq9y9zd3b5s2bN+5KzWpS8IuIlDPu4Hf3A+5+KJx/CEib2VxgB3BsyaaLwrJJoRa/iEh54w5+M1toZhbOnxPucw+wATjZzE4wszrgMmDdeF+vUjMb03Rn82Ryhcl6SRGRaSE10gZmdh9wATDXzDqAm4E0gLvfCfw9cI2Z5YBu4DJ3dyBnZtcBjwBJYLW7Pz0hR1FG6bAN81rqJ+tlRUSmvBGD392Xj7D+u8B3h1j3EPDQ2Ko2Pq0KfhGRsiJ55y5ooDYRkaFEPvh1Lb+IyECRD/593Zka10REZGqJfPBraGYRkYEiG/wamllEpLzIBr+GZhYRKS+ywQ+6e1dEpJxIB7+GZhYROVKkg19DM4uIHCnywa8Wv4jIQAp+EZGYUfCLiMRM5INfQzOLiAwU7eBv0kBtIiKDRTv4NUKniMgRIh38rQp+EZEjRDr4NTSziMiRYhH8avGLiPSLdPDPUvCLiBwh0sGvPn4RkSNFOvg1NLOIyJFGDH4zW21mu8xs6xDrLzezp8xsi5n9zszOKFn3fFi+2czaq1nxSunuXRGRgSpp8d8FXDTM+r8Ab3X3JcBXgVWD1r/N3c9097axVXF8NDSziMhAqZE2cPf1ZrZ4mPW/K1n8A7CoCvWqGrX4RUQGqnYf/8eAX5QsO/BLM9toZiuGe6KZrTCzdjNr7+zsrFqFZjam9YPrIiIlRmzxV8rM3kYQ/G8pKX6Lu+8ws/nAo2b2R3dfX+757r6KsJuora3Nq1UvtfhFRAaqSovfzP4W+AGw1N33FMvdfUc43QU8CJxTjdcbDQW/iMhA4w5+MzsO+CnwEXffVlI+w8xaivPAhUDZK4MmkoZmFhEZaMSuHjO7D7gAmGtmHcDNQBrA3e8EvgLMAb5nZgC58AqeBcCDYVkKuNfdH56AYxhW6dDM81rqJ/vlRUSmnEqu6lk+wvqrgavLlG8HzjjyGZOrdLweBb+ISMTv3AUN2yAiMljkg19DM4uIDBSb4FeLX0QkoOAXEYkZBb+ISMxEPvjTyQRNGppZRKRP5IMfdPeuiEgpBb+ISMzEIvg1Jr+ISL9YBP/MxrSu4xcRCcUi+GepxS8i0icWwa8+fhGRfrEJ/q5MnmxeQzOLiMQj+Jt0E5eISFE8gl9374qI9IlF8GtoZhGRfrEI/r4Wf5eCX0QkXsGvFr+IiIJfRCRuFPwiIjETi+DX0MwiIv0qCn4zW21mu8xs6xDrzcy+Y2bPmdlTZvaGknVXmNmfw8cV1ar4aOnuXRGRQKUt/ruAi4ZZ/y7g5PCxArgDwMxeA9wMvBE4B7jZzGaPtbLjoeAXEQlUFPzuvh7YO8wmS4EfeeAPwCwzOwp4J/Cou+9191eBRxn+BDJhNDSziEigWn38xwB/LVnuCMuGKp90GppZRCQwZb7cNbMVZtZuZu2dnZ1V37+6ekREAtUK/h3AsSXLi8KyocqP4O6r3L3N3dvmzZtXpWr1U/CLiASqFfzrgI+GV/e8Cdjv7i8DjwAXmtns8EvdC8OySaehmUVEAqlKNjKz+4ALgLlm1kFwpU4awN3vBB4CLgaeA7qAq8J1e83sq8CGcFe3uvtwXxJPmNKbuOY219eiCiIiU0JFwe/uy0dY78C1Q6xbDawefdWqS8EvIhKYMl/uTjQN2yAiEohN8GtMfhGRQGyCv9ji17X8IhJ3sQn+WfrdXRERIEbBr1/hEhEJxCb4NTSziEggNsEPuntXRAQU/CIisROr4G9tTLNPwS8iMRer4NfQzCIiMQx+dfWISNwp+EVEYiZ2wa+hmUUk7mIX/KC7d0Uk3hT8IiIxo+AXEYmZWAW/hmYWEYlZ8GtoZhGRmAa/WvwiEmfxDH4NzSwiMRar4K9LJWhMa2hmEYm3WAU/6O5dEZGKgt/MLjKzP5nZc2Z2U5n13zazzeFjm5ntK1mXL1m3rop1HxMFv4jEXWqkDcwsCdwOvAPoADaY2Tp3f6a4jbt/umT764GzSnbR7e5nVq3G46TgF5G4q6TFfw7wnLtvd/cMcD+wdJjtlwP3VaNyE6FVwS8iMVdJ8B8D/LVkuSMsO4KZHQ+cAPyqpLjBzNrN7A9m9t6hXsTMVoTbtXd2dlZQrbGZ1aQx+UUk3qr95e5lwAPuni8pO97d24APAf9oZieVe6K7r3L3NndvmzdvXpWr1U9dPSISd5UE/w7g2JLlRWFZOZcxqJvH3XeE0+3ArxnY/z/pZjamOayhmUUkxioJ/g3AyWZ2gpnVEYT7EVfnmNkpwGzg9yVls82sPpyfC7wZeGbwcyeThm0QkbgbMfjdPQdcBzwCPAusdfenzexWM7ukZNPLgPvd3UvKTgXazexJ4DHgG6VXA9WChm0Qkbgb8XJOAHd/CHhoUNlXBi3fUuZ5vwOWjKN+VVcM/n0KfhGJqdjduauhmUUk7mIX/OrjF5G4i23wq8UvInEV3+DX0MwiElOxC34NzSwicRe74AfdvSsi8abgFxGJGQW/iEjMxDL4NTSziMRZLIN/ZqOGZhaR+Ipt8KvFLyJxFdvg19DMIhJXMQ3+YGw6dfeISBzFM/ibNGyDiMRXPINf4/WISIwp+EVEYiamwV8HKPhFJJ5iGvwak19E4ivWwa8Wv4jEUSyDX0Mzi0icxTL4QXfvikh8VRT8ZnaRmf3JzJ4zs5vKrL/SzDrNbHP4uLpk3RVm9ufwcUU1Kz8eMxvT7NOvcIlIDKVG2sDMksDtwDuADmCDma1z92cGbbrG3a8b9NzXADcDbYADG8PnvlqV2o+DWvwiEleVtPjPAZ5z9+3ungHuB5ZWuP93Ao+6+94w7B8FLhpbVatLQzOLSFxVEvzHAH8tWe4Iywb7gJk9ZWYPmNmxo3wuZrbCzNrNrL2zs7OCao2PhmYWkbiq1pe7/wIsdve/JWjV3z3aHbj7Kndvc/e2efPmValaQ1NXj4jEVSXBvwM4tmR5UVjWx933uHtvuPgD4D9U+txa0dDMIhJXlQT/BuBkMzvBzOqAy4B1pRuY2VEli5cAz4bzjwAXmtlsM5sNXBiW1ZyGZhaRuBrxqh53z5nZdQSBnQRWu/vTZnYr0O7u64AbzOwSIAfsBa4Mn7vXzL5KcPIAuNXd907AcYxa6dDMc5rra1wbEZHJM2LwA7j7Q8BDg8q+UjL/eeDzQzx3NbB6HHWcEBq2QUTiKtZ37oKCX0TiR8Gv4BeRmIlt8LdqaGYRianYBr9a/CISV7EN/vpUkoZ0QsEvIrETneB3h/s+BE+sgnxlYa67d0UkjqIT/L0HIHMIfnEjfO9c+NPDwclgGAp+EYmj6AR/w0z46M9g+Zpg+b5l8KOl8MqWIZ+i4BeROIpO8AOYwesugk/8Ht61El55Cu48D352HRx85YjNg+DP1aCiIiK1E63gL0qm4Y0r4IZ/h3OvhSfvh++8AX6zEjJdfZvNbKzT5ZwiEjvRDP6ixtnwzq/BtU/A37wdHrsNvtsGT66BQkFdPSISS9EO/qI5J8Gy/w1XPgQz5sGDK+AHb+fUzFYO9ebIaWhmEYmRigZpi4zFb4aPPwZb1sK//gOXvvRxZqXfQPaXT5Ca0Qr1LVDXDPXN4bTMcjJd66MQERmXeAU/QCIBZ1wGp17CMz/9Gmc++2MaNjwFhQq/5E3WB1cQNc0JHjPm9M83zR1UFi6nGyb2mERERiF+wV9U18Susz7JxZv/jmQC5jXAwsYc8+uzzKvLMiedZU66l1mpDLMSPbQkemm2HmbQTWP+EHWZfaR795La+SyJ7r3QvRfzIbqM0jOgcVbwiaE+/GTR0FqyXJwfVJ5ugrqmYJpugnQjJJKT+mcSkeiJb/AD5540h1uXnsbOAz3s786yvzvH/u4sW7uzHDiUDcuy5AvD3wgGkE44C9I9LEwfYmHqMPMTh5ibPMQcO8hsDjDTumjOdtOc6aLxwE7q89upzx8inTtMMtc14v77pBqCE0DpyaBuRjCtb4HmBdA8H2bM759vXhB8t5GqG8dfS0SiItbBX59K8tFzFw+7jbtzOJMPTgJdWfZ1ZzjUk6M7m6crk6c7kw/ncwOW/5rJsy3TX36oN8fBnhwHe7IMPo8kyTODblroptm6mZvqZV5dL7Pr8sxOZZmZytGaytCSyNKcyNCUyNBELw300uA91GV7Sfe8SnrviyS7f4317C9/MI2zjzwxNMwc+Kmirin4hJJuHFQelqUagvslRGTainXwV8LMaK5P0Vyf4phZjePeX6HgHM4EJ4EDPVkOdOc40J3lYG/pfI79XVl29mZ5ricoK6470JMlmx/+E0hTIsvihi6OqzvIovRBjkoeYH5iP3PZz+zcq8zcs5fmV7bTmNlDKt89ugOwBNQVu6RaR5jODLutmiGRhmQKknXhfBoSqXBaZl1UTi7uwXAi3a8O8dh3ZFmmKzghN84KTtaVPNKN1f+buUMhD4VsMP5V8XswS4SvZSXTcmXhFA+HT/H+/Q5VBsG/gVT92I+nUICefdC1Bw7vhq7dJdM9QbkXoGVh+Dhq4LRuxthedxpR8E+yRMJoaUjT0pDmaEZ/InF3enOF8CRQPHlkOdgTdFMdHFT2XE+WTcVtwxNHT7b/u4gk+b5PD03WSyMZmuhhdjrLa+ryzE5nmZXK0prK0ZrM0JLoZQY9NHsXTYXDNBw6TMP+F6nLHSKdO0QqcxDzKtwNbcngRNB3gqhgPpEMnmeJcD7R/xiwnOwPKi8E4eb5cFoI58Pp4PWDgzCfDZdzkM/0z/dtM8J9IukZJQE+C+a+NviEVTxZ7N4WTLv2jryvRCp4WLL/71EsSyQHLlsyOKa++mfLH0stpRqCE0DZacm8JYK/UTHcu/YGx1ZOXXNwwYUZHNwJuTINn/rWI08KzQvDq/rqgi7TZH3JtD4sD6el831//+K/z6nRoFHwTzNmRkM6SUM6yfzWse0jkytwsCfbd6IodkEVTxqlZS/25Hi6d2DZ4d6gO6s8p4EMLXTTYl200MWsVC9NSacxWQgfwXxDInwkC9QnCjRYnrpEnnorkLZ88CBHmhwp8qQ8mCbJkfIcSc+RzGZJZnIkvAcjT8IdI4+5Y57HCKa4YxT654uhbkm876SQxIsnhkQCt2RYZuE0CE9LNmH1aRLJOhLJNJZMD3FSCj/NNMwcoqU+KwiISrhDtqv8p4auvZDtDk9OufDkVDotmS/dxhJBHYsB1ffpKz1wvm9dqr8uXmBAq71sWfDvIWj9Q/+ngNL5QWUQnHByvZDrGX7a/WowLeSCv+eck+C4N/ZfUTdjbsnVd8Ur7EoaW+7Qsx8O7YSDLwfDugyevvj74ASR763sfRqJJcqcDEpOyM3zYMWvq/Naw1Dwx1BdKsGc5nrmNFcYOmXkC973/cXh3hyHe/MczuToyuQ41JunqzfH4eK6TI7ebIHeXJ6ubIG92Tw92Ty9uQI92Tw92QI9mTy92eJynmzeyUyTG+sSBqlkgrpkgnTSSCcTpJMJ6lIJUgkjmTDMjISBWY6E7cZsDwmDhBlGOA2XE4nisvVtEzy3dLkZs2YSdlzfuoJ7kL9AIZxxgrLSdR4GcsKCuqaSRioR1H3gfIJ0IpgG5Ra+dliPhGGJcnXsLyvXwLVBhYM3sZL9wZHHzqC/24D1iTL1cCNx2Eh0Z0lYrm+/wa5SmC3CWhdBK2HZwHobTiKzn2T2MKlClkQhQ6KQJVnIkCj0kihkSeQzfeWW78XymfBTU67kk2Ku/+FlygqFSetmqij4zewi4L8DSeAH7v6NQes/A1wN5IBO4D+5+wvhujxQHCLzRXe/pEp1lxpKlnRZTRR3J5t3svkC2XyBTL5AJlfoK8vkgrJsOM0XnII7ubyTLzh5D6cFJ1dwCsVpuE3BHQsDJMyTYDkMjv5y61tfcPrqM7hu2ZyTK4TLuf51BXcKHhxP6bQYxqXTfMHJ5P2IbYvHVtxu4HwwLT159NV90ImFcB6C52TzBXKF4O9RnM/mC+TyxWMZ+Yo2gWAQhIbw0YIZJM1IJIykBSf/hAX/b4oNgb7yRP+2c2fUs3YSajti8JtZErgdeAfQAWwws3Xu/kzJZv8OtLl7l5ldA3wTWBau63b3M6tbbYkDM6MuZdSl4jGyyFTk3n/iLJ40vdB/8hl8Iit3Qhq4vyNe4Yj1xU8lpfvz8NNL6QnT3XGCk6IPUY/iCbNcPftfr2S+7/W9v3Ylrx28VrFhEVysUfCgkVEoOPmSv02x8VFa3l+fYqOEAdu21E9OJ0wlr3IO8Jy7bwcws/uBpUBf8Lv7YyXb/wH4cDUrKSK1YRZ2/+i+wUippCl1DPDXkuWOsGwoHwN+UbLcYGbtZvYHM3vvUE8ysxXhdu2dnZ0VVEtERMaiqp8rzOzDQBvw1pLi4919h5mdCPzKzLa4+/8b/Fx3XwWsAmhra1PHoojIBKmkxb8DOLZkeVFYNoCZ/Ufgi8Al7t537ZO77win24FfA2eNo74iIjJOlQT/BuBkMzvBzOqAy4B1pRuY2VnA9wlCf1dJ+Wwzqw/n5wJvpuS7ARERmXwjdvW4e87MrgMeIbicc7W7P21mtwLt7r4OWAk0A/8UXqNbvGzzVOD7ZlYgOMl8Y9DVQCIiMsmseNnSVNLW1ubt7e21roaIyLRhZhvdva2SbXWBtIhIzCj4RURiZkp29ZhZJ/DCGJ8+F9hdxepMJ3E+doj38evY46t4/Me7+7xKnjAlg388zKy90n6uqInzsUO8j1/HHs9jh7Edv7p6RERiRsEvIhIzUQz+VbWuQA3F+dgh3sevY4+vUR9/5Pr4RURkeFFs8YuIyDAU/CIiMROZ4Dezi8zsT2b2nJndVOv6TDYze97MtpjZZjOL9HgXZrbazHaZ2daSsteY2aNm9udwOruWdZxIQxz/LWa2I3z/N5vZxbWs40Qxs2PN7DEze8bMnjazT4blkX//hzn2Ub/3kejjD38echslPw8JLI/TgHBm9jzBz19G/kYWMzsfOAT8yN1PD8u+Cex192+EJ/7Z7v65WtZzogxx/LcAh9z9v9aybhPNzI4CjnL3TWbWAmwE3gtcScTf/2GO/YOM8r2PSou/7+ch3T0DFH8eUiLI3dcDewcVLwXuDufvJvgPEUlDHH8suPvL7r4pnD8IPEvwi4CRf/+HOfZRi0rwj/bnIaPIgV+a2UYzW1HrytTAAnd/OZx/BVhQy8rUyHVm9lTYFRS5ro7BzGwxwQ87PUHM3v9Bxw6jfO+jEvwCb3H3NwDvAq4NuwNiyYP+y+nfhzk6dwAnAWcCLwP/raa1mWBm1gz8BPiUux8oXRf197/MsY/6vY9K8Ff085BRVvITl7uABwm6v+JkZ9gHWuwL3TXC9pHi7jvdPe/uBeB/EuH338zSBMF3j7v/NCyOxftf7tjH8t5HJfhH/HnIKDOzGeGXPZjZDOBCYOvwz4qcdcAV4fwVwM9qWJdJVwy90PuI6PtvwU/8/S/gWXf/VsmqyL//Qx37WN77SFzVAxBewvSP9P885NdqW6PJY2YnErTyIfg5zXujfPxmdh9wAcFwtDuBm4F/BtYCxxEM6f1Bd4/kF6BDHP8FBB/1HXge+M8lfd6RYWZvAR4HtgCFsPgLBH3dkX7/hzn25YzyvY9M8IuISGWi0tUjIiIVUvCLiMSMgl9EJGYU/CIiMaPgFxGJGQW/iEjMKPhFRGLm/wPyqWVOqz9AFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70276f2d-3b32-4256-92e5-b5625180c6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77671917-886d-495a-bfd0-37fae2d13efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2179e1d8-b35c-4c71-86de-63ec3828a83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.49755300829014004"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y) #r2 0.80 üzeri olması lazım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52a40932-180b-4c1f-a665-7133baaa30d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165395.04346365607"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y))**0.5 # hatanın 100bin altında olması lazım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e48b771d-f4ac-4637-97f3-c16f143281e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "119/119 [==============================] - 2s 7ms/step - loss: 261877219328.0000 - val_loss: 213746532352.0000\n",
      "Epoch 2/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 63320907776.0000 - val_loss: 34179479552.0000\n",
      "Epoch 3/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 32374173696.0000 - val_loss: 33774374912.0000\n",
      "Epoch 4/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 32121583616.0000 - val_loss: 33568432128.0000\n",
      "Epoch 5/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31825487872.0000 - val_loss: 33125984256.0000\n",
      "Epoch 6/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31536857088.0000 - val_loss: 32793708544.0000\n",
      "Epoch 7/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31253168128.0000 - val_loss: 32449845248.0000\n",
      "Epoch 8/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 30961405952.0000 - val_loss: 32226013184.0000\n",
      "Epoch 9/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 30627944448.0000 - val_loss: 31783217152.0000\n",
      "Epoch 10/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 30328387584.0000 - val_loss: 31442792448.0000\n",
      "Epoch 11/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 30034647040.0000 - val_loss: 31404369920.0000\n",
      "Epoch 12/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 29853245440.0000 - val_loss: 30853851136.0000\n",
      "Epoch 13/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 29486018560.0000 - val_loss: 30493087744.0000\n",
      "Epoch 14/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 29267456000.0000 - val_loss: 30223826944.0000\n",
      "Epoch 15/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 29042755584.0000 - val_loss: 30000418816.0000\n",
      "Epoch 16/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 28820736000.0000 - val_loss: 29777813504.0000\n",
      "Epoch 17/25\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 28626561024.0000 - val_loss: 29621649408.0000\n",
      "Epoch 18/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 28449589248.0000 - val_loss: 29836771328.0000\n",
      "Epoch 19/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 28344893440.0000 - val_loss: 29469057024.0000\n",
      "Epoch 20/25\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 28207456256.0000 - val_loss: 29528346624.0000\n",
      "Epoch 21/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28109015040.0000 - val_loss: 29719011328.0000\n",
      "Epoch 22/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28073578496.0000 - val_loss: 29925740544.0000\n",
      "Epoch 23/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27975264256.0000 - val_loss: 29631913984.0000\n",
      "Epoch 24/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27832358912.0000 - val_loss: 29311115264.0000\n",
      "Epoch 25/25\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27810410496.0000 - val_loss: 29455806464.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208a06729a0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verileri değiştiriyoruz\n",
    "model=Sequential()\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")\n",
    "model.fit(x,y,validation_split=0.20, batch_size=128,epochs=25) #uzun sürmesin diye epoch yükseltmedik yoksa 1500 yapsaydık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec567a82-23ea-413b-93f6-359ee40e91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c369a98-344b-4870-86ba-8f890d14071f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27894794240.0000 - val_loss: 28502312960.0000\n",
      "Epoch 2/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27913105408.0000 - val_loss: 28455084032.0000\n",
      "Epoch 3/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27809843200.0000 - val_loss: 28397062144.0000\n",
      "Epoch 4/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27847088128.0000 - val_loss: 28377376768.0000\n",
      "Epoch 5/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27754788864.0000 - val_loss: 28342175744.0000\n",
      "Epoch 6/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27722493952.0000 - val_loss: 28286560256.0000\n",
      "Epoch 7/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27647784960.0000 - val_loss: 28278726656.0000\n",
      "Epoch 8/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27645542400.0000 - val_loss: 28209565696.0000\n",
      "Epoch 9/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 27596986368.0000 - val_loss: 28216764416.0000\n",
      "Epoch 10/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 27555096576.0000 - val_loss: 28137238528.0000\n",
      "Epoch 11/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27520256000.0000 - val_loss: 28100038656.0000\n",
      "Epoch 12/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 27458152448.0000 - val_loss: 28049827840.0000\n",
      "Epoch 13/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 27422208000.0000 - val_loss: 28011505664.0000\n",
      "Epoch 14/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27382126592.0000 - val_loss: 28067815424.0000\n",
      "Epoch 15/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27410659328.0000 - val_loss: 28198144000.0000\n",
      "Epoch 16/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27291213824.0000 - val_loss: 27904274432.0000\n",
      "Epoch 17/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27299307520.0000 - val_loss: 28069511168.0000\n",
      "Epoch 18/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27208026112.0000 - val_loss: 27772192768.0000\n",
      "Epoch 19/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27130892288.0000 - val_loss: 27731277824.0000\n",
      "Epoch 20/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27145928704.0000 - val_loss: 27724558336.0000\n",
      "Epoch 21/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27057870848.0000 - val_loss: 27679473664.0000\n",
      "Epoch 22/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26947092480.0000 - val_loss: 27579428864.0000\n",
      "Epoch 23/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26925715456.0000 - val_loss: 27491444736.0000\n",
      "Epoch 24/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26870061056.0000 - val_loss: 27496740864.0000\n",
      "Epoch 25/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26775724032.0000 - val_loss: 27560796160.0000\n",
      "Epoch 26/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26752935936.0000 - val_loss: 27303641088.0000\n",
      "Epoch 27/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26617446400.0000 - val_loss: 27534454784.0000\n",
      "Epoch 28/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26545895424.0000 - val_loss: 27111813120.0000\n",
      "Epoch 29/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26436040704.0000 - val_loss: 27278473216.0000\n",
      "Epoch 30/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 26327916544.0000 - val_loss: 27120785408.0000\n",
      "Epoch 31/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26230034432.0000 - val_loss: 27058274304.0000\n",
      "Epoch 32/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26117349376.0000 - val_loss: 26684825600.0000\n",
      "Epoch 33/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26041632768.0000 - val_loss: 26719819776.0000\n",
      "Epoch 34/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25912174592.0000 - val_loss: 26407000064.0000\n",
      "Epoch 35/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25749938176.0000 - val_loss: 26249502720.0000\n",
      "Epoch 36/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25582274560.0000 - val_loss: 26084222976.0000\n",
      "Epoch 37/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 25368508416.0000 - val_loss: 25977458688.0000\n",
      "Epoch 38/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 25192912896.0000 - val_loss: 25736593408.0000\n",
      "Epoch 39/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 24975130624.0000 - val_loss: 25544736768.0000\n",
      "Epoch 40/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 24699949056.0000 - val_loss: 25211660288.0000\n",
      "Epoch 41/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 24405979136.0000 - val_loss: 25061949440.0000\n",
      "Epoch 42/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 24223303680.0000 - val_loss: 24780552192.0000\n",
      "Epoch 43/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 23674339328.0000 - val_loss: 24103688192.0000\n",
      "Epoch 44/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 23188404224.0000 - val_loss: 23627081728.0000\n",
      "Epoch 45/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 22698276864.0000 - val_loss: 22996051968.0000\n",
      "Epoch 46/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 22166538240.0000 - val_loss: 22433499136.0000\n",
      "Epoch 47/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 21451419648.0000 - val_loss: 21980069888.0000\n",
      "Epoch 48/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 20858478592.0000 - val_loss: 21600720896.0000\n",
      "Epoch 49/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 20266553344.0000 - val_loss: 21728645120.0000\n",
      "Epoch 50/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 19904430080.0000 - val_loss: 20131194880.0000\n",
      "Epoch 51/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 19285696512.0000 - val_loss: 20066215936.0000\n",
      "Epoch 52/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 18960005120.0000 - val_loss: 19474089984.0000\n",
      "Epoch 53/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 18732197888.0000 - val_loss: 19609673728.0000\n",
      "Epoch 54/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 18305169408.0000 - val_loss: 19043301376.0000\n",
      "Epoch 55/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 18139553792.0000 - val_loss: 19223257088.0000\n",
      "Epoch 56/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17996183552.0000 - val_loss: 18712160256.0000\n",
      "Epoch 57/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17660073984.0000 - val_loss: 18766016512.0000\n",
      "Epoch 58/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17461106688.0000 - val_loss: 18114424832.0000\n",
      "Epoch 59/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 17358510080.0000 - val_loss: 18278213632.0000\n",
      "Epoch 60/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 16877209600.0000 - val_loss: 17752430592.0000\n",
      "Epoch 61/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16755654656.0000 - val_loss: 17702219776.0000\n",
      "Epoch 62/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16532801536.0000 - val_loss: 17784098816.0000\n",
      "Epoch 63/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16223563776.0000 - val_loss: 17114653696.0000\n",
      "Epoch 64/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 16135838720.0000 - val_loss: 16889338880.0000\n",
      "Epoch 65/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15946298368.0000 - val_loss: 17423431680.0000\n",
      "Epoch 66/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 15680056320.0000 - val_loss: 16680567808.0000\n",
      "Epoch 67/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 15454692352.0000 - val_loss: 16231033856.0000\n",
      "Epoch 68/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 15255211008.0000 - val_loss: 16194277376.0000\n",
      "Epoch 69/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 14976876544.0000 - val_loss: 15828627456.0000\n",
      "Epoch 70/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 14809637888.0000 - val_loss: 15613036544.0000\n",
      "Epoch 71/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14747475968.0000 - val_loss: 15780084736.0000\n",
      "Epoch 72/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14505743360.0000 - val_loss: 15241719808.0000\n",
      "Epoch 73/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 14243680256.0000 - val_loss: 15047989248.0000\n",
      "Epoch 74/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 14027143168.0000 - val_loss: 15186641920.0000\n",
      "Epoch 75/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 13802722304.0000 - val_loss: 14743181312.0000\n",
      "Epoch 76/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 13653874688.0000 - val_loss: 14580422656.0000\n",
      "Epoch 77/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13729546240.0000 - val_loss: 14548460544.0000\n",
      "Epoch 78/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13402473472.0000 - val_loss: 14265118720.0000\n",
      "Epoch 79/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13295610880.0000 - val_loss: 14048755712.0000\n",
      "Epoch 80/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 13018820608.0000 - val_loss: 14590087168.0000\n",
      "Epoch 81/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 13054920704.0000 - val_loss: 13806066688.0000\n",
      "Epoch 82/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 12818531328.0000 - val_loss: 13788475392.0000\n",
      "Epoch 83/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 12637101056.0000 - val_loss: 13677568000.0000\n",
      "Epoch 84/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 12552112128.0000 - val_loss: 13624440832.0000\n",
      "Epoch 85/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 12409537536.0000 - val_loss: 13362445312.0000\n",
      "Epoch 86/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 12371480576.0000 - val_loss: 13269753856.0000\n",
      "Epoch 87/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 12475922432.0000 - val_loss: 13302913024.0000\n",
      "Epoch 88/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12246542336.0000 - val_loss: 12976745472.0000\n",
      "Epoch 89/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12039365632.0000 - val_loss: 12896266240.0000\n",
      "Epoch 90/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 12157890560.0000 - val_loss: 12933882880.0000\n",
      "Epoch 91/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 11920857088.0000 - val_loss: 13374861312.0000\n",
      "Epoch 92/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11904662528.0000 - val_loss: 12736000000.0000\n",
      "Epoch 93/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 11736263680.0000 - val_loss: 13521574912.0000\n",
      "Epoch 94/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11749886976.0000 - val_loss: 12648617984.0000\n",
      "Epoch 95/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11549425664.0000 - val_loss: 12443057152.0000\n",
      "Epoch 96/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11508199424.0000 - val_loss: 12334830592.0000\n",
      "Epoch 97/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11436308480.0000 - val_loss: 12255096832.0000\n",
      "Epoch 98/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11346719744.0000 - val_loss: 13238307840.0000\n",
      "Epoch 99/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11507398656.0000 - val_loss: 12202047488.0000\n",
      "Epoch 100/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11464103936.0000 - val_loss: 12129988608.0000\n",
      "Epoch 101/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11218369536.0000 - val_loss: 12040929280.0000\n",
      "Epoch 102/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11226405888.0000 - val_loss: 11977306112.0000\n",
      "Epoch 103/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11084064768.0000 - val_loss: 11944399872.0000\n",
      "Epoch 104/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11049782272.0000 - val_loss: 11838678016.0000\n",
      "Epoch 105/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 11147417600.0000 - val_loss: 11825038336.0000\n",
      "Epoch 106/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11117398016.0000 - val_loss: 11901927424.0000\n",
      "Epoch 107/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 10942886912.0000 - val_loss: 12059111424.0000\n",
      "Epoch 108/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11026512896.0000 - val_loss: 11694427136.0000\n",
      "Epoch 109/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 10891527168.0000 - val_loss: 11725290496.0000\n",
      "Epoch 110/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10750007296.0000 - val_loss: 11909615616.0000\n",
      "Epoch 111/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10757125120.0000 - val_loss: 11531054080.0000\n",
      "Epoch 112/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10711130112.0000 - val_loss: 11663338496.0000\n",
      "Epoch 113/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10773607424.0000 - val_loss: 11435715584.0000\n",
      "Epoch 114/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10664003584.0000 - val_loss: 11437719552.0000\n",
      "Epoch 115/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10602353664.0000 - val_loss: 11419772928.0000\n",
      "Epoch 116/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10590219264.0000 - val_loss: 11361111040.0000\n",
      "Epoch 117/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10799670272.0000 - val_loss: 11370089472.0000\n",
      "Epoch 118/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10600775680.0000 - val_loss: 11536016384.0000\n",
      "Epoch 119/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10464873472.0000 - val_loss: 11215363072.0000\n",
      "Epoch 120/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 10526330880.0000 - val_loss: 11176162304.0000\n",
      "Epoch 121/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10397778944.0000 - val_loss: 11218347008.0000\n",
      "Epoch 122/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10451956736.0000 - val_loss: 11131120640.0000\n",
      "Epoch 123/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10403610624.0000 - val_loss: 11279801344.0000\n",
      "Epoch 124/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10354794496.0000 - val_loss: 11036805120.0000\n",
      "Epoch 125/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10510400512.0000 - val_loss: 11146549248.0000\n",
      "Epoch 126/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10249117696.0000 - val_loss: 11007568896.0000\n",
      "Epoch 127/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10251729920.0000 - val_loss: 10981440512.0000\n",
      "Epoch 128/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 10363395072.0000 - val_loss: 11057684480.0000\n",
      "Epoch 129/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10256412672.0000 - val_loss: 11109419008.0000\n",
      "Epoch 130/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10197903360.0000 - val_loss: 11249359872.0000\n",
      "Epoch 131/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10292064256.0000 - val_loss: 10964140032.0000\n",
      "Epoch 132/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10138725376.0000 - val_loss: 11277799424.0000\n",
      "Epoch 133/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10126303232.0000 - val_loss: 11190141952.0000\n",
      "Epoch 134/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10159776768.0000 - val_loss: 11716088832.0000\n",
      "Epoch 135/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10134875136.0000 - val_loss: 10759241728.0000\n",
      "Epoch 136/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 10087639040.0000 - val_loss: 11320656896.0000\n",
      "Epoch 137/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10165977088.0000 - val_loss: 10686901248.0000\n",
      "Epoch 138/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10182811648.0000 - val_loss: 10665337856.0000\n",
      "Epoch 139/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9919732736.0000 - val_loss: 10756932608.0000\n",
      "Epoch 140/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9898351616.0000 - val_loss: 10810070016.0000\n",
      "Epoch 141/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9931479040.0000 - val_loss: 10661419008.0000\n",
      "Epoch 142/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9943348224.0000 - val_loss: 11104940032.0000\n",
      "Epoch 143/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9942315008.0000 - val_loss: 10760456192.0000\n",
      "Epoch 144/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9877376000.0000 - val_loss: 10525558784.0000\n",
      "Epoch 145/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9835430912.0000 - val_loss: 11346755584.0000\n",
      "Epoch 146/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9968740352.0000 - val_loss: 12409962496.0000\n",
      "Epoch 147/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9842817024.0000 - val_loss: 10500413440.0000\n",
      "Epoch 148/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9736806400.0000 - val_loss: 10542976000.0000\n",
      "Epoch 149/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9855920128.0000 - val_loss: 10685319168.0000\n",
      "Epoch 150/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9827464192.0000 - val_loss: 10972704768.0000\n",
      "Epoch 151/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9734713344.0000 - val_loss: 10662870016.0000\n",
      "Epoch 152/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9733689344.0000 - val_loss: 10412551168.0000\n",
      "Epoch 153/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9687613440.0000 - val_loss: 10736577536.0000\n",
      "Epoch 154/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9780849664.0000 - val_loss: 10561198080.0000\n",
      "Epoch 155/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9709733888.0000 - val_loss: 10381110272.0000\n",
      "Epoch 156/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9613882368.0000 - val_loss: 10278023168.0000\n",
      "Epoch 157/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9578735616.0000 - val_loss: 10288699392.0000\n",
      "Epoch 158/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9677917184.0000 - val_loss: 10270766080.0000\n",
      "Epoch 159/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9704388608.0000 - val_loss: 10702247936.0000\n",
      "Epoch 160/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9928543232.0000 - val_loss: 10178767872.0000\n",
      "Epoch 161/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9649562624.0000 - val_loss: 10168671232.0000\n",
      "Epoch 162/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9495169024.0000 - val_loss: 10216031232.0000\n",
      "Epoch 163/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9483827200.0000 - val_loss: 10159369216.0000\n",
      "Epoch 164/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9482037248.0000 - val_loss: 10692455424.0000\n",
      "Epoch 165/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9550365696.0000 - val_loss: 10168047616.0000\n",
      "Epoch 166/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9422092288.0000 - val_loss: 10110611456.0000\n",
      "Epoch 167/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9572759552.0000 - val_loss: 10373187584.0000\n",
      "Epoch 168/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9426628608.0000 - val_loss: 10042307584.0000\n",
      "Epoch 169/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9445592064.0000 - val_loss: 10106682368.0000\n",
      "Epoch 170/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9643249664.0000 - val_loss: 10171653120.0000\n",
      "Epoch 171/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9407005696.0000 - val_loss: 10088263680.0000\n",
      "Epoch 172/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9343237120.0000 - val_loss: 10152732672.0000\n",
      "Epoch 173/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9458262016.0000 - val_loss: 10025108480.0000\n",
      "Epoch 174/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9608327168.0000 - val_loss: 10482476032.0000\n",
      "Epoch 175/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9866235904.0000 - val_loss: 10528046080.0000\n",
      "Epoch 176/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9289083904.0000 - val_loss: 10094222336.0000\n",
      "Epoch 177/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9304694784.0000 - val_loss: 10160996352.0000\n",
      "Epoch 178/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9277946880.0000 - val_loss: 9904358400.0000\n",
      "Epoch 179/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9368450048.0000 - val_loss: 10368738304.0000\n",
      "Epoch 180/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9348031488.0000 - val_loss: 9893168128.0000\n",
      "Epoch 181/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9306435584.0000 - val_loss: 9935666176.0000\n",
      "Epoch 182/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9376972800.0000 - val_loss: 9924494336.0000\n",
      "Epoch 183/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9527127040.0000 - val_loss: 10498174976.0000\n",
      "Epoch 184/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9254428672.0000 - val_loss: 10227140608.0000\n",
      "Epoch 185/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 9272815616.0000 - val_loss: 9961788416.0000\n",
      "Epoch 186/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 9443805184.0000 - val_loss: 11288987648.0000\n",
      "Epoch 187/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9260339200.0000 - val_loss: 10257630208.0000\n",
      "Epoch 188/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9214910464.0000 - val_loss: 9952051200.0000\n",
      "Epoch 189/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9256161280.0000 - val_loss: 9885875200.0000\n",
      "Epoch 190/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9157687296.0000 - val_loss: 9758784512.0000\n",
      "Epoch 191/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9091450880.0000 - val_loss: 9833208832.0000\n",
      "Epoch 192/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9142363136.0000 - val_loss: 10377392128.0000\n",
      "Epoch 193/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9334879232.0000 - val_loss: 9801670656.0000\n",
      "Epoch 194/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9264737280.0000 - val_loss: 10725404672.0000\n",
      "Epoch 195/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9146614784.0000 - val_loss: 10186608640.0000\n",
      "Epoch 196/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9065785344.0000 - val_loss: 9799491584.0000\n",
      "Epoch 197/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9012730880.0000 - val_loss: 9691057152.0000\n",
      "Epoch 198/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9110970368.0000 - val_loss: 10052355072.0000\n",
      "Epoch 199/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9023355904.0000 - val_loss: 9692512256.0000\n",
      "Epoch 200/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9138239488.0000 - val_loss: 10004462592.0000\n",
      "Epoch 201/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9258297344.0000 - val_loss: 9639128064.0000\n",
      "Epoch 202/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9137873920.0000 - val_loss: 9708011520.0000\n",
      "Epoch 203/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9080732672.0000 - val_loss: 9702720512.0000\n",
      "Epoch 204/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9126422528.0000 - val_loss: 9725597696.0000\n",
      "Epoch 205/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 9097515008.0000 - val_loss: 9733161984.0000\n",
      "Epoch 206/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8999945216.0000 - val_loss: 9603399680.0000\n",
      "Epoch 207/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9076157440.0000 - val_loss: 9582208000.0000\n",
      "Epoch 208/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9103382528.0000 - val_loss: 9650122752.0000\n",
      "Epoch 209/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8979034112.0000 - val_loss: 9755623424.0000\n",
      "Epoch 210/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9018882048.0000 - val_loss: 10071926784.0000\n",
      "Epoch 211/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8995343360.0000 - val_loss: 9951336448.0000\n",
      "Epoch 212/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8944838656.0000 - val_loss: 9493715968.0000\n",
      "Epoch 213/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8996432896.0000 - val_loss: 10028542976.0000\n",
      "Epoch 214/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9130411008.0000 - val_loss: 9579302912.0000\n",
      "Epoch 215/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8970819584.0000 - val_loss: 9565344768.0000\n",
      "Epoch 216/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8962493440.0000 - val_loss: 9558554624.0000\n",
      "Epoch 217/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9069465600.0000 - val_loss: 9704059904.0000\n",
      "Epoch 218/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8954822656.0000 - val_loss: 9620153344.0000\n",
      "Epoch 219/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8940012544.0000 - val_loss: 9464203264.0000\n",
      "Epoch 220/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8843003904.0000 - val_loss: 9770844160.0000\n",
      "Epoch 221/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8885008384.0000 - val_loss: 9581894656.0000\n",
      "Epoch 222/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9030142976.0000 - val_loss: 10004289536.0000\n",
      "Epoch 223/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8918440960.0000 - val_loss: 9497881600.0000\n",
      "Epoch 224/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8939163648.0000 - val_loss: 9435382784.0000\n",
      "Epoch 225/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8939673600.0000 - val_loss: 9422091264.0000\n",
      "Epoch 226/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8901039104.0000 - val_loss: 9520557056.0000\n",
      "Epoch 227/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8827468800.0000 - val_loss: 9415225344.0000\n",
      "Epoch 228/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8790520832.0000 - val_loss: 9754525696.0000\n",
      "Epoch 229/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8868253696.0000 - val_loss: 9518303232.0000\n",
      "Epoch 230/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8860979200.0000 - val_loss: 9425179648.0000\n",
      "Epoch 231/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8842041344.0000 - val_loss: 9390653440.0000\n",
      "Epoch 232/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8726813696.0000 - val_loss: 9400020992.0000\n",
      "Epoch 233/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8719006720.0000 - val_loss: 9380471808.0000\n",
      "Epoch 234/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8768787456.0000 - val_loss: 9386944512.0000\n",
      "Epoch 235/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8760145920.0000 - val_loss: 9473101824.0000\n",
      "Epoch 236/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8831150080.0000 - val_loss: 9502686208.0000\n",
      "Epoch 237/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8788885504.0000 - val_loss: 9406830592.0000\n",
      "Epoch 238/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8915674112.0000 - val_loss: 9697911808.0000\n",
      "Epoch 239/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8865819648.0000 - val_loss: 9337887744.0000\n",
      "Epoch 240/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8748278784.0000 - val_loss: 9738526720.0000\n",
      "Epoch 241/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8809098240.0000 - val_loss: 9367520256.0000\n",
      "Epoch 242/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8699573248.0000 - val_loss: 9317180416.0000\n",
      "Epoch 243/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8780643328.0000 - val_loss: 9254302720.0000\n",
      "Epoch 244/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8797358080.0000 - val_loss: 9320799232.0000\n",
      "Epoch 245/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8785771520.0000 - val_loss: 9376050176.0000\n",
      "Epoch 246/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8818884608.0000 - val_loss: 9366161408.0000\n",
      "Epoch 247/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8782033920.0000 - val_loss: 9756592128.0000\n",
      "Epoch 248/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8769929216.0000 - val_loss: 9242935296.0000\n",
      "Epoch 249/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8705918976.0000 - val_loss: 9294025728.0000\n",
      "Epoch 250/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8667330560.0000 - val_loss: 9290586112.0000\n",
      "Epoch 251/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8651914240.0000 - val_loss: 9312699392.0000\n",
      "Epoch 252/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8763003904.0000 - val_loss: 9682235392.0000\n",
      "Epoch 253/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8673290240.0000 - val_loss: 9221704704.0000\n",
      "Epoch 254/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8612349952.0000 - val_loss: 9367254016.0000\n",
      "Epoch 255/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8681038848.0000 - val_loss: 9302908928.0000\n",
      "Epoch 256/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8745652224.0000 - val_loss: 9221404672.0000\n",
      "Epoch 257/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8623704064.0000 - val_loss: 9183752192.0000\n",
      "Epoch 258/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8800512000.0000 - val_loss: 9224085504.0000\n",
      "Epoch 259/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8607303680.0000 - val_loss: 9615626240.0000\n",
      "Epoch 260/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8728017920.0000 - val_loss: 9373407232.0000\n",
      "Epoch 261/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8847840256.0000 - val_loss: 9312870400.0000\n",
      "Epoch 262/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8605879296.0000 - val_loss: 9379654656.0000\n",
      "Epoch 263/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8643617792.0000 - val_loss: 9998745600.0000\n",
      "Epoch 264/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8686781440.0000 - val_loss: 9302114304.0000\n",
      "Epoch 265/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8591790080.0000 - val_loss: 9760041984.0000\n",
      "Epoch 266/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8807304192.0000 - val_loss: 9350753280.0000\n",
      "Epoch 267/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8672470016.0000 - val_loss: 9525095424.0000\n",
      "Epoch 268/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8759139328.0000 - val_loss: 9443584000.0000\n",
      "Epoch 269/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8695991296.0000 - val_loss: 9162955776.0000\n",
      "Epoch 270/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8594795520.0000 - val_loss: 9300856832.0000\n",
      "Epoch 271/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8694360064.0000 - val_loss: 9182127104.0000\n",
      "Epoch 272/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8630509568.0000 - val_loss: 9095742464.0000\n",
      "Epoch 273/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8560901120.0000 - val_loss: 9181687808.0000\n",
      "Epoch 274/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8800913408.0000 - val_loss: 9148873728.0000\n",
      "Epoch 275/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8611774464.0000 - val_loss: 9199420416.0000\n",
      "Epoch 276/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8528961536.0000 - val_loss: 9071072256.0000\n",
      "Epoch 277/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8517395456.0000 - val_loss: 9119693824.0000\n",
      "Epoch 278/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8653147136.0000 - val_loss: 9450737664.0000\n",
      "Epoch 279/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9276964864.0000 - val_loss: 9076975616.0000\n",
      "Epoch 280/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8549794304.0000 - val_loss: 9199905792.0000\n",
      "Epoch 281/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8494081024.0000 - val_loss: 9220319232.0000\n",
      "Epoch 282/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8607251456.0000 - val_loss: 9080934400.0000\n",
      "Epoch 283/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8470045184.0000 - val_loss: 9146718208.0000\n",
      "Epoch 284/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8539274752.0000 - val_loss: 9174933504.0000\n",
      "Epoch 285/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8569302528.0000 - val_loss: 9240263680.0000\n",
      "Epoch 286/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8565219840.0000 - val_loss: 9665568768.0000\n",
      "Epoch 287/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8443703808.0000 - val_loss: 9081843712.0000\n",
      "Epoch 288/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8499549696.0000 - val_loss: 9138643968.0000\n",
      "Epoch 289/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8516555264.0000 - val_loss: 9057764352.0000\n",
      "Epoch 290/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8417250816.0000 - val_loss: 9180374016.0000\n",
      "Epoch 291/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8696781824.0000 - val_loss: 9318617088.0000\n",
      "Epoch 292/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8564580864.0000 - val_loss: 9153254400.0000\n",
      "Epoch 293/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8511962112.0000 - val_loss: 9685865472.0000\n",
      "Epoch 294/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8605236224.0000 - val_loss: 10030471168.0000\n",
      "Epoch 295/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8543919104.0000 - val_loss: 9078507520.0000\n",
      "Epoch 296/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8531163136.0000 - val_loss: 9049507840.0000\n",
      "Epoch 297/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8583401984.0000 - val_loss: 9482191872.0000\n",
      "Epoch 298/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8453837824.0000 - val_loss: 9122361344.0000\n",
      "Epoch 299/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8408138240.0000 - val_loss: 9018031104.0000\n",
      "Epoch 300/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8594006016.0000 - val_loss: 9400926208.0000\n",
      "Epoch 301/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8454637056.0000 - val_loss: 9000613888.0000\n",
      "Epoch 302/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8546563072.0000 - val_loss: 9006476288.0000\n",
      "Epoch 303/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8428346368.0000 - val_loss: 8982425600.0000\n",
      "Epoch 304/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8468506112.0000 - val_loss: 9248632832.0000\n",
      "Epoch 305/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8545545216.0000 - val_loss: 9066318848.0000\n",
      "Epoch 306/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8453273600.0000 - val_loss: 9379773440.0000\n",
      "Epoch 307/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8609290240.0000 - val_loss: 9080057856.0000\n",
      "Epoch 308/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8500150784.0000 - val_loss: 9220229120.0000\n",
      "Epoch 309/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8578124800.0000 - val_loss: 8964078592.0000\n",
      "Epoch 310/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8686822400.0000 - val_loss: 9085671424.0000\n",
      "Epoch 311/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8421026304.0000 - val_loss: 9002484736.0000\n",
      "Epoch 312/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8419045376.0000 - val_loss: 9159302144.0000\n",
      "Epoch 313/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8416835072.0000 - val_loss: 9207790592.0000\n",
      "Epoch 314/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8713503744.0000 - val_loss: 9306199040.0000\n",
      "Epoch 315/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8395038208.0000 - val_loss: 9120337920.0000\n",
      "Epoch 316/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8430461952.0000 - val_loss: 9063122944.0000\n",
      "Epoch 317/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8558720512.0000 - val_loss: 9686480896.0000\n",
      "Epoch 318/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8437498368.0000 - val_loss: 9182412800.0000\n",
      "Epoch 319/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8427983360.0000 - val_loss: 8975382528.0000\n",
      "Epoch 320/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8432451584.0000 - val_loss: 8993641472.0000\n",
      "Epoch 321/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8381311488.0000 - val_loss: 9154844672.0000\n",
      "Epoch 322/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8491995136.0000 - val_loss: 8953675776.0000\n",
      "Epoch 323/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8402315776.0000 - val_loss: 8946386944.0000\n",
      "Epoch 324/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8270211584.0000 - val_loss: 8966724608.0000\n",
      "Epoch 325/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8490787328.0000 - val_loss: 8951350272.0000\n",
      "Epoch 326/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8421881856.0000 - val_loss: 9145991168.0000\n",
      "Epoch 327/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8450979840.0000 - val_loss: 9229035520.0000\n",
      "Epoch 328/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8594920448.0000 - val_loss: 8945951744.0000\n",
      "Epoch 329/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8515378176.0000 - val_loss: 9109329920.0000\n",
      "Epoch 330/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8541500928.0000 - val_loss: 10288664576.0000\n",
      "Epoch 331/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8598391808.0000 - val_loss: 8910208000.0000\n",
      "Epoch 332/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8440954368.0000 - val_loss: 9062281216.0000\n",
      "Epoch 333/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8348636160.0000 - val_loss: 8899953664.0000\n",
      "Epoch 334/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8557671424.0000 - val_loss: 9460149248.0000\n",
      "Epoch 335/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8311198720.0000 - val_loss: 8927720448.0000\n",
      "Epoch 336/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8368534016.0000 - val_loss: 9496982528.0000\n",
      "Epoch 337/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8267749376.0000 - val_loss: 8905234432.0000\n",
      "Epoch 338/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8357969408.0000 - val_loss: 9207540736.0000\n",
      "Epoch 339/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8474490880.0000 - val_loss: 9520356352.0000\n",
      "Epoch 340/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8348441600.0000 - val_loss: 9398404096.0000\n",
      "Epoch 341/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8488457728.0000 - val_loss: 9803461632.0000\n",
      "Epoch 342/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8445796864.0000 - val_loss: 8912901120.0000\n",
      "Epoch 343/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8274418688.0000 - val_loss: 8887913472.0000\n",
      "Epoch 344/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8402794496.0000 - val_loss: 9065618432.0000\n",
      "Epoch 345/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8304304128.0000 - val_loss: 9001886720.0000\n",
      "Epoch 346/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8303208448.0000 - val_loss: 9387594752.0000\n",
      "Epoch 347/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8282324480.0000 - val_loss: 9165060096.0000\n",
      "Epoch 348/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8495405056.0000 - val_loss: 9986660352.0000\n",
      "Epoch 349/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8364436992.0000 - val_loss: 8938080256.0000\n",
      "Epoch 350/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8343362048.0000 - val_loss: 9067454464.0000\n",
      "Epoch 351/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8484568064.0000 - val_loss: 9133664256.0000\n",
      "Epoch 352/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8320425984.0000 - val_loss: 9348260864.0000\n",
      "Epoch 353/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8623203328.0000 - val_loss: 8880078848.0000\n",
      "Epoch 354/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8281750016.0000 - val_loss: 8889396224.0000\n",
      "Epoch 355/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8368814080.0000 - val_loss: 8988007424.0000\n",
      "Epoch 356/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8385449984.0000 - val_loss: 8844403712.0000\n",
      "Epoch 357/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8921243648.0000 - val_loss: 8982202368.0000\n",
      "Epoch 358/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8445070848.0000 - val_loss: 8880414720.0000\n",
      "Epoch 359/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8361972224.0000 - val_loss: 8856162304.0000\n",
      "Epoch 360/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8354245632.0000 - val_loss: 9072800768.0000\n",
      "Epoch 361/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8344989696.0000 - val_loss: 9270661120.0000\n",
      "Epoch 362/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8491346432.0000 - val_loss: 8828812288.0000\n",
      "Epoch 363/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8348679680.0000 - val_loss: 8950706176.0000\n",
      "Epoch 364/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8425440256.0000 - val_loss: 8917936128.0000\n",
      "Epoch 365/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8338702336.0000 - val_loss: 8951457792.0000\n",
      "Epoch 366/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8322659328.0000 - val_loss: 8866955264.0000\n",
      "Epoch 367/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8261006848.0000 - val_loss: 9473754112.0000\n",
      "Epoch 368/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8199050240.0000 - val_loss: 9107994624.0000\n",
      "Epoch 369/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8259466752.0000 - val_loss: 8870715392.0000\n",
      "Epoch 370/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8283218432.0000 - val_loss: 8850094080.0000\n",
      "Epoch 371/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8511600640.0000 - val_loss: 9466571776.0000\n",
      "Epoch 372/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8398904832.0000 - val_loss: 9285377024.0000\n",
      "Epoch 373/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8219151360.0000 - val_loss: 9350985728.0000\n",
      "Epoch 374/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8570330112.0000 - val_loss: 9040231424.0000\n",
      "Epoch 375/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8409422848.0000 - val_loss: 9493859328.0000\n",
      "Epoch 376/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8372788736.0000 - val_loss: 9331243008.0000\n",
      "Epoch 377/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8588514816.0000 - val_loss: 9303121920.0000\n",
      "Epoch 378/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8310998016.0000 - val_loss: 10725114880.0000\n",
      "Epoch 379/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8364476928.0000 - val_loss: 9083762688.0000\n",
      "Epoch 380/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8339020288.0000 - val_loss: 8881866752.0000\n",
      "Epoch 381/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8162511872.0000 - val_loss: 8969231360.0000\n",
      "Epoch 382/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8224137216.0000 - val_loss: 8816550912.0000\n",
      "Epoch 383/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8175909888.0000 - val_loss: 9074284544.0000\n",
      "Epoch 384/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8283327488.0000 - val_loss: 9041881088.0000\n",
      "Epoch 385/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8258372096.0000 - val_loss: 8816569344.0000\n",
      "Epoch 386/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8240627200.0000 - val_loss: 9419098112.0000\n",
      "Epoch 387/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8196186624.0000 - val_loss: 8843745280.0000\n",
      "Epoch 388/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8229742080.0000 - val_loss: 9189155840.0000\n",
      "Epoch 389/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8276303360.0000 - val_loss: 8850203648.0000\n",
      "Epoch 390/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8374184960.0000 - val_loss: 8907053056.0000\n",
      "Epoch 391/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8263345152.0000 - val_loss: 8860709888.0000\n",
      "Epoch 392/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8211717120.0000 - val_loss: 8816094208.0000\n",
      "Epoch 393/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8288251904.0000 - val_loss: 9321136128.0000\n",
      "Epoch 394/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8373488128.0000 - val_loss: 8845614080.0000\n",
      "Epoch 395/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8273580032.0000 - val_loss: 8811875328.0000\n",
      "Epoch 396/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8247695360.0000 - val_loss: 9045361664.0000\n",
      "Epoch 397/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8220400640.0000 - val_loss: 8793658368.0000\n",
      "Epoch 398/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8251393536.0000 - val_loss: 8789228544.0000\n",
      "Epoch 399/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8462018048.0000 - val_loss: 8788706304.0000\n",
      "Epoch 400/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8299739136.0000 - val_loss: 9184908288.0000\n",
      "Epoch 401/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8340062208.0000 - val_loss: 9116423168.0000\n",
      "Epoch 402/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8290847744.0000 - val_loss: 9822448640.0000\n",
      "Epoch 403/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8350019072.0000 - val_loss: 9237502976.0000\n",
      "Epoch 404/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8420801024.0000 - val_loss: 9141636096.0000\n",
      "Epoch 405/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8260642304.0000 - val_loss: 9677179904.0000\n",
      "Epoch 406/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8256219136.0000 - val_loss: 8783419392.0000\n",
      "Epoch 407/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8209795584.0000 - val_loss: 8980713472.0000\n",
      "Epoch 408/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8562966016.0000 - val_loss: 8820382720.0000\n",
      "Epoch 409/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8139148288.0000 - val_loss: 9169867776.0000\n",
      "Epoch 410/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8394728960.0000 - val_loss: 8794024960.0000\n",
      "Epoch 411/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8286195712.0000 - val_loss: 9301219328.0000\n",
      "Epoch 412/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8472754688.0000 - val_loss: 9425835008.0000\n",
      "Epoch 413/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8134895616.0000 - val_loss: 8755411968.0000\n",
      "Epoch 414/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8118667264.0000 - val_loss: 8979694592.0000\n",
      "Epoch 415/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8174724096.0000 - val_loss: 8754420736.0000\n",
      "Epoch 416/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8319043072.0000 - val_loss: 9204590592.0000\n",
      "Epoch 417/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8376087552.0000 - val_loss: 9238492160.0000\n",
      "Epoch 418/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8372822016.0000 - val_loss: 8822821888.0000\n",
      "Epoch 419/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 8147743232.0000 - val_loss: 8812535808.0000\n",
      "Epoch 420/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8172047872.0000 - val_loss: 8802691072.0000\n",
      "Epoch 421/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8312603136.0000 - val_loss: 8817115136.0000\n",
      "Epoch 422/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8140597248.0000 - val_loss: 9034605568.0000\n",
      "Epoch 423/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8207039488.0000 - val_loss: 8994262016.0000\n",
      "Epoch 424/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8220722176.0000 - val_loss: 8814758912.0000\n",
      "Epoch 425/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8103073792.0000 - val_loss: 8747494400.0000\n",
      "Epoch 426/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8233508864.0000 - val_loss: 8765076480.0000\n",
      "Epoch 427/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8107523072.0000 - val_loss: 9065679872.0000\n",
      "Epoch 428/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8146709504.0000 - val_loss: 9059628032.0000\n",
      "Epoch 429/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8300403712.0000 - val_loss: 9030139904.0000\n",
      "Epoch 430/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8091229696.0000 - val_loss: 10325523456.0000\n",
      "Epoch 431/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8448891904.0000 - val_loss: 8780338176.0000\n",
      "Epoch 432/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8306586112.0000 - val_loss: 8996490240.0000\n",
      "Epoch 433/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8266077184.0000 - val_loss: 8760411136.0000\n",
      "Epoch 434/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8208670720.0000 - val_loss: 8865816576.0000\n",
      "Epoch 435/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8193987584.0000 - val_loss: 8928717824.0000\n",
      "Epoch 436/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8117971456.0000 - val_loss: 8862750720.0000\n",
      "Epoch 437/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8083934720.0000 - val_loss: 8763767808.0000\n",
      "Epoch 438/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8075184640.0000 - val_loss: 8737732608.0000\n",
      "Epoch 439/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8244895232.0000 - val_loss: 8732412928.0000\n",
      "Epoch 440/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8211658240.0000 - val_loss: 9087494144.0000\n",
      "Epoch 441/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8181966336.0000 - val_loss: 9034268672.0000\n",
      "Epoch 442/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8564909056.0000 - val_loss: 8889765888.0000\n",
      "Epoch 443/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8189783552.0000 - val_loss: 9312811008.0000\n",
      "Epoch 444/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8194929664.0000 - val_loss: 9122161664.0000\n",
      "Epoch 445/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8181566976.0000 - val_loss: 9034544128.0000\n",
      "Epoch 446/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8246103552.0000 - val_loss: 8869689344.0000\n",
      "Epoch 447/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8064084480.0000 - val_loss: 8875377664.0000\n",
      "Epoch 448/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8307791872.0000 - val_loss: 8932197376.0000\n",
      "Epoch 449/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8207008768.0000 - val_loss: 8696296448.0000\n",
      "Epoch 450/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8277597184.0000 - val_loss: 9391496192.0000\n",
      "Epoch 451/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8204506624.0000 - val_loss: 9667200000.0000\n",
      "Epoch 452/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8066997760.0000 - val_loss: 8696174592.0000\n",
      "Epoch 453/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8139475968.0000 - val_loss: 8906405888.0000\n",
      "Epoch 454/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8126626816.0000 - val_loss: 8856311808.0000\n",
      "Epoch 455/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8132744192.0000 - val_loss: 9325274112.0000\n",
      "Epoch 456/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8062435840.0000 - val_loss: 9256091648.0000\n",
      "Epoch 457/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8247352832.0000 - val_loss: 8863504384.0000\n",
      "Epoch 458/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8065932800.0000 - val_loss: 9358412800.0000\n",
      "Epoch 459/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8082357248.0000 - val_loss: 8867833856.0000\n",
      "Epoch 460/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8047660544.0000 - val_loss: 9041701888.0000\n",
      "Epoch 461/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8209093120.0000 - val_loss: 9588460544.0000\n",
      "Epoch 462/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8242661376.0000 - val_loss: 9076952064.0000\n",
      "Epoch 463/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8277801472.0000 - val_loss: 10139179008.0000\n",
      "Epoch 464/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8247646720.0000 - val_loss: 8684247040.0000\n",
      "Epoch 465/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8098955264.0000 - val_loss: 8745734144.0000\n",
      "Epoch 466/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8258042368.0000 - val_loss: 9171396608.0000\n",
      "Epoch 467/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8127691264.0000 - val_loss: 8886533120.0000\n",
      "Epoch 468/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8132877824.0000 - val_loss: 9233028096.0000\n",
      "Epoch 469/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8193221120.0000 - val_loss: 8824835072.0000\n",
      "Epoch 470/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8137822720.0000 - val_loss: 9104590848.0000\n",
      "Epoch 471/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8236553216.0000 - val_loss: 8763468800.0000\n",
      "Epoch 472/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8191406080.0000 - val_loss: 9933617152.0000\n",
      "Epoch 473/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8174412800.0000 - val_loss: 8862508032.0000\n",
      "Epoch 474/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8130970112.0000 - val_loss: 9853322240.0000\n",
      "Epoch 475/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8107482112.0000 - val_loss: 8900913152.0000\n",
      "Epoch 476/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8043651072.0000 - val_loss: 8840617984.0000\n",
      "Epoch 477/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8015475712.0000 - val_loss: 8890980352.0000\n",
      "Epoch 478/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8321354752.0000 - val_loss: 8643701760.0000\n",
      "Epoch 479/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8179101696.0000 - val_loss: 8711965696.0000\n",
      "Epoch 480/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8069299712.0000 - val_loss: 8663534592.0000\n",
      "Epoch 481/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8051533824.0000 - val_loss: 8709535744.0000\n",
      "Epoch 482/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8091663872.0000 - val_loss: 9207963648.0000\n",
      "Epoch 483/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8119584768.0000 - val_loss: 9033713664.0000\n",
      "Epoch 484/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8107646976.0000 - val_loss: 8656526336.0000\n",
      "Epoch 485/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8206211584.0000 - val_loss: 8986650624.0000\n",
      "Epoch 486/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8251245568.0000 - val_loss: 8671333376.0000\n",
      "Epoch 487/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7985664000.0000 - val_loss: 8726268928.0000\n",
      "Epoch 488/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8127477760.0000 - val_loss: 8696536064.0000\n",
      "Epoch 489/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8108163072.0000 - val_loss: 8771653632.0000\n",
      "Epoch 490/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8187370496.0000 - val_loss: 8761837568.0000\n",
      "Epoch 491/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8172295680.0000 - val_loss: 9274540032.0000\n",
      "Epoch 492/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7995223040.0000 - val_loss: 9244322816.0000\n",
      "Epoch 493/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8190867456.0000 - val_loss: 8832034816.0000\n",
      "Epoch 494/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8033916416.0000 - val_loss: 8720667648.0000\n",
      "Epoch 495/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8018727936.0000 - val_loss: 8920309760.0000\n",
      "Epoch 496/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8042576384.0000 - val_loss: 9100945408.0000\n",
      "Epoch 497/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8034150912.0000 - val_loss: 8825032704.0000\n",
      "Epoch 498/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7964062208.0000 - val_loss: 8699168768.0000\n",
      "Epoch 499/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8210989568.0000 - val_loss: 9481193472.0000\n",
      "Epoch 500/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8025807360.0000 - val_loss: 8728765440.0000\n",
      "Epoch 501/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8005399552.0000 - val_loss: 8948202496.0000\n",
      "Epoch 502/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8205061632.0000 - val_loss: 8649938944.0000\n",
      "Epoch 503/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7997737472.0000 - val_loss: 8629665792.0000\n",
      "Epoch 504/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8055561728.0000 - val_loss: 8681991168.0000\n",
      "Epoch 505/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8053281280.0000 - val_loss: 8773355520.0000\n",
      "Epoch 506/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8060009984.0000 - val_loss: 8764741632.0000\n",
      "Epoch 507/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8109779968.0000 - val_loss: 8641287168.0000\n",
      "Epoch 508/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7992593920.0000 - val_loss: 8640678912.0000\n",
      "Epoch 509/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8034386944.0000 - val_loss: 8655275008.0000\n",
      "Epoch 510/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7974094848.0000 - val_loss: 9352189952.0000\n",
      "Epoch 511/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8093173248.0000 - val_loss: 9279971328.0000\n",
      "Epoch 512/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8142587904.0000 - val_loss: 8868180992.0000\n",
      "Epoch 513/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7970120192.0000 - val_loss: 8663546880.0000\n",
      "Epoch 514/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8039621632.0000 - val_loss: 8666033152.0000\n",
      "Epoch 515/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7994556928.0000 - val_loss: 9250712576.0000\n",
      "Epoch 516/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8131762688.0000 - val_loss: 8974965760.0000\n",
      "Epoch 517/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8212808192.0000 - val_loss: 8832261120.0000\n",
      "Epoch 518/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8169182720.0000 - val_loss: 8665620480.0000\n",
      "Epoch 519/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8121337856.0000 - val_loss: 8727803904.0000\n",
      "Epoch 520/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7924783616.0000 - val_loss: 8601683968.0000\n",
      "Epoch 521/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8186413568.0000 - val_loss: 10138918912.0000\n",
      "Epoch 522/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8200039424.0000 - val_loss: 8623935488.0000\n",
      "Epoch 523/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8020853760.0000 - val_loss: 8965980160.0000\n",
      "Epoch 524/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8034645504.0000 - val_loss: 8815623168.0000\n",
      "Epoch 525/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8000050176.0000 - val_loss: 9396313088.0000\n",
      "Epoch 526/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8005369856.0000 - val_loss: 9176192000.0000\n",
      "Epoch 527/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8066809344.0000 - val_loss: 8594509824.0000\n",
      "Epoch 528/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8126803968.0000 - val_loss: 8950181888.0000\n",
      "Epoch 529/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8077642752.0000 - val_loss: 8597849088.0000\n",
      "Epoch 530/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8037502464.0000 - val_loss: 8622535680.0000\n",
      "Epoch 531/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8085613568.0000 - val_loss: 8696491008.0000\n",
      "Epoch 532/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8028519936.0000 - val_loss: 8885982208.0000\n",
      "Epoch 533/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7929440256.0000 - val_loss: 8730915840.0000\n",
      "Epoch 534/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8131739136.0000 - val_loss: 8717981696.0000\n",
      "Epoch 535/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7919664640.0000 - val_loss: 8703670272.0000\n",
      "Epoch 536/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7891311616.0000 - val_loss: 8605132800.0000\n",
      "Epoch 537/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8025093120.0000 - val_loss: 8847631360.0000\n",
      "Epoch 538/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8254536192.0000 - val_loss: 8666785792.0000\n",
      "Epoch 539/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8084440576.0000 - val_loss: 8586076160.0000\n",
      "Epoch 540/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8000067072.0000 - val_loss: 8618663936.0000\n",
      "Epoch 541/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7864358400.0000 - val_loss: 8899750912.0000\n",
      "Epoch 542/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8095030784.0000 - val_loss: 9023570944.0000\n",
      "Epoch 543/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7965407744.0000 - val_loss: 8560010240.0000\n",
      "Epoch 544/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8009069568.0000 - val_loss: 8881790976.0000\n",
      "Epoch 545/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8097388032.0000 - val_loss: 9098389504.0000\n",
      "Epoch 546/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7949904896.0000 - val_loss: 9510998016.0000\n",
      "Epoch 547/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8060366336.0000 - val_loss: 8838793216.0000\n",
      "Epoch 548/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7981878272.0000 - val_loss: 8627733504.0000\n",
      "Epoch 549/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8229019648.0000 - val_loss: 9044699136.0000\n",
      "Epoch 550/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7999072768.0000 - val_loss: 8632016896.0000\n",
      "Epoch 551/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7946374144.0000 - val_loss: 9052460032.0000\n",
      "Epoch 552/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7920090624.0000 - val_loss: 8594983936.0000\n",
      "Epoch 553/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7948491776.0000 - val_loss: 8844882944.0000\n",
      "Epoch 554/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7959357440.0000 - val_loss: 8933836800.0000\n",
      "Epoch 555/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8059504640.0000 - val_loss: 9111028736.0000\n",
      "Epoch 556/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8143975424.0000 - val_loss: 8565074944.0000\n",
      "Epoch 557/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7892040192.0000 - val_loss: 8620167168.0000\n",
      "Epoch 558/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7938059776.0000 - val_loss: 8933634048.0000\n",
      "Epoch 559/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7899105280.0000 - val_loss: 8549324288.0000\n",
      "Epoch 560/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7977369088.0000 - val_loss: 8723266560.0000\n",
      "Epoch 561/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8007012352.0000 - val_loss: 8576500224.0000\n",
      "Epoch 562/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7996120576.0000 - val_loss: 8647097344.0000\n",
      "Epoch 563/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7922005504.0000 - val_loss: 9137384448.0000\n",
      "Epoch 564/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8125214208.0000 - val_loss: 8841859072.0000\n",
      "Epoch 565/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8055914496.0000 - val_loss: 8734923776.0000\n",
      "Epoch 566/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7916856320.0000 - val_loss: 8525463040.0000\n",
      "Epoch 567/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8097761792.0000 - val_loss: 8647404544.0000\n",
      "Epoch 568/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7957673472.0000 - val_loss: 8818518016.0000\n",
      "Epoch 569/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7923182592.0000 - val_loss: 8738368512.0000\n",
      "Epoch 570/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7892256256.0000 - val_loss: 8530699264.0000\n",
      "Epoch 571/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7951595008.0000 - val_loss: 8719087616.0000\n",
      "Epoch 572/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7933219328.0000 - val_loss: 8606858240.0000\n",
      "Epoch 573/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7984041472.0000 - val_loss: 9122102272.0000\n",
      "Epoch 574/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7936464896.0000 - val_loss: 9187170304.0000\n",
      "Epoch 575/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8094289920.0000 - val_loss: 8666024960.0000\n",
      "Epoch 576/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7895894528.0000 - val_loss: 8593989632.0000\n",
      "Epoch 577/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7920206336.0000 - val_loss: 8607254528.0000\n",
      "Epoch 578/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7887898624.0000 - val_loss: 8647078912.0000\n",
      "Epoch 579/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8056581120.0000 - val_loss: 8591128576.0000\n",
      "Epoch 580/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8023711744.0000 - val_loss: 8762167296.0000\n",
      "Epoch 581/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7943958016.0000 - val_loss: 8540248576.0000\n",
      "Epoch 582/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7908137984.0000 - val_loss: 8662056960.0000\n",
      "Epoch 583/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7918873600.0000 - val_loss: 8765555712.0000\n",
      "Epoch 584/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7976203264.0000 - val_loss: 8766526464.0000\n",
      "Epoch 585/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7894699520.0000 - val_loss: 8519896064.0000\n",
      "Epoch 586/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8013678592.0000 - val_loss: 9054219264.0000\n",
      "Epoch 587/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7916271104.0000 - val_loss: 8881201152.0000\n",
      "Epoch 588/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7886921216.0000 - val_loss: 8847083520.0000\n",
      "Epoch 589/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7936864768.0000 - val_loss: 8641901568.0000\n",
      "Epoch 590/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8138777600.0000 - val_loss: 8743974912.0000\n",
      "Epoch 591/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7930438144.0000 - val_loss: 8669329408.0000\n",
      "Epoch 592/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7967008256.0000 - val_loss: 8512912896.0000\n",
      "Epoch 593/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7882232320.0000 - val_loss: 8627928064.0000\n",
      "Epoch 594/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8081037824.0000 - val_loss: 8595929088.0000\n",
      "Epoch 595/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8023868928.0000 - val_loss: 8555954688.0000\n",
      "Epoch 596/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7888046592.0000 - val_loss: 9010058240.0000\n",
      "Epoch 597/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8018684416.0000 - val_loss: 8515353600.0000\n",
      "Epoch 598/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7820837376.0000 - val_loss: 10236207104.0000\n",
      "Epoch 599/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7994456576.0000 - val_loss: 9070780416.0000\n",
      "Epoch 600/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8193734656.0000 - val_loss: 10069168128.0000\n",
      "Epoch 601/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7970931712.0000 - val_loss: 8581949440.0000\n",
      "Epoch 602/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8108518912.0000 - val_loss: 8495335424.0000\n",
      "Epoch 603/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7809453056.0000 - val_loss: 8572584448.0000\n",
      "Epoch 604/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7886002176.0000 - val_loss: 8526606336.0000\n",
      "Epoch 605/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8019792896.0000 - val_loss: 8532535808.0000\n",
      "Epoch 606/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8034401280.0000 - val_loss: 8736234496.0000\n",
      "Epoch 607/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7955344896.0000 - val_loss: 8505956864.0000\n",
      "Epoch 608/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8047612416.0000 - val_loss: 8780043264.0000\n",
      "Epoch 609/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7851456512.0000 - val_loss: 8575493120.0000\n",
      "Epoch 610/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7863041024.0000 - val_loss: 8848482304.0000\n",
      "Epoch 611/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7896114688.0000 - val_loss: 10276271104.0000\n",
      "Epoch 612/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8096992256.0000 - val_loss: 8791685120.0000\n",
      "Epoch 613/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7917496832.0000 - val_loss: 8460886016.0000\n",
      "Epoch 614/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8101954560.0000 - val_loss: 8498307584.0000\n",
      "Epoch 615/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7789705216.0000 - val_loss: 8797166592.0000\n",
      "Epoch 616/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7808425472.0000 - val_loss: 8734617600.0000\n",
      "Epoch 617/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7858844160.0000 - val_loss: 8509260800.0000\n",
      "Epoch 618/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7849077760.0000 - val_loss: 8463540224.0000\n",
      "Epoch 619/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7938979328.0000 - val_loss: 8431440896.0000\n",
      "Epoch 620/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7968491008.0000 - val_loss: 8520934400.0000\n",
      "Epoch 621/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7817548800.0000 - val_loss: 8562562048.0000\n",
      "Epoch 622/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7764053504.0000 - val_loss: 8927553536.0000\n",
      "Epoch 623/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7864528384.0000 - val_loss: 8497338368.0000\n",
      "Epoch 624/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7924762624.0000 - val_loss: 8619868160.0000\n",
      "Epoch 625/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7978963456.0000 - val_loss: 8508096000.0000\n",
      "Epoch 626/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7847097856.0000 - val_loss: 8707958784.0000\n",
      "Epoch 627/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7800991744.0000 - val_loss: 8665873408.0000\n",
      "Epoch 628/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7936096768.0000 - val_loss: 8999528448.0000\n",
      "Epoch 629/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7899163136.0000 - val_loss: 8946396160.0000\n",
      "Epoch 630/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8032252416.0000 - val_loss: 8536261632.0000\n",
      "Epoch 631/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7939553792.0000 - val_loss: 8799165440.0000\n",
      "Epoch 632/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7864425472.0000 - val_loss: 8510169088.0000\n",
      "Epoch 633/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7850685440.0000 - val_loss: 8449095680.0000\n",
      "Epoch 634/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7810594304.0000 - val_loss: 9842440192.0000\n",
      "Epoch 635/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7983183872.0000 - val_loss: 8501438976.0000\n",
      "Epoch 636/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8033412096.0000 - val_loss: 8522888192.0000\n",
      "Epoch 637/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7823168512.0000 - val_loss: 8462891520.0000\n",
      "Epoch 638/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7811717632.0000 - val_loss: 8491388416.0000\n",
      "Epoch 639/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7799261184.0000 - val_loss: 9127180288.0000\n",
      "Epoch 640/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7919334912.0000 - val_loss: 8472502784.0000\n",
      "Epoch 641/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8100644352.0000 - val_loss: 8469287936.0000\n",
      "Epoch 642/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7885406720.0000 - val_loss: 9040569344.0000\n",
      "Epoch 643/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7801759744.0000 - val_loss: 8568134656.0000\n",
      "Epoch 644/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8084754432.0000 - val_loss: 9244104704.0000\n",
      "Epoch 645/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7748487680.0000 - val_loss: 8446795264.0000\n",
      "Epoch 646/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8247577600.0000 - val_loss: 9589357568.0000\n",
      "Epoch 647/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7928165888.0000 - val_loss: 8472807936.0000\n",
      "Epoch 648/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7884096000.0000 - val_loss: 8719605760.0000\n",
      "Epoch 649/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7863521280.0000 - val_loss: 8487442432.0000\n",
      "Epoch 650/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7833130496.0000 - val_loss: 8426733568.0000\n",
      "Epoch 651/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7870734848.0000 - val_loss: 8589481472.0000\n",
      "Epoch 652/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7914190336.0000 - val_loss: 8469458944.0000\n",
      "Epoch 653/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7901926912.0000 - val_loss: 8547550720.0000\n",
      "Epoch 654/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7864141824.0000 - val_loss: 9128960000.0000\n",
      "Epoch 655/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8181078016.0000 - val_loss: 8487011328.0000\n",
      "Epoch 656/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7775211520.0000 - val_loss: 8585068544.0000\n",
      "Epoch 657/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7815583744.0000 - val_loss: 8755419136.0000\n",
      "Epoch 658/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7837127680.0000 - val_loss: 8552489984.0000\n",
      "Epoch 659/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7696863232.0000 - val_loss: 8416743936.0000\n",
      "Epoch 660/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7691060224.0000 - val_loss: 8742277120.0000\n",
      "Epoch 661/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7773782528.0000 - val_loss: 10015662080.0000\n",
      "Epoch 662/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7938583552.0000 - val_loss: 8611360768.0000\n",
      "Epoch 663/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7923115520.0000 - val_loss: 8407620608.0000\n",
      "Epoch 664/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7658055680.0000 - val_loss: 8766382080.0000\n",
      "Epoch 665/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7833358848.0000 - val_loss: 8492992512.0000\n",
      "Epoch 666/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7722710016.0000 - val_loss: 8878236672.0000\n",
      "Epoch 667/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7954848768.0000 - val_loss: 8424324608.0000\n",
      "Epoch 668/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7821437440.0000 - val_loss: 9272218624.0000\n",
      "Epoch 669/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7762784768.0000 - val_loss: 9324999680.0000\n",
      "Epoch 670/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7710092288.0000 - val_loss: 8754294784.0000\n",
      "Epoch 671/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7933380096.0000 - val_loss: 8834110464.0000\n",
      "Epoch 672/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8163227136.0000 - val_loss: 9400935424.0000\n",
      "Epoch 673/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7746111488.0000 - val_loss: 8608178176.0000\n",
      "Epoch 674/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7696973824.0000 - val_loss: 8931680256.0000\n",
      "Epoch 675/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7921259008.0000 - val_loss: 8489202688.0000\n",
      "Epoch 676/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7803638784.0000 - val_loss: 8561141248.0000\n",
      "Epoch 677/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7946841600.0000 - val_loss: 9875410944.0000\n",
      "Epoch 678/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8018662400.0000 - val_loss: 8400806400.0000\n",
      "Epoch 679/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8004642816.0000 - val_loss: 8502890496.0000\n",
      "Epoch 680/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7798150144.0000 - val_loss: 9156594688.0000\n",
      "Epoch 681/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8091933184.0000 - val_loss: 8790270976.0000\n",
      "Epoch 682/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7835944448.0000 - val_loss: 8474236928.0000\n",
      "Epoch 683/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7894131200.0000 - val_loss: 9434160128.0000\n",
      "Epoch 684/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7871029248.0000 - val_loss: 8815438848.0000\n",
      "Epoch 685/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7735491584.0000 - val_loss: 8417132544.0000\n",
      "Epoch 686/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7863568384.0000 - val_loss: 8452004352.0000\n",
      "Epoch 687/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7711270912.0000 - val_loss: 8412516864.0000\n",
      "Epoch 688/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7783372800.0000 - val_loss: 8482685440.0000\n",
      "Epoch 689/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7973243392.0000 - val_loss: 8419196416.0000\n",
      "Epoch 690/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7949544448.0000 - val_loss: 9523584000.0000\n",
      "Epoch 691/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7813897728.0000 - val_loss: 8957372416.0000\n",
      "Epoch 692/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7631843328.0000 - val_loss: 8466932224.0000\n",
      "Epoch 693/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7712747520.0000 - val_loss: 8904698880.0000\n",
      "Epoch 694/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7903103488.0000 - val_loss: 8679399424.0000\n",
      "Epoch 695/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7887464960.0000 - val_loss: 8521542144.0000\n",
      "Epoch 696/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7749762048.0000 - val_loss: 8688798720.0000\n",
      "Epoch 697/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7924288000.0000 - val_loss: 8403347456.0000\n",
      "Epoch 698/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7769737728.0000 - val_loss: 8877638656.0000\n",
      "Epoch 699/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7868697600.0000 - val_loss: 8422030848.0000\n",
      "Epoch 700/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7838826496.0000 - val_loss: 8950945792.0000\n",
      "Epoch 701/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7783668224.0000 - val_loss: 8938203136.0000\n",
      "Epoch 702/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7963905536.0000 - val_loss: 8416901632.0000\n",
      "Epoch 703/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7649988608.0000 - val_loss: 8448374784.0000\n",
      "Epoch 704/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7872197120.0000 - val_loss: 8471618560.0000\n",
      "Epoch 705/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7746468864.0000 - val_loss: 8533570048.0000\n",
      "Epoch 706/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7896960512.0000 - val_loss: 8388296704.0000\n",
      "Epoch 707/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7816258048.0000 - val_loss: 8432666624.0000\n",
      "Epoch 708/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7728474112.0000 - val_loss: 8393191936.0000\n",
      "Epoch 709/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7801194496.0000 - val_loss: 8440781312.0000\n",
      "Epoch 710/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7775859712.0000 - val_loss: 8627719168.0000\n",
      "Epoch 711/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7783258624.0000 - val_loss: 8360905728.0000\n",
      "Epoch 712/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7766604288.0000 - val_loss: 8515145216.0000\n",
      "Epoch 713/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7780913152.0000 - val_loss: 8436104704.0000\n",
      "Epoch 714/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7769549824.0000 - val_loss: 8445595136.0000\n",
      "Epoch 715/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7733272576.0000 - val_loss: 8385254400.0000\n",
      "Epoch 716/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7784416256.0000 - val_loss: 8430745600.0000\n",
      "Epoch 717/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7866997248.0000 - val_loss: 8538698240.0000\n",
      "Epoch 718/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7804553728.0000 - val_loss: 8407029248.0000\n",
      "Epoch 719/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7742795776.0000 - val_loss: 8759732224.0000\n",
      "Epoch 720/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7899422720.0000 - val_loss: 8386445824.0000\n",
      "Epoch 721/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7691860992.0000 - val_loss: 8439530496.0000\n",
      "Epoch 722/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7728336896.0000 - val_loss: 8408840704.0000\n",
      "Epoch 723/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7805915136.0000 - val_loss: 8511634432.0000\n",
      "Epoch 724/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7588545024.0000 - val_loss: 8443728896.0000\n",
      "Epoch 725/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7689937920.0000 - val_loss: 8571830272.0000\n",
      "Epoch 726/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7998571520.0000 - val_loss: 8446055936.0000\n",
      "Epoch 727/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7984984064.0000 - val_loss: 8551984640.0000\n",
      "Epoch 728/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7781898752.0000 - val_loss: 8895336448.0000\n",
      "Epoch 729/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7814261248.0000 - val_loss: 8590729216.0000\n",
      "Epoch 730/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7739159552.0000 - val_loss: 8661280768.0000\n",
      "Epoch 731/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7747444224.0000 - val_loss: 9011699712.0000\n",
      "Epoch 732/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7717783552.0000 - val_loss: 8349686784.0000\n",
      "Epoch 733/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7855372288.0000 - val_loss: 8448393216.0000\n",
      "Epoch 734/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7596655104.0000 - val_loss: 8358062592.0000\n",
      "Epoch 735/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7754607616.0000 - val_loss: 8472688640.0000\n",
      "Epoch 736/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7838070784.0000 - val_loss: 8787193856.0000\n",
      "Epoch 737/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7728261632.0000 - val_loss: 8673841152.0000\n",
      "Epoch 738/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7978360832.0000 - val_loss: 8353737728.0000\n",
      "Epoch 739/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7798948864.0000 - val_loss: 8453988352.0000\n",
      "Epoch 740/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7778816000.0000 - val_loss: 8414009344.0000\n",
      "Epoch 741/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7715897856.0000 - val_loss: 8661371904.0000\n",
      "Epoch 742/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7754085888.0000 - val_loss: 8524835840.0000\n",
      "Epoch 743/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7720833536.0000 - val_loss: 8748366848.0000\n",
      "Epoch 744/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7650300416.0000 - val_loss: 8572981248.0000\n",
      "Epoch 745/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7716717568.0000 - val_loss: 8436551680.0000\n",
      "Epoch 746/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7704745472.0000 - val_loss: 8395930624.0000\n",
      "Epoch 747/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7884575232.0000 - val_loss: 8536041984.0000\n",
      "Epoch 748/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7816544768.0000 - val_loss: 8816336896.0000\n",
      "Epoch 749/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7700084736.0000 - val_loss: 8337761280.0000\n",
      "Epoch 750/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7928574464.0000 - val_loss: 8599813120.0000\n",
      "Epoch 751/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7868478464.0000 - val_loss: 8447981568.0000\n",
      "Epoch 752/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7691778048.0000 - val_loss: 8703938560.0000\n",
      "Epoch 753/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7699567104.0000 - val_loss: 8407121920.0000\n",
      "Epoch 754/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7751252480.0000 - val_loss: 8415571456.0000\n",
      "Epoch 755/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7974395904.0000 - val_loss: 8390264832.0000\n",
      "Epoch 756/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7736442368.0000 - val_loss: 8582976512.0000\n",
      "Epoch 757/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7759055360.0000 - val_loss: 8332153856.0000\n",
      "Epoch 758/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7716946432.0000 - val_loss: 8597051392.0000\n",
      "Epoch 759/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7609983488.0000 - val_loss: 8352181760.0000\n",
      "Epoch 760/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7664540160.0000 - val_loss: 8857620480.0000\n",
      "Epoch 761/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7773989888.0000 - val_loss: 8497027072.0000\n",
      "Epoch 762/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7937043968.0000 - val_loss: 9460535296.0000\n",
      "Epoch 763/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7960528896.0000 - val_loss: 8761914368.0000\n",
      "Epoch 764/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7637082624.0000 - val_loss: 8334994432.0000\n",
      "Epoch 765/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7648310272.0000 - val_loss: 8387732992.0000\n",
      "Epoch 766/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7781909504.0000 - val_loss: 8330513920.0000\n",
      "Epoch 767/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7630948352.0000 - val_loss: 8353602048.0000\n",
      "Epoch 768/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7678832128.0000 - val_loss: 8405179904.0000\n",
      "Epoch 769/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7619021312.0000 - val_loss: 8348739072.0000\n",
      "Epoch 770/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7745600000.0000 - val_loss: 9065388032.0000\n",
      "Epoch 771/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7756357120.0000 - val_loss: 8357964288.0000\n",
      "Epoch 772/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7556169728.0000 - val_loss: 8370191872.0000\n",
      "Epoch 773/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7675480064.0000 - val_loss: 8348718080.0000\n",
      "Epoch 774/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7711079424.0000 - val_loss: 8604271616.0000\n",
      "Epoch 775/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7661478912.0000 - val_loss: 8415498752.0000\n",
      "Epoch 776/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7682996224.0000 - val_loss: 8579636224.0000\n",
      "Epoch 777/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7675173376.0000 - val_loss: 8356773376.0000\n",
      "Epoch 778/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7643833344.0000 - val_loss: 8319208448.0000\n",
      "Epoch 779/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7788433920.0000 - val_loss: 8403623424.0000\n",
      "Epoch 780/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7682642944.0000 - val_loss: 8309928960.0000\n",
      "Epoch 781/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7706537472.0000 - val_loss: 8890287104.0000\n",
      "Epoch 782/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7733536768.0000 - val_loss: 8931684352.0000\n",
      "Epoch 783/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7556597760.0000 - val_loss: 8429235200.0000\n",
      "Epoch 784/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7638663680.0000 - val_loss: 8750981120.0000\n",
      "Epoch 785/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7945393664.0000 - val_loss: 8423840256.0000\n",
      "Epoch 786/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7781856256.0000 - val_loss: 8583033856.0000\n",
      "Epoch 787/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7665035776.0000 - val_loss: 8378771968.0000\n",
      "Epoch 788/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7536432640.0000 - val_loss: 8310934016.0000\n",
      "Epoch 789/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7659581952.0000 - val_loss: 8298371584.0000\n",
      "Epoch 790/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7687802880.0000 - val_loss: 8360644096.0000\n",
      "Epoch 791/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7674946560.0000 - val_loss: 8341568000.0000\n",
      "Epoch 792/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7647917056.0000 - val_loss: 8446075904.0000\n",
      "Epoch 793/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7839208960.0000 - val_loss: 8325160960.0000\n",
      "Epoch 794/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7777073664.0000 - val_loss: 8581970944.0000\n",
      "Epoch 795/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7789079552.0000 - val_loss: 9263822848.0000\n",
      "Epoch 796/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7709344256.0000 - val_loss: 8395134464.0000\n",
      "Epoch 797/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7588687360.0000 - val_loss: 8348231680.0000\n",
      "Epoch 798/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7669214720.0000 - val_loss: 8381502464.0000\n",
      "Epoch 799/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7609283584.0000 - val_loss: 8547016704.0000\n",
      "Epoch 800/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7788244992.0000 - val_loss: 9049249792.0000\n",
      "Epoch 801/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7645163520.0000 - val_loss: 8326716416.0000\n",
      "Epoch 802/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7579877376.0000 - val_loss: 9074913280.0000\n",
      "Epoch 803/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7602578944.0000 - val_loss: 8500917760.0000\n",
      "Epoch 804/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7825865728.0000 - val_loss: 8502306816.0000\n",
      "Epoch 805/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7724300800.0000 - val_loss: 8378910208.0000\n",
      "Epoch 806/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7794988032.0000 - val_loss: 8867181568.0000\n",
      "Epoch 807/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7735234560.0000 - val_loss: 8455438848.0000\n",
      "Epoch 808/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7804682752.0000 - val_loss: 8307685888.0000\n",
      "Epoch 809/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7625008128.0000 - val_loss: 8286099968.0000\n",
      "Epoch 810/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7559135744.0000 - val_loss: 8569301504.0000\n",
      "Epoch 811/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7723427328.0000 - val_loss: 8373524480.0000\n",
      "Epoch 812/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7644313600.0000 - val_loss: 8554237440.0000\n",
      "Epoch 813/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7584599552.0000 - val_loss: 8333007872.0000\n",
      "Epoch 814/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7657266688.0000 - val_loss: 8296553472.0000\n",
      "Epoch 815/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7782013952.0000 - val_loss: 8472119296.0000\n",
      "Epoch 816/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7674700288.0000 - val_loss: 8446051840.0000\n",
      "Epoch 817/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7663805952.0000 - val_loss: 8308515328.0000\n",
      "Epoch 818/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7517091328.0000 - val_loss: 8324209152.0000\n",
      "Epoch 819/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7592458752.0000 - val_loss: 8304229888.0000\n",
      "Epoch 820/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7670651392.0000 - val_loss: 8328299008.0000\n",
      "Epoch 821/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7567360512.0000 - val_loss: 8360857088.0000\n",
      "Epoch 822/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7608838656.0000 - val_loss: 8319162368.0000\n",
      "Epoch 823/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7700404736.0000 - val_loss: 8481357312.0000\n",
      "Epoch 824/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7635046912.0000 - val_loss: 8350497792.0000\n",
      "Epoch 825/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7567786496.0000 - val_loss: 8337423360.0000\n",
      "Epoch 826/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7528051712.0000 - val_loss: 8312476672.0000\n",
      "Epoch 827/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7627781632.0000 - val_loss: 8324529664.0000\n",
      "Epoch 828/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7683340800.0000 - val_loss: 10015160320.0000\n",
      "Epoch 829/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7719996416.0000 - val_loss: 8463812096.0000\n",
      "Epoch 830/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7528997888.0000 - val_loss: 8590090240.0000\n",
      "Epoch 831/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7553408512.0000 - val_loss: 8316536320.0000\n",
      "Epoch 832/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7837090816.0000 - val_loss: 8309257216.0000\n",
      "Epoch 833/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7660304896.0000 - val_loss: 8458442752.0000\n",
      "Epoch 834/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7572960768.0000 - val_loss: 8482601984.0000\n",
      "Epoch 835/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560140800.0000 - val_loss: 8423260160.0000\n",
      "Epoch 836/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7653710848.0000 - val_loss: 8893410304.0000\n",
      "Epoch 837/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7994858496.0000 - val_loss: 8273740288.0000\n",
      "Epoch 838/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7475836416.0000 - val_loss: 8267254784.0000\n",
      "Epoch 839/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7730542080.0000 - val_loss: 8783130624.0000\n",
      "Epoch 840/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7942203392.0000 - val_loss: 8643145728.0000\n",
      "Epoch 841/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7775994880.0000 - val_loss: 8418928640.0000\n",
      "Epoch 842/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7549044224.0000 - val_loss: 8303132160.0000\n",
      "Epoch 843/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500622336.0000 - val_loss: 8286786560.0000\n",
      "Epoch 844/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7662808064.0000 - val_loss: 8372459008.0000\n",
      "Epoch 845/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7629241344.0000 - val_loss: 8295290880.0000\n",
      "Epoch 846/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7678800896.0000 - val_loss: 8748298240.0000\n",
      "Epoch 847/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7639135744.0000 - val_loss: 8288328192.0000\n",
      "Epoch 848/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7559230464.0000 - val_loss: 8470209536.0000\n",
      "Epoch 849/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7614861312.0000 - val_loss: 8497214464.0000\n",
      "Epoch 850/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7642483712.0000 - val_loss: 8334501376.0000\n",
      "Epoch 851/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7620907008.0000 - val_loss: 8470643712.0000\n",
      "Epoch 852/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7876882944.0000 - val_loss: 8307595776.0000\n",
      "Epoch 853/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7527398912.0000 - val_loss: 8338505216.0000\n",
      "Epoch 854/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7620160000.0000 - val_loss: 8517251072.0000\n",
      "Epoch 855/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7502764032.0000 - val_loss: 8302281728.0000\n",
      "Epoch 856/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7612068864.0000 - val_loss: 8558145536.0000\n",
      "Epoch 857/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548607488.0000 - val_loss: 8434939392.0000\n",
      "Epoch 858/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7574880768.0000 - val_loss: 8708770816.0000\n",
      "Epoch 859/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7641069568.0000 - val_loss: 8379456000.0000\n",
      "Epoch 860/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7754894848.0000 - val_loss: 8305526272.0000\n",
      "Epoch 861/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7530648064.0000 - val_loss: 8866345984.0000\n",
      "Epoch 862/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7499780608.0000 - val_loss: 8905163776.0000\n",
      "Epoch 863/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7567472640.0000 - val_loss: 8794090496.0000\n",
      "Epoch 864/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7555559936.0000 - val_loss: 8480239616.0000\n",
      "Epoch 865/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7554425344.0000 - val_loss: 8288301056.0000\n",
      "Epoch 866/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7625866752.0000 - val_loss: 8353539584.0000\n",
      "Epoch 867/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7559629312.0000 - val_loss: 8287930368.0000\n",
      "Epoch 868/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7622384128.0000 - val_loss: 8243546624.0000\n",
      "Epoch 869/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7692653568.0000 - val_loss: 8573474304.0000\n",
      "Epoch 870/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7643654144.0000 - val_loss: 8642607104.0000\n",
      "Epoch 871/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7642097152.0000 - val_loss: 8425261056.0000\n",
      "Epoch 872/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7608556032.0000 - val_loss: 8625874944.0000\n",
      "Epoch 873/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7809982464.0000 - val_loss: 8247579648.0000\n",
      "Epoch 874/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7744506368.0000 - val_loss: 8307713024.0000\n",
      "Epoch 875/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7557314048.0000 - val_loss: 10129717248.0000\n",
      "Epoch 876/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7827367424.0000 - val_loss: 8303331840.0000\n",
      "Epoch 877/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7775266816.0000 - val_loss: 8440144896.0000\n",
      "Epoch 878/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7614156288.0000 - val_loss: 8563355648.0000\n",
      "Epoch 879/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7535949824.0000 - val_loss: 8237928448.0000\n",
      "Epoch 880/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7983954432.0000 - val_loss: 9957004288.0000\n",
      "Epoch 881/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7561256448.0000 - val_loss: 8319460352.0000\n",
      "Epoch 882/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560704512.0000 - val_loss: 8281868800.0000\n",
      "Epoch 883/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7455629312.0000 - val_loss: 8249879552.0000\n",
      "Epoch 884/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7567961600.0000 - val_loss: 8675046400.0000\n",
      "Epoch 885/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7637262848.0000 - val_loss: 8227832832.0000\n",
      "Epoch 886/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7488155136.0000 - val_loss: 8295343104.0000\n",
      "Epoch 887/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7631641088.0000 - val_loss: 8288426496.0000\n",
      "Epoch 888/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7546319872.0000 - val_loss: 8251796992.0000\n",
      "Epoch 889/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7596233728.0000 - val_loss: 8554144768.0000\n",
      "Epoch 890/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7621407744.0000 - val_loss: 8311538176.0000\n",
      "Epoch 891/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7639171072.0000 - val_loss: 8314090496.0000\n",
      "Epoch 892/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7442120704.0000 - val_loss: 8990280704.0000\n",
      "Epoch 893/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7582937600.0000 - val_loss: 8339305472.0000\n",
      "Epoch 894/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7542731264.0000 - val_loss: 8952318976.0000\n",
      "Epoch 895/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7540101632.0000 - val_loss: 8280122880.0000\n",
      "Epoch 896/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7571805184.0000 - val_loss: 8446928896.0000\n",
      "Epoch 897/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7618409984.0000 - val_loss: 8254896640.0000\n",
      "Epoch 898/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7554830336.0000 - val_loss: 8250766848.0000\n",
      "Epoch 899/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7629098496.0000 - val_loss: 8259326464.0000\n",
      "Epoch 900/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7504337920.0000 - val_loss: 8255552512.0000\n",
      "Epoch 901/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7671184896.0000 - val_loss: 8973568000.0000\n",
      "Epoch 902/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7589745152.0000 - val_loss: 9156532224.0000\n",
      "Epoch 903/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7798874112.0000 - val_loss: 8320640512.0000\n",
      "Epoch 904/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7584994304.0000 - val_loss: 8404466688.0000\n",
      "Epoch 905/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7539441152.0000 - val_loss: 8208332288.0000\n",
      "Epoch 906/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7553016320.0000 - val_loss: 8230861312.0000\n",
      "Epoch 907/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7534158848.0000 - val_loss: 9068579840.0000\n",
      "Epoch 908/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7715946496.0000 - val_loss: 8315399168.0000\n",
      "Epoch 909/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7493581312.0000 - val_loss: 8370633728.0000\n",
      "Epoch 910/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7492653568.0000 - val_loss: 8303940096.0000\n",
      "Epoch 911/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7613928960.0000 - val_loss: 8390298112.0000\n",
      "Epoch 912/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7910478336.0000 - val_loss: 8614538240.0000\n",
      "Epoch 913/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7635657728.0000 - val_loss: 8264005632.0000\n",
      "Epoch 914/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7453461504.0000 - val_loss: 8216194560.0000\n",
      "Epoch 915/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7572063232.0000 - val_loss: 8698226688.0000\n",
      "Epoch 916/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7491354112.0000 - val_loss: 8321490432.0000\n",
      "Epoch 917/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7386663936.0000 - val_loss: 8244854272.0000\n",
      "Epoch 918/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7504797184.0000 - val_loss: 9726485504.0000\n",
      "Epoch 919/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7640636928.0000 - val_loss: 8524827136.0000\n",
      "Epoch 920/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7519936000.0000 - val_loss: 8337678848.0000\n",
      "Epoch 921/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7564125696.0000 - val_loss: 8244621824.0000\n",
      "Epoch 922/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7457960960.0000 - val_loss: 8744955904.0000\n",
      "Epoch 923/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7675076096.0000 - val_loss: 8994756608.0000\n",
      "Epoch 924/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7718111744.0000 - val_loss: 8977822720.0000\n",
      "Epoch 925/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7561932800.0000 - val_loss: 8667351040.0000\n",
      "Epoch 926/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7444750848.0000 - val_loss: 8566488576.0000\n",
      "Epoch 927/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7460000256.0000 - val_loss: 8242333184.0000\n",
      "Epoch 928/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7663247872.0000 - val_loss: 8332687360.0000\n",
      "Epoch 929/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7454388736.0000 - val_loss: 8321797120.0000\n",
      "Epoch 930/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7669056512.0000 - val_loss: 8284504064.0000\n",
      "Epoch 931/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7490329088.0000 - val_loss: 8225210880.0000\n",
      "Epoch 932/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7513209856.0000 - val_loss: 8567030272.0000\n",
      "Epoch 933/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7504135680.0000 - val_loss: 8240208384.0000\n",
      "Epoch 934/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7463953920.0000 - val_loss: 8601698304.0000\n",
      "Epoch 935/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7586670080.0000 - val_loss: 9097263104.0000\n",
      "Epoch 936/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7408058880.0000 - val_loss: 8428774912.0000\n",
      "Epoch 937/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7558563840.0000 - val_loss: 8442416128.0000\n",
      "Epoch 938/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7457589248.0000 - val_loss: 8368525824.0000\n",
      "Epoch 939/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7514824192.0000 - val_loss: 9457283072.0000\n",
      "Epoch 940/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7764140544.0000 - val_loss: 10078831616.0000\n",
      "Epoch 941/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7640967680.0000 - val_loss: 8294672896.0000\n",
      "Epoch 942/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7688256000.0000 - val_loss: 8564963840.0000\n",
      "Epoch 943/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7651033088.0000 - val_loss: 11329570816.0000\n",
      "Epoch 944/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7475721216.0000 - val_loss: 8422069248.0000\n",
      "Epoch 945/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7566261248.0000 - val_loss: 8216518144.0000\n",
      "Epoch 946/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7519217664.0000 - val_loss: 8206613504.0000\n",
      "Epoch 947/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7446972416.0000 - val_loss: 8326725120.0000\n",
      "Epoch 948/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7564739072.0000 - val_loss: 8227406336.0000\n",
      "Epoch 949/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7436834816.0000 - val_loss: 8514436096.0000\n",
      "Epoch 950/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7705003008.0000 - val_loss: 8345959424.0000\n",
      "Epoch 951/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7574752768.0000 - val_loss: 9482614784.0000\n",
      "Epoch 952/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7678380544.0000 - val_loss: 8517723136.0000\n",
      "Epoch 953/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7526090752.0000 - val_loss: 8278218752.0000\n",
      "Epoch 954/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7519674880.0000 - val_loss: 8240376832.0000\n",
      "Epoch 955/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7538263552.0000 - val_loss: 9099104256.0000\n",
      "Epoch 956/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7582859264.0000 - val_loss: 8282190336.0000\n",
      "Epoch 957/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7634639360.0000 - val_loss: 8283330048.0000\n",
      "Epoch 958/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7470223360.0000 - val_loss: 8288741888.0000\n",
      "Epoch 959/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7505467904.0000 - val_loss: 8313908736.0000\n",
      "Epoch 960/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7478094848.0000 - val_loss: 8206660608.0000\n",
      "Epoch 961/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7485897728.0000 - val_loss: 9025163264.0000\n",
      "Epoch 962/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7545930752.0000 - val_loss: 8258665984.0000\n",
      "Epoch 963/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7647545856.0000 - val_loss: 8255744000.0000\n",
      "Epoch 964/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7515974656.0000 - val_loss: 8481226752.0000\n",
      "Epoch 965/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7430266880.0000 - val_loss: 9309993984.0000\n",
      "Epoch 966/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7657184256.0000 - val_loss: 8367302656.0000\n",
      "Epoch 967/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7402245120.0000 - val_loss: 8416725504.0000\n",
      "Epoch 968/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7395854336.0000 - val_loss: 8522833408.0000\n",
      "Epoch 969/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500142080.0000 - val_loss: 8471938560.0000\n",
      "Epoch 970/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7467499520.0000 - val_loss: 8452865536.0000\n",
      "Epoch 971/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7487206400.0000 - val_loss: 8231451136.0000\n",
      "Epoch 972/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7398649344.0000 - val_loss: 8223711744.0000\n",
      "Epoch 973/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7511585792.0000 - val_loss: 8309619712.0000\n",
      "Epoch 974/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7714590720.0000 - val_loss: 8431463936.0000\n",
      "Epoch 975/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7568616448.0000 - val_loss: 8210054144.0000\n",
      "Epoch 976/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7409750016.0000 - val_loss: 8389859328.0000\n",
      "Epoch 977/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7562377216.0000 - val_loss: 8334398976.0000\n",
      "Epoch 978/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7480145920.0000 - val_loss: 8216779776.0000\n",
      "Epoch 979/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7450081280.0000 - val_loss: 8630200320.0000\n",
      "Epoch 980/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7572888064.0000 - val_loss: 8225553408.0000\n",
      "Epoch 981/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7437824000.0000 - val_loss: 8258721280.0000\n",
      "Epoch 982/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7415370240.0000 - val_loss: 9452649472.0000\n",
      "Epoch 983/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7433749504.0000 - val_loss: 8282532864.0000\n",
      "Epoch 984/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7894588416.0000 - val_loss: 8413374976.0000\n",
      "Epoch 985/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7530984448.0000 - val_loss: 8207284736.0000\n",
      "Epoch 986/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7490948096.0000 - val_loss: 8294812672.0000\n",
      "Epoch 987/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7439899648.0000 - val_loss: 8235554304.0000\n",
      "Epoch 988/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7701008384.0000 - val_loss: 8357204480.0000\n",
      "Epoch 989/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7544265728.0000 - val_loss: 9489991680.0000\n",
      "Epoch 990/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7473135104.0000 - val_loss: 8174018048.0000\n",
      "Epoch 991/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7417888256.0000 - val_loss: 8314589184.0000\n",
      "Epoch 992/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7480675840.0000 - val_loss: 8320374272.0000\n",
      "Epoch 993/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7437964800.0000 - val_loss: 8199099904.0000\n",
      "Epoch 994/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7398550528.0000 - val_loss: 8699058176.0000\n",
      "Epoch 995/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7670353920.0000 - val_loss: 8223507968.0000\n",
      "Epoch 996/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7492188160.0000 - val_loss: 8450078208.0000\n",
      "Epoch 997/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7416172032.0000 - val_loss: 8363265024.0000\n",
      "Epoch 998/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7399742464.0000 - val_loss: 8426177024.0000\n",
      "Epoch 999/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7415788032.0000 - val_loss: 8393664512.0000\n",
      "Epoch 1000/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7553833472.0000 - val_loss: 9280886784.0000\n",
      "Epoch 1001/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7839466496.0000 - val_loss: 8314107392.0000\n",
      "Epoch 1002/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7487445504.0000 - val_loss: 8428691968.0000\n",
      "Epoch 1003/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7594174976.0000 - val_loss: 8717902848.0000\n",
      "Epoch 1004/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7384029184.0000 - val_loss: 8258880512.0000\n",
      "Epoch 1005/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7442328064.0000 - val_loss: 8392214016.0000\n",
      "Epoch 1006/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7412875776.0000 - val_loss: 8209277440.0000\n",
      "Epoch 1007/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7553010176.0000 - val_loss: 8292326400.0000\n",
      "Epoch 1008/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7587507200.0000 - val_loss: 8311036928.0000\n",
      "Epoch 1009/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7477020672.0000 - val_loss: 8187136000.0000\n",
      "Epoch 1010/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7419748352.0000 - val_loss: 8261639168.0000\n",
      "Epoch 1011/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7504853504.0000 - val_loss: 8554782208.0000\n",
      "Epoch 1012/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7826834944.0000 - val_loss: 8255198720.0000\n",
      "Epoch 1013/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7371107328.0000 - val_loss: 8254513152.0000\n",
      "Epoch 1014/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7643672576.0000 - val_loss: 8267747328.0000\n",
      "Epoch 1015/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7461129216.0000 - val_loss: 8334059520.0000\n",
      "Epoch 1016/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7534871552.0000 - val_loss: 8596132864.0000\n",
      "Epoch 1017/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7394227712.0000 - val_loss: 8274068480.0000\n",
      "Epoch 1018/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7453962240.0000 - val_loss: 8168014848.0000\n",
      "Epoch 1019/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7443307008.0000 - val_loss: 8292361216.0000\n",
      "Epoch 1020/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7431228928.0000 - val_loss: 8810976256.0000\n",
      "Epoch 1021/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7474279936.0000 - val_loss: 8228609536.0000\n",
      "Epoch 1022/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7381133824.0000 - val_loss: 8171870208.0000\n",
      "Epoch 1023/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7547656704.0000 - val_loss: 8208961536.0000\n",
      "Epoch 1024/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7424543232.0000 - val_loss: 9071004672.0000\n",
      "Epoch 1025/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7498505216.0000 - val_loss: 8493611008.0000\n",
      "Epoch 1026/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7387237888.0000 - val_loss: 8190468608.0000\n",
      "Epoch 1027/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7515398144.0000 - val_loss: 8638226432.0000\n",
      "Epoch 1028/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7658965504.0000 - val_loss: 8212495872.0000\n",
      "Epoch 1029/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7399915520.0000 - val_loss: 8183563264.0000\n",
      "Epoch 1030/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7415635968.0000 - val_loss: 8980687872.0000\n",
      "Epoch 1031/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7536730624.0000 - val_loss: 8470265856.0000\n",
      "Epoch 1032/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7418435584.0000 - val_loss: 8417429504.0000\n",
      "Epoch 1033/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7374366720.0000 - val_loss: 8564571136.0000\n",
      "Epoch 1034/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7463096832.0000 - val_loss: 9544965120.0000\n",
      "Epoch 1035/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7418269696.0000 - val_loss: 8278568960.0000\n",
      "Epoch 1036/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7460882432.0000 - val_loss: 8651943936.0000\n",
      "Epoch 1037/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7356792320.0000 - val_loss: 8201634304.0000\n",
      "Epoch 1038/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7467949056.0000 - val_loss: 8256749568.0000\n",
      "Epoch 1039/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7439789568.0000 - val_loss: 9136913408.0000\n",
      "Epoch 1040/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7507347968.0000 - val_loss: 8167113216.0000\n",
      "Epoch 1041/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7512323584.0000 - val_loss: 8181121024.0000\n",
      "Epoch 1042/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7530968576.0000 - val_loss: 8365803008.0000\n",
      "Epoch 1043/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7459616256.0000 - val_loss: 8741070848.0000\n",
      "Epoch 1044/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7382936064.0000 - val_loss: 8171937792.0000\n",
      "Epoch 1045/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7362009600.0000 - val_loss: 8301987328.0000\n",
      "Epoch 1046/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7372835328.0000 - val_loss: 8310892544.0000\n",
      "Epoch 1047/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7382702080.0000 - val_loss: 8241225728.0000\n",
      "Epoch 1048/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7520946688.0000 - val_loss: 8267915776.0000\n",
      "Epoch 1049/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7558032384.0000 - val_loss: 8748188672.0000\n",
      "Epoch 1050/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7546732544.0000 - val_loss: 8579734016.0000\n",
      "Epoch 1051/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7508305920.0000 - val_loss: 8165739520.0000\n",
      "Epoch 1052/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7392831488.0000 - val_loss: 8403853824.0000\n",
      "Epoch 1053/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7420113920.0000 - val_loss: 8517160448.0000\n",
      "Epoch 1054/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7429234176.0000 - val_loss: 8159591936.0000\n",
      "Epoch 1055/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7427850240.0000 - val_loss: 8367895040.0000\n",
      "Epoch 1056/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7292957184.0000 - val_loss: 8240366592.0000\n",
      "Epoch 1057/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7435174912.0000 - val_loss: 8319072768.0000\n",
      "Epoch 1058/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7395602944.0000 - val_loss: 8124420608.0000\n",
      "Epoch 1059/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7480048640.0000 - val_loss: 8146694144.0000\n",
      "Epoch 1060/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7278467584.0000 - val_loss: 8148929024.0000\n",
      "Epoch 1061/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7332508160.0000 - val_loss: 8159177216.0000\n",
      "Epoch 1062/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7347444736.0000 - val_loss: 8276549120.0000\n",
      "Epoch 1063/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7651277824.0000 - val_loss: 8450907136.0000\n",
      "Epoch 1064/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7841891840.0000 - val_loss: 8406205440.0000\n",
      "Epoch 1065/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7443779584.0000 - val_loss: 8562147328.0000\n",
      "Epoch 1066/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7802243584.0000 - val_loss: 8160589312.0000\n",
      "Epoch 1067/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7496552448.0000 - val_loss: 8168128000.0000\n",
      "Epoch 1068/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7424484864.0000 - val_loss: 8305242624.0000\n",
      "Epoch 1069/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7359619584.0000 - val_loss: 8364771840.0000\n",
      "Epoch 1070/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7344279040.0000 - val_loss: 8193396224.0000\n",
      "Epoch 1071/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7294992896.0000 - val_loss: 8138528768.0000\n",
      "Epoch 1072/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7330644992.0000 - val_loss: 8226352128.0000\n",
      "Epoch 1073/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7484555264.0000 - val_loss: 8139349504.0000\n",
      "Epoch 1074/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7444645376.0000 - val_loss: 8264155648.0000\n",
      "Epoch 1075/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7501928448.0000 - val_loss: 8262865920.0000\n",
      "Epoch 1076/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7355589632.0000 - val_loss: 8261255168.0000\n",
      "Epoch 1077/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7398952448.0000 - val_loss: 8213151232.0000\n",
      "Epoch 1078/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7302552576.0000 - val_loss: 8266816000.0000\n",
      "Epoch 1079/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7350182912.0000 - val_loss: 8217363968.0000\n",
      "Epoch 1080/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7367803392.0000 - val_loss: 8616177664.0000\n",
      "Epoch 1081/1500\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7353218560.0000 - val_loss: 8682350592.0000\n",
      "Epoch 1082/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7462698496.0000 - val_loss: 8341160448.0000\n",
      "Epoch 1083/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7420254208.0000 - val_loss: 8312602112.0000\n",
      "Epoch 1084/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7276922368.0000 - val_loss: 8244887040.0000\n",
      "Epoch 1085/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7358381568.0000 - val_loss: 8633042944.0000\n",
      "Epoch 1086/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7532550144.0000 - val_loss: 8175352832.0000\n",
      "Epoch 1087/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7603925504.0000 - val_loss: 8591451136.0000\n",
      "Epoch 1088/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7586046464.0000 - val_loss: 8423062528.0000\n",
      "Epoch 1089/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7455118848.0000 - val_loss: 8192188416.0000\n",
      "Epoch 1090/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7344001024.0000 - val_loss: 8686729216.0000\n",
      "Epoch 1091/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7644528640.0000 - val_loss: 8878416896.0000\n",
      "Epoch 1092/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7417105920.0000 - val_loss: 8463547904.0000\n",
      "Epoch 1093/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7290920960.0000 - val_loss: 8143933440.0000\n",
      "Epoch 1094/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7411768320.0000 - val_loss: 8281654784.0000\n",
      "Epoch 1095/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7331572736.0000 - val_loss: 8746032128.0000\n",
      "Epoch 1096/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7302258176.0000 - val_loss: 8250644480.0000\n",
      "Epoch 1097/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7470976512.0000 - val_loss: 8212680192.0000\n",
      "Epoch 1098/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7355058688.0000 - val_loss: 8143596544.0000\n",
      "Epoch 1099/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7656802304.0000 - val_loss: 8378186240.0000\n",
      "Epoch 1100/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7318552064.0000 - val_loss: 8127742976.0000\n",
      "Epoch 1101/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7374749696.0000 - val_loss: 8271564288.0000\n",
      "Epoch 1102/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7399199232.0000 - val_loss: 8257800192.0000\n",
      "Epoch 1103/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7357143040.0000 - val_loss: 8449195520.0000\n",
      "Epoch 1104/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7344990720.0000 - val_loss: 8628639744.0000\n",
      "Epoch 1105/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7343100928.0000 - val_loss: 8334416896.0000\n",
      "Epoch 1106/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7467643392.0000 - val_loss: 8299504640.0000\n",
      "Epoch 1107/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7403974144.0000 - val_loss: 8154887168.0000\n",
      "Epoch 1108/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7464527360.0000 - val_loss: 8271131648.0000\n",
      "Epoch 1109/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7617300480.0000 - val_loss: 8313804800.0000\n",
      "Epoch 1110/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7506191872.0000 - val_loss: 8377462272.0000\n",
      "Epoch 1111/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7549565440.0000 - val_loss: 8904309760.0000\n",
      "Epoch 1112/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7280748544.0000 - val_loss: 8531736064.0000\n",
      "Epoch 1113/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7354936832.0000 - val_loss: 8797735936.0000\n",
      "Epoch 1114/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7519924224.0000 - val_loss: 8426183680.0000\n",
      "Epoch 1115/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7383833088.0000 - val_loss: 8179138560.0000\n",
      "Epoch 1116/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7449746432.0000 - val_loss: 8166375424.0000\n",
      "Epoch 1117/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7274366976.0000 - val_loss: 8221673472.0000\n",
      "Epoch 1118/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7491120128.0000 - val_loss: 8147044864.0000\n",
      "Epoch 1119/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7461641216.0000 - val_loss: 8387279872.0000\n",
      "Epoch 1120/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7392620032.0000 - val_loss: 8214471168.0000\n",
      "Epoch 1121/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7405222400.0000 - val_loss: 8135607296.0000\n",
      "Epoch 1122/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7339719168.0000 - val_loss: 8557979136.0000\n",
      "Epoch 1123/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7465129984.0000 - val_loss: 8359269376.0000\n",
      "Epoch 1124/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7503218688.0000 - val_loss: 8777404416.0000\n",
      "Epoch 1125/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7316766208.0000 - val_loss: 8171741696.0000\n",
      "Epoch 1126/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7292097536.0000 - val_loss: 9186806784.0000\n",
      "Epoch 1127/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7342598144.0000 - val_loss: 8391427584.0000\n",
      "Epoch 1128/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7382724096.0000 - val_loss: 8592131072.0000\n",
      "Epoch 1129/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7430143488.0000 - val_loss: 8564174336.0000\n",
      "Epoch 1130/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7596751872.0000 - val_loss: 8271851008.0000\n",
      "Epoch 1131/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7467158528.0000 - val_loss: 8544723456.0000\n",
      "Epoch 1132/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7422115840.0000 - val_loss: 8317902336.0000\n",
      "Epoch 1133/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7348988416.0000 - val_loss: 8199043584.0000\n",
      "Epoch 1134/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7531054080.0000 - val_loss: 8311384576.0000\n",
      "Epoch 1135/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7363383808.0000 - val_loss: 8225156608.0000\n",
      "Epoch 1136/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7273802240.0000 - val_loss: 8190241280.0000\n",
      "Epoch 1137/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7354147840.0000 - val_loss: 8344152576.0000\n",
      "Epoch 1138/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7430394880.0000 - val_loss: 8148140032.0000\n",
      "Epoch 1139/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7381894656.0000 - val_loss: 8181667328.0000\n",
      "Epoch 1140/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7486153216.0000 - val_loss: 8107632128.0000\n",
      "Epoch 1141/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7380322304.0000 - val_loss: 8257502208.0000\n",
      "Epoch 1142/1500\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7535326720.0000 - val_loss: 8382761984.0000\n",
      "Epoch 1143/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7265421312.0000 - val_loss: 8558286336.0000\n",
      "Epoch 1144/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7558774272.0000 - val_loss: 8212549120.0000\n",
      "Epoch 1145/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7399338496.0000 - val_loss: 8249436160.0000\n",
      "Epoch 1146/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7472174592.0000 - val_loss: 8129329664.0000\n",
      "Epoch 1147/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7300305920.0000 - val_loss: 8163315200.0000\n",
      "Epoch 1148/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7388336640.0000 - val_loss: 8341954560.0000\n",
      "Epoch 1149/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7417831936.0000 - val_loss: 8105122816.0000\n",
      "Epoch 1150/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7369359872.0000 - val_loss: 8413935104.0000\n",
      "Epoch 1151/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7388364800.0000 - val_loss: 8141530112.0000\n",
      "Epoch 1152/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7224466432.0000 - val_loss: 8234161664.0000\n",
      "Epoch 1153/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7253890048.0000 - val_loss: 8764364800.0000\n",
      "Epoch 1154/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7461967360.0000 - val_loss: 8606745600.0000\n",
      "Epoch 1155/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7263573504.0000 - val_loss: 8228925952.0000\n",
      "Epoch 1156/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7471028224.0000 - val_loss: 8209453568.0000\n",
      "Epoch 1157/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7576280064.0000 - val_loss: 8090675712.0000\n",
      "Epoch 1158/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7462885888.0000 - val_loss: 8079225344.0000\n",
      "Epoch 1159/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7308608512.0000 - val_loss: 8439024640.0000\n",
      "Epoch 1160/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7441324032.0000 - val_loss: 8194436608.0000\n",
      "Epoch 1161/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7329946112.0000 - val_loss: 8648030208.0000\n",
      "Epoch 1162/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7312908288.0000 - val_loss: 8209283072.0000\n",
      "Epoch 1163/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7441612800.0000 - val_loss: 8215631872.0000\n",
      "Epoch 1164/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7401774592.0000 - val_loss: 8940008448.0000\n",
      "Epoch 1165/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7391363584.0000 - val_loss: 8174525952.0000\n",
      "Epoch 1166/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7354235904.0000 - val_loss: 8101291008.0000\n",
      "Epoch 1167/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7259004416.0000 - val_loss: 8235948032.0000\n",
      "Epoch 1168/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7419474432.0000 - val_loss: 8349754368.0000\n",
      "Epoch 1169/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7324960768.0000 - val_loss: 8519891968.0000\n",
      "Epoch 1170/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7300921344.0000 - val_loss: 8538101248.0000\n",
      "Epoch 1171/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7337009152.0000 - val_loss: 8086519296.0000\n",
      "Epoch 1172/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7290756608.0000 - val_loss: 8206851072.0000\n",
      "Epoch 1173/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7472806912.0000 - val_loss: 8149939712.0000\n",
      "Epoch 1174/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7650466304.0000 - val_loss: 8496181760.0000\n",
      "Epoch 1175/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7358097408.0000 - val_loss: 8098091520.0000\n",
      "Epoch 1176/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7444663808.0000 - val_loss: 8349932544.0000\n",
      "Epoch 1177/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7285814272.0000 - val_loss: 8116833280.0000\n",
      "Epoch 1178/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7247749120.0000 - val_loss: 8861904896.0000\n",
      "Epoch 1179/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7403863040.0000 - val_loss: 8219407360.0000\n",
      "Epoch 1180/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7250867712.0000 - val_loss: 9113407488.0000\n",
      "Epoch 1181/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7422286336.0000 - val_loss: 8171411968.0000\n",
      "Epoch 1182/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7281846272.0000 - val_loss: 8196569600.0000\n",
      "Epoch 1183/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7416153600.0000 - val_loss: 8106174464.0000\n",
      "Epoch 1184/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7625623040.0000 - val_loss: 8479526400.0000\n",
      "Epoch 1185/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7362488320.0000 - val_loss: 8077798400.0000\n",
      "Epoch 1186/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7246822912.0000 - val_loss: 8174273536.0000\n",
      "Epoch 1187/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7208240128.0000 - val_loss: 8804615168.0000\n",
      "Epoch 1188/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7490121216.0000 - val_loss: 8153677824.0000\n",
      "Epoch 1189/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7308869632.0000 - val_loss: 8103092224.0000\n",
      "Epoch 1190/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7329418240.0000 - val_loss: 8224019968.0000\n",
      "Epoch 1191/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7423557632.0000 - val_loss: 8142909952.0000\n",
      "Epoch 1192/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7285097472.0000 - val_loss: 8778753024.0000\n",
      "Epoch 1193/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7397558784.0000 - val_loss: 8150435840.0000\n",
      "Epoch 1194/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7381030912.0000 - val_loss: 8079844864.0000\n",
      "Epoch 1195/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7352918016.0000 - val_loss: 10387872768.0000\n",
      "Epoch 1196/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7589923328.0000 - val_loss: 8158525440.0000\n",
      "Epoch 1197/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7432620032.0000 - val_loss: 10104038400.0000\n",
      "Epoch 1198/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7434272768.0000 - val_loss: 8072548864.0000\n",
      "Epoch 1199/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7433344000.0000 - val_loss: 8516867072.0000\n",
      "Epoch 1200/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7289219072.0000 - val_loss: 8170784768.0000\n",
      "Epoch 1201/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7332242944.0000 - val_loss: 8091487232.0000\n",
      "Epoch 1202/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7430411776.0000 - val_loss: 8113561600.0000\n",
      "Epoch 1203/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7326402560.0000 - val_loss: 8065326592.0000\n",
      "Epoch 1204/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7239278592.0000 - val_loss: 8079469056.0000\n",
      "Epoch 1205/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7308336640.0000 - val_loss: 8079618048.0000\n",
      "Epoch 1206/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7290586112.0000 - val_loss: 8084601344.0000\n",
      "Epoch 1207/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7304445440.0000 - val_loss: 9719354368.0000\n",
      "Epoch 1208/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7416284672.0000 - val_loss: 8336708096.0000\n",
      "Epoch 1209/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7334643200.0000 - val_loss: 8191621120.0000\n",
      "Epoch 1210/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7245299712.0000 - val_loss: 8449818624.0000\n",
      "Epoch 1211/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7333813760.0000 - val_loss: 8947539968.0000\n",
      "Epoch 1212/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7281100800.0000 - val_loss: 8123974144.0000\n",
      "Epoch 1213/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7221941248.0000 - val_loss: 8153510912.0000\n",
      "Epoch 1214/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7234138624.0000 - val_loss: 8230010368.0000\n",
      "Epoch 1215/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7344811008.0000 - val_loss: 8217524736.0000\n",
      "Epoch 1216/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7535229440.0000 - val_loss: 8836733952.0000\n",
      "Epoch 1217/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7367083008.0000 - val_loss: 8197280256.0000\n",
      "Epoch 1218/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7312090112.0000 - val_loss: 8405813760.0000\n",
      "Epoch 1219/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7459826688.0000 - val_loss: 8348311040.0000\n",
      "Epoch 1220/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7404054528.0000 - val_loss: 8265054208.0000\n",
      "Epoch 1221/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7194203648.0000 - val_loss: 8156412416.0000\n",
      "Epoch 1222/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7346799616.0000 - val_loss: 8226445824.0000\n",
      "Epoch 1223/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7247968256.0000 - val_loss: 8283905024.0000\n",
      "Epoch 1224/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7212664320.0000 - val_loss: 8137174016.0000\n",
      "Epoch 1225/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7280439296.0000 - val_loss: 8579838976.0000\n",
      "Epoch 1226/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7300331520.0000 - val_loss: 8477917184.0000\n",
      "Epoch 1227/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7639326720.0000 - val_loss: 9005934592.0000\n",
      "Epoch 1228/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7426670080.0000 - val_loss: 8238088704.0000\n",
      "Epoch 1229/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7332826624.0000 - val_loss: 8407504896.0000\n",
      "Epoch 1230/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7453881856.0000 - val_loss: 8066422272.0000\n",
      "Epoch 1231/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7519065600.0000 - val_loss: 9114970112.0000\n",
      "Epoch 1232/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7425992704.0000 - val_loss: 8126893568.0000\n",
      "Epoch 1233/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7278612992.0000 - val_loss: 8044578816.0000\n",
      "Epoch 1234/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7233186304.0000 - val_loss: 8089035264.0000\n",
      "Epoch 1235/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7565415424.0000 - val_loss: 8838411264.0000\n",
      "Epoch 1236/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7295343616.0000 - val_loss: 8309726720.0000\n",
      "Epoch 1237/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7236886016.0000 - val_loss: 8544237568.0000\n",
      "Epoch 1238/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7292735488.0000 - val_loss: 8098721280.0000\n",
      "Epoch 1239/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7358004224.0000 - val_loss: 8240573440.0000\n",
      "Epoch 1240/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7252397568.0000 - val_loss: 8179559936.0000\n",
      "Epoch 1241/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7336604672.0000 - val_loss: 8177492992.0000\n",
      "Epoch 1242/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7300210688.0000 - val_loss: 8480495616.0000\n",
      "Epoch 1243/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7559062528.0000 - val_loss: 8279396864.0000\n",
      "Epoch 1244/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7398019584.0000 - val_loss: 8177139712.0000\n",
      "Epoch 1245/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7278528512.0000 - val_loss: 8593156096.0000\n",
      "Epoch 1246/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7192982528.0000 - val_loss: 8270232576.0000\n",
      "Epoch 1247/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7294159872.0000 - val_loss: 8294788096.0000\n",
      "Epoch 1248/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7294797824.0000 - val_loss: 8155401728.0000\n",
      "Epoch 1249/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7204712448.0000 - val_loss: 8098527232.0000\n",
      "Epoch 1250/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7264778752.0000 - val_loss: 8100080128.0000\n",
      "Epoch 1251/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7247281664.0000 - val_loss: 8346165248.0000\n",
      "Epoch 1252/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7590972416.0000 - val_loss: 8112280064.0000\n",
      "Epoch 1253/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7372380672.0000 - val_loss: 8108147712.0000\n",
      "Epoch 1254/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7631585792.0000 - val_loss: 8974671872.0000\n",
      "Epoch 1255/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7451606528.0000 - val_loss: 8261950464.0000\n",
      "Epoch 1256/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7204472320.0000 - val_loss: 8196257792.0000\n",
      "Epoch 1257/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7495163904.0000 - val_loss: 8729375744.0000\n",
      "Epoch 1258/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7298399744.0000 - val_loss: 8368315904.0000\n",
      "Epoch 1259/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7366415872.0000 - val_loss: 8207765504.0000\n",
      "Epoch 1260/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7142619648.0000 - val_loss: 8105507328.0000\n",
      "Epoch 1261/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7499419648.0000 - val_loss: 8178273792.0000\n",
      "Epoch 1262/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7580011008.0000 - val_loss: 8366547456.0000\n",
      "Epoch 1263/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7263158784.0000 - val_loss: 8386915840.0000\n",
      "Epoch 1264/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7289324032.0000 - val_loss: 8106108928.0000\n",
      "Epoch 1265/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7274874368.0000 - val_loss: 8442969600.0000\n",
      "Epoch 1266/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7532641280.0000 - val_loss: 8254736896.0000\n",
      "Epoch 1267/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7288886272.0000 - val_loss: 8331863040.0000\n",
      "Epoch 1268/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7382240768.0000 - val_loss: 8070031872.0000\n",
      "Epoch 1269/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7219395584.0000 - val_loss: 8285324800.0000\n",
      "Epoch 1270/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7334912512.0000 - val_loss: 8075740672.0000\n",
      "Epoch 1271/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7244811264.0000 - val_loss: 8027283968.0000\n",
      "Epoch 1272/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7385729536.0000 - val_loss: 8251891200.0000\n",
      "Epoch 1273/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7246671360.0000 - val_loss: 8288016896.0000\n",
      "Epoch 1274/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7293862912.0000 - val_loss: 8171923456.0000\n",
      "Epoch 1275/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7356651008.0000 - val_loss: 8185609216.0000\n",
      "Epoch 1276/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7326745088.0000 - val_loss: 8053467136.0000\n",
      "Epoch 1277/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7190448640.0000 - val_loss: 8037549056.0000\n",
      "Epoch 1278/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7313627136.0000 - val_loss: 8156433920.0000\n",
      "Epoch 1279/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7436417024.0000 - val_loss: 8125196800.0000\n",
      "Epoch 1280/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7200323584.0000 - val_loss: 8234932736.0000\n",
      "Epoch 1281/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7314242048.0000 - val_loss: 8924562432.0000\n",
      "Epoch 1282/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7279378432.0000 - val_loss: 9049340928.0000\n",
      "Epoch 1283/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7267168768.0000 - val_loss: 8097431552.0000\n",
      "Epoch 1284/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7364256256.0000 - val_loss: 8357088256.0000\n",
      "Epoch 1285/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7410720768.0000 - val_loss: 8059146752.0000\n",
      "Epoch 1286/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7285634560.0000 - val_loss: 8398900736.0000\n",
      "Epoch 1287/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7304133632.0000 - val_loss: 8039017984.0000\n",
      "Epoch 1288/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7245611008.0000 - val_loss: 8148894720.0000\n",
      "Epoch 1289/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7205610496.0000 - val_loss: 8424789504.0000\n",
      "Epoch 1290/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7523641856.0000 - val_loss: 8122338304.0000\n",
      "Epoch 1291/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7410800640.0000 - val_loss: 8534562304.0000\n",
      "Epoch 1292/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7255997952.0000 - val_loss: 8315826176.0000\n",
      "Epoch 1293/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7190582784.0000 - val_loss: 8124272640.0000\n",
      "Epoch 1294/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7258259968.0000 - val_loss: 8148613632.0000\n",
      "Epoch 1295/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7234831872.0000 - val_loss: 8052462080.0000\n",
      "Epoch 1296/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7374411776.0000 - val_loss: 9638267904.0000\n",
      "Epoch 1297/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7346863616.0000 - val_loss: 8391442432.0000\n",
      "Epoch 1298/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7396765184.0000 - val_loss: 8218185216.0000\n",
      "Epoch 1299/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7219424256.0000 - val_loss: 8788568064.0000\n",
      "Epoch 1300/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7425172992.0000 - val_loss: 8459691008.0000\n",
      "Epoch 1301/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7243465216.0000 - val_loss: 8173382144.0000\n",
      "Epoch 1302/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7313851392.0000 - val_loss: 8205955072.0000\n",
      "Epoch 1303/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7410866176.0000 - val_loss: 8081635840.0000\n",
      "Epoch 1304/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7320239616.0000 - val_loss: 8066336768.0000\n",
      "Epoch 1305/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7601947136.0000 - val_loss: 8438744064.0000\n",
      "Epoch 1306/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7186433536.0000 - val_loss: 8480822272.0000\n",
      "Epoch 1307/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7338322432.0000 - val_loss: 8073789440.0000\n",
      "Epoch 1308/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7456320000.0000 - val_loss: 8805016576.0000\n",
      "Epoch 1309/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7645352448.0000 - val_loss: 8295648256.0000\n",
      "Epoch 1310/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7236344320.0000 - val_loss: 8178621440.0000\n",
      "Epoch 1311/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7330293248.0000 - val_loss: 8998408192.0000\n",
      "Epoch 1312/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7425442304.0000 - val_loss: 8118574080.0000\n",
      "Epoch 1313/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7167452672.0000 - val_loss: 8051098624.0000\n",
      "Epoch 1314/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7256730624.0000 - val_loss: 8362028544.0000\n",
      "Epoch 1315/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7229527552.0000 - val_loss: 8074598912.0000\n",
      "Epoch 1316/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7255224320.0000 - val_loss: 9196774400.0000\n",
      "Epoch 1317/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7309459456.0000 - val_loss: 8098541568.0000\n",
      "Epoch 1318/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7435441664.0000 - val_loss: 8147825152.0000\n",
      "Epoch 1319/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7331294720.0000 - val_loss: 8198987264.0000\n",
      "Epoch 1320/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7162598400.0000 - val_loss: 8678307840.0000\n",
      "Epoch 1321/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7448066048.0000 - val_loss: 8834036736.0000\n",
      "Epoch 1322/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7403458048.0000 - val_loss: 8441007616.0000\n",
      "Epoch 1323/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7282009088.0000 - val_loss: 8042696704.0000\n",
      "Epoch 1324/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7320784896.0000 - val_loss: 8486181376.0000\n",
      "Epoch 1325/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7220832768.0000 - val_loss: 8034496512.0000\n",
      "Epoch 1326/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7232145920.0000 - val_loss: 8097832448.0000\n",
      "Epoch 1327/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7151055872.0000 - val_loss: 8173436416.0000\n",
      "Epoch 1328/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7277561344.0000 - val_loss: 8088657920.0000\n",
      "Epoch 1329/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7157505024.0000 - val_loss: 8909416448.0000\n",
      "Epoch 1330/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7231672832.0000 - val_loss: 8041857536.0000\n",
      "Epoch 1331/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7536856576.0000 - val_loss: 8453522432.0000\n",
      "Epoch 1332/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7340025856.0000 - val_loss: 8078560256.0000\n",
      "Epoch 1333/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7235326976.0000 - val_loss: 8370945024.0000\n",
      "Epoch 1334/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7262534144.0000 - val_loss: 8207558656.0000\n",
      "Epoch 1335/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7465915904.0000 - val_loss: 8039176704.0000\n",
      "Epoch 1336/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7218010624.0000 - val_loss: 8261285888.0000\n",
      "Epoch 1337/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7404596736.0000 - val_loss: 8166803456.0000\n",
      "Epoch 1338/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7205857792.0000 - val_loss: 8525847552.0000\n",
      "Epoch 1339/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7359120384.0000 - val_loss: 8157051904.0000\n",
      "Epoch 1340/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7133036032.0000 - val_loss: 8051128832.0000\n",
      "Epoch 1341/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7242079232.0000 - val_loss: 8100738560.0000\n",
      "Epoch 1342/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7308172800.0000 - val_loss: 8184337920.0000\n",
      "Epoch 1343/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7213473792.0000 - val_loss: 8127613440.0000\n",
      "Epoch 1344/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7213847552.0000 - val_loss: 8149346304.0000\n",
      "Epoch 1345/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7303872000.0000 - val_loss: 8621534208.0000\n",
      "Epoch 1346/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7194743296.0000 - val_loss: 8001554432.0000\n",
      "Epoch 1347/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7427048960.0000 - val_loss: 8120330240.0000\n",
      "Epoch 1348/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7209717760.0000 - val_loss: 8030284800.0000\n",
      "Epoch 1349/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7259796992.0000 - val_loss: 8072196096.0000\n",
      "Epoch 1350/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7343086080.0000 - val_loss: 9173071872.0000\n",
      "Epoch 1351/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7379473920.0000 - val_loss: 8062455296.0000\n",
      "Epoch 1352/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7249465856.0000 - val_loss: 8021830656.0000\n",
      "Epoch 1353/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7209955840.0000 - val_loss: 8050568704.0000\n",
      "Epoch 1354/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7075504128.0000 - val_loss: 8005411840.0000\n",
      "Epoch 1355/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7232683008.0000 - val_loss: 8581461504.0000\n",
      "Epoch 1356/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7372558848.0000 - val_loss: 8098125312.0000\n",
      "Epoch 1357/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7209432064.0000 - val_loss: 8126275072.0000\n",
      "Epoch 1358/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7280317952.0000 - val_loss: 8020050432.0000\n",
      "Epoch 1359/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7288856576.0000 - val_loss: 8105731072.0000\n",
      "Epoch 1360/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7205491200.0000 - val_loss: 8202520576.0000\n",
      "Epoch 1361/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7664093696.0000 - val_loss: 8066486784.0000\n",
      "Epoch 1362/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7267096064.0000 - val_loss: 8741954560.0000\n",
      "Epoch 1363/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7276426752.0000 - val_loss: 8277811712.0000\n",
      "Epoch 1364/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7169460736.0000 - val_loss: 8690642944.0000\n",
      "Epoch 1365/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7279840256.0000 - val_loss: 8076451840.0000\n",
      "Epoch 1366/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7518243328.0000 - val_loss: 8564382720.0000\n",
      "Epoch 1367/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7245534720.0000 - val_loss: 8532992000.0000\n",
      "Epoch 1368/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7447197184.0000 - val_loss: 8033961472.0000\n",
      "Epoch 1369/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7095404544.0000 - val_loss: 8078209536.0000\n",
      "Epoch 1370/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7214088704.0000 - val_loss: 9297784832.0000\n",
      "Epoch 1371/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7172471808.0000 - val_loss: 8045364224.0000\n",
      "Epoch 1372/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7278568960.0000 - val_loss: 8081742336.0000\n",
      "Epoch 1373/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7126517760.0000 - val_loss: 8006493696.0000\n",
      "Epoch 1374/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7218031104.0000 - val_loss: 8004126208.0000\n",
      "Epoch 1375/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7297001472.0000 - val_loss: 8403693056.0000\n",
      "Epoch 1376/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7456356352.0000 - val_loss: 8191320064.0000\n",
      "Epoch 1377/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7098686464.0000 - val_loss: 8142773760.0000\n",
      "Epoch 1378/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7156598272.0000 - val_loss: 8098240512.0000\n",
      "Epoch 1379/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7239689728.0000 - val_loss: 8123821056.0000\n",
      "Epoch 1380/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7319051776.0000 - val_loss: 8564698112.0000\n",
      "Epoch 1381/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7273164800.0000 - val_loss: 9020113920.0000\n",
      "Epoch 1382/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7360045056.0000 - val_loss: 8075650560.0000\n",
      "Epoch 1383/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7502657024.0000 - val_loss: 8017893376.0000\n",
      "Epoch 1384/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7173627392.0000 - val_loss: 8008357888.0000\n",
      "Epoch 1385/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7313606144.0000 - val_loss: 8047637504.0000\n",
      "Epoch 1386/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7096800768.0000 - val_loss: 8126958080.0000\n",
      "Epoch 1387/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7252029440.0000 - val_loss: 7995065856.0000\n",
      "Epoch 1388/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7240403456.0000 - val_loss: 8073050112.0000\n",
      "Epoch 1389/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7172491776.0000 - val_loss: 8113949696.0000\n",
      "Epoch 1390/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7307525632.0000 - val_loss: 8224838144.0000\n",
      "Epoch 1391/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7126849024.0000 - val_loss: 8257909248.0000\n",
      "Epoch 1392/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7293115392.0000 - val_loss: 8106018304.0000\n",
      "Epoch 1393/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7170563584.0000 - val_loss: 8830109696.0000\n",
      "Epoch 1394/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7334565376.0000 - val_loss: 8030718464.0000\n",
      "Epoch 1395/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7427959296.0000 - val_loss: 8921152512.0000\n",
      "Epoch 1396/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7152753152.0000 - val_loss: 8258359808.0000\n",
      "Epoch 1397/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7253650432.0000 - val_loss: 8169053184.0000\n",
      "Epoch 1398/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7374841344.0000 - val_loss: 8123863040.0000\n",
      "Epoch 1399/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7193750528.0000 - val_loss: 8894739456.0000\n",
      "Epoch 1400/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7337276928.0000 - val_loss: 8167290368.0000\n",
      "Epoch 1401/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7308340224.0000 - val_loss: 8110013440.0000\n",
      "Epoch 1402/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7372289536.0000 - val_loss: 8148648960.0000\n",
      "Epoch 1403/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7235394560.0000 - val_loss: 8138146816.0000\n",
      "Epoch 1404/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7147357184.0000 - val_loss: 9023616000.0000\n",
      "Epoch 1405/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7297618432.0000 - val_loss: 8514365440.0000\n",
      "Epoch 1406/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7331282432.0000 - val_loss: 8028123648.0000\n",
      "Epoch 1407/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7319964160.0000 - val_loss: 8155096576.0000\n",
      "Epoch 1408/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7465573376.0000 - val_loss: 8772020224.0000\n",
      "Epoch 1409/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7262419968.0000 - val_loss: 8082177536.0000\n",
      "Epoch 1410/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7265404416.0000 - val_loss: 8575481856.0000\n",
      "Epoch 1411/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7211868672.0000 - val_loss: 8568685056.0000\n",
      "Epoch 1412/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7210542080.0000 - val_loss: 8060854272.0000\n",
      "Epoch 1413/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7228230144.0000 - val_loss: 8175138816.0000\n",
      "Epoch 1414/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7087282176.0000 - val_loss: 8071256064.0000\n",
      "Epoch 1415/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7126561280.0000 - val_loss: 8910456832.0000\n",
      "Epoch 1416/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7211723264.0000 - val_loss: 8080901632.0000\n",
      "Epoch 1417/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7363975680.0000 - val_loss: 8555487744.0000\n",
      "Epoch 1418/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7125437440.0000 - val_loss: 8042458624.0000\n",
      "Epoch 1419/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7116731392.0000 - val_loss: 8348494336.0000\n",
      "Epoch 1420/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7352318464.0000 - val_loss: 8060736000.0000\n",
      "Epoch 1421/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7233705472.0000 - val_loss: 8529660416.0000\n",
      "Epoch 1422/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7596082176.0000 - val_loss: 10070766592.0000\n",
      "Epoch 1423/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7395395072.0000 - val_loss: 8109980160.0000\n",
      "Epoch 1424/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7279771648.0000 - val_loss: 8276875264.0000\n",
      "Epoch 1425/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7165171712.0000 - val_loss: 8023109632.0000\n",
      "Epoch 1426/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7139315712.0000 - val_loss: 8073412608.0000\n",
      "Epoch 1427/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7233440256.0000 - val_loss: 8243660288.0000\n",
      "Epoch 1428/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7164238336.0000 - val_loss: 8391254528.0000\n",
      "Epoch 1429/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7218088960.0000 - val_loss: 7977300480.0000\n",
      "Epoch 1430/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7086701056.0000 - val_loss: 8331998720.0000\n",
      "Epoch 1431/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7136005632.0000 - val_loss: 8022648320.0000\n",
      "Epoch 1432/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7181330432.0000 - val_loss: 8007170048.0000\n",
      "Epoch 1433/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7144670720.0000 - val_loss: 8111830016.0000\n",
      "Epoch 1434/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7201645056.0000 - val_loss: 8233590784.0000\n",
      "Epoch 1435/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7478049792.0000 - val_loss: 8278572032.0000\n",
      "Epoch 1436/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7166161920.0000 - val_loss: 8544014848.0000\n",
      "Epoch 1437/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7221177856.0000 - val_loss: 8972418048.0000\n",
      "Epoch 1438/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7263699456.0000 - val_loss: 8199212032.0000\n",
      "Epoch 1439/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7250899456.0000 - val_loss: 8026658304.0000\n",
      "Epoch 1440/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7230815232.0000 - val_loss: 7985989632.0000\n",
      "Epoch 1441/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7345073664.0000 - val_loss: 8017788416.0000\n",
      "Epoch 1442/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7286870016.0000 - val_loss: 8121169408.0000\n",
      "Epoch 1443/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7345840640.0000 - val_loss: 8751263744.0000\n",
      "Epoch 1444/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7159592448.0000 - val_loss: 8483197440.0000\n",
      "Epoch 1445/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7100514816.0000 - val_loss: 8166812672.0000\n",
      "Epoch 1446/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7256825344.0000 - val_loss: 8571088896.0000\n",
      "Epoch 1447/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7218913280.0000 - val_loss: 8872867840.0000\n",
      "Epoch 1448/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7340352000.0000 - val_loss: 8288525312.0000\n",
      "Epoch 1449/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7145428992.0000 - val_loss: 8326771712.0000\n",
      "Epoch 1450/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7165091840.0000 - val_loss: 8390193152.0000\n",
      "Epoch 1451/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7235403776.0000 - val_loss: 8126723072.0000\n",
      "Epoch 1452/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7351263232.0000 - val_loss: 8077407232.0000\n",
      "Epoch 1453/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7247020032.0000 - val_loss: 8085180416.0000\n",
      "Epoch 1454/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7214883840.0000 - val_loss: 8149032448.0000\n",
      "Epoch 1455/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7197434880.0000 - val_loss: 7997477888.0000\n",
      "Epoch 1456/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7143267328.0000 - val_loss: 8050315264.0000\n",
      "Epoch 1457/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7292898816.0000 - val_loss: 8351890432.0000\n",
      "Epoch 1458/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7312392192.0000 - val_loss: 8382791168.0000\n",
      "Epoch 1459/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7335564800.0000 - val_loss: 8294307840.0000\n",
      "Epoch 1460/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7128099328.0000 - val_loss: 7999390720.0000\n",
      "Epoch 1461/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7159051264.0000 - val_loss: 8010873344.0000\n",
      "Epoch 1462/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7100281344.0000 - val_loss: 8266423808.0000\n",
      "Epoch 1463/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7111682048.0000 - val_loss: 8167806464.0000\n",
      "Epoch 1464/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7162768896.0000 - val_loss: 7989287936.0000\n",
      "Epoch 1465/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7092997632.0000 - val_loss: 8409403904.0000\n",
      "Epoch 1466/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7170631680.0000 - val_loss: 8108025344.0000\n",
      "Epoch 1467/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7150462464.0000 - val_loss: 8035052544.0000\n",
      "Epoch 1468/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7258279936.0000 - val_loss: 8052423168.0000\n",
      "Epoch 1469/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7197600768.0000 - val_loss: 8140885504.0000\n",
      "Epoch 1470/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7272351232.0000 - val_loss: 8154986496.0000\n",
      "Epoch 1471/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7272003072.0000 - val_loss: 7980551680.0000\n",
      "Epoch 1472/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7282747904.0000 - val_loss: 8092542464.0000\n",
      "Epoch 1473/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7515852800.0000 - val_loss: 8373424128.0000\n",
      "Epoch 1474/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7110608896.0000 - val_loss: 8064324096.0000\n",
      "Epoch 1475/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7085292032.0000 - val_loss: 8079380992.0000\n",
      "Epoch 1476/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7230380032.0000 - val_loss: 8070298624.0000\n",
      "Epoch 1477/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7146011648.0000 - val_loss: 7982893568.0000\n",
      "Epoch 1478/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7597023232.0000 - val_loss: 8044052992.0000\n",
      "Epoch 1479/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7176470528.0000 - val_loss: 8070650368.0000\n",
      "Epoch 1480/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7075393536.0000 - val_loss: 8484258304.0000\n",
      "Epoch 1481/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7341001728.0000 - val_loss: 8057175552.0000\n",
      "Epoch 1482/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7276958720.0000 - val_loss: 8083396096.0000\n",
      "Epoch 1483/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7091859968.0000 - val_loss: 8053218816.0000\n",
      "Epoch 1484/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7116634624.0000 - val_loss: 7974659584.0000\n",
      "Epoch 1485/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7230956544.0000 - val_loss: 8403894784.0000\n",
      "Epoch 1486/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7304540160.0000 - val_loss: 8211573248.0000\n",
      "Epoch 1487/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7057070080.0000 - val_loss: 7986724864.0000\n",
      "Epoch 1488/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7129614336.0000 - val_loss: 7990033920.0000\n",
      "Epoch 1489/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7103666176.0000 - val_loss: 8149279232.0000\n",
      "Epoch 1490/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7207664640.0000 - val_loss: 8859003904.0000\n",
      "Epoch 1491/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7153065472.0000 - val_loss: 8347875840.0000\n",
      "Epoch 1492/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7074326016.0000 - val_loss: 7998281216.0000\n",
      "Epoch 1493/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7323675648.0000 - val_loss: 8317367296.0000\n",
      "Epoch 1494/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7208569856.0000 - val_loss: 7961635840.0000\n",
      "Epoch 1495/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7172215808.0000 - val_loss: 7980088832.0000\n",
      "Epoch 1496/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7155883008.0000 - val_loss: 8050723840.0000\n",
      "Epoch 1497/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7061484032.0000 - val_loss: 8027349504.0000\n",
      "Epoch 1498/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7446918144.0000 - val_loss: 8096808448.0000\n",
      "Epoch 1499/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7134782976.0000 - val_loss: 8151383040.0000\n",
      "Epoch 1500/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7323144192.0000 - val_loss: 7943204864.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208a067d700>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1500) #datayı split etmek yerine kendimiz verdik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8815a4c1-495e-4880-8c80-c6e0d54c8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 19)                1558      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,098\n",
      "Trainable params: 3,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4ebfc-59cc-4ee2-b61c-1f538ba63cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
